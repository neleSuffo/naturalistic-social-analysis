{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add audio results to output.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pkl file\n",
    "quantex_results = pd.read_pickle(\"/home/nele_pauline_suffo/outputs/vtc/quantex_df.pkl\")\n",
    "# remove _16khz from audio_file_name \n",
    "quantex_results['audio_file_name'] = quantex_results['audio_file_name'].str.replace('_16kHz', '', regex=False)\n",
    "\n",
    "#quantex_results = df[0:10]\n",
    "\n",
    "# Load frame-wise detection results and video info from the database\n",
    "db_path = '/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db'\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    frame_df = pd.read_sql_query(\"SELECT * FROM Detections\", conn)\n",
    "    videos_info_df = pd.read_sql_query(\"SELECT video_id, video_path FROM Videos\", conn)\n",
    "\n",
    "# Merge video_id into quantex_results\n",
    "quantex_results = pd.merge(quantex_results, videos_info_df[['video_id', 'video_path']], left_on='audio_file_name', right_on='video_path', how='left')\n",
    "\n",
    "# Map RTTM annotations to frames\n",
    "fps = 30  # Assuming a frame rate of 30 FPS\n",
    "\n",
    "# Initialize new columns for speaker types in frame_df\n",
    "speaker_types = ['KCHI', 'FEM', 'MAL', 'CHI']  # Define target speaker type columns\n",
    "for speaker_col in speaker_types:\n",
    "    frame_df[speaker_col] = 0\n",
    "\n",
    "# Assign speaker annotations to frames for KCHI, CDS, OHS\n",
    "if not quantex_results.empty:  # Proceed only if quantex_results has data after merge\n",
    "    for _, rttm_row in quantex_results.iterrows():\n",
    "        rttm_video_id = rttm_row['video_id']\n",
    "        speaker_label_from_rttm = rttm_row['Voice_type']  # Label from RTTM 'Speaker' column\n",
    "        utterance_start_time = rttm_row['Utterance_Start']\n",
    "        utterance_end_time = rttm_row['Utterance_End']\n",
    "\n",
    "        # Determine which speaker type column to update\n",
    "        if speaker_label_from_rttm not in speaker_types:\n",
    "            continue  # Skip unknown speaker types\n",
    "\n",
    "        # Convert time to frame numbers (inclusive)\n",
    "        start_frame = int(utterance_start_time * fps)\n",
    "        end_frame = int(utterance_end_time * fps)\n",
    "\n",
    "        #print(f\"Convert {utterance_start_time} - {utterance_end_time} for video {rttm_video_id} with speaker type {speaker_label_from_rttm} to {start_frame} - {end_frame}\")\n",
    "\n",
    "        # Set the speaker label to 1 for all frames in range\n",
    "        frame_mask = (\n",
    "            (frame_df['video_id'] == rttm_video_id) &\n",
    "            (frame_df['frame_number'] >= start_frame) &\n",
    "            (frame_df['frame_number'] <= end_frame)\n",
    "        )\n",
    "        frame_df.loc[frame_mask, speaker_label_from_rttm] = 1\n",
    "\n",
    "# To view the first few rows of the modified frame_df:\n",
    "# print(\"Modified frame_df head:\")\n",
    "# print(frame_df.head())\n",
    "\n",
    "# To view rows where speaker types are active:\n",
    "# print(\"\\nFrames with speaker activity:\")\n",
    "# print(frame_df[(frame_df['KCHI'] == 1) | (frame_df['CDS'] == 1) | (frame_df['OHS'] == 1)].head())\n",
    "\n",
    "#Save the updated frame-wise detection results back to the database (optional)\n",
    "db_path = '/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db'\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Save the new table\n",
    "    frame_df.to_sql('Detections_with_speaker', conn, if_exists='replace', index=False)\n",
    "\n",
    "    # List all tables to confirm it's there\n",
    "    tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "    print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How many utterances does the key child produce?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# show all columns in pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_01 = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 40\n",
    "),\n",
    "-- Ziehe alle möglichen Frames aus den Videos der RandomSubjects\n",
    "AllFrames AS (\n",
    "    SELECT \n",
    "        rs.child_id, \n",
    "        rs.video_id, \n",
    "        rs.age_at_recording,\n",
    "        f.frame_number\n",
    "    FROM RandomSubjects rs\n",
    "    JOIN (\n",
    "        -- Hier alle möglichen Frames pro Video bestimmen\n",
    "        SELECT video_id, frame_number\n",
    "        FROM Detections_with_speaker\n",
    "        GROUP BY video_id, frame_number\n",
    "    ) f ON rs.video_id = f.video_id\n",
    "),\n",
    "-- Ziehe zufällig 5000 Frames\n",
    "RandomFrames AS (\n",
    "    SELECT *\n",
    "    FROM AllFrames\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5000\n",
    ")\n",
    "SELECT \n",
    "    rf.video_id,\n",
    "    rf.frame_number,\n",
    "    rf.child_id,\n",
    "    rf.age_at_recording AS age,\n",
    "    d.proximity,\n",
    "    CASE\n",
    "        WHEN CAST(d.object_class AS INTEGER) >= 5 AND CAST(d.object_class AS INTEGER) <= 10 THEN d.object_class\n",
    "        ELSE 'none'\n",
    "    END AS object_class,\n",
    "    COALESCE(d.gaze_direction, 'none') AS gaze_direction,\n",
    "    COALESCE(d.KCHI, 0) AS kchi_present,\n",
    "    COALESCE(CASE WHEN d.FEM = 1 OR d.CHI = 1 OR d.MAL = 1 THEN 1 ELSE 0 END, 0) AS cds_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 2 OR CAST(d.object_class AS INTEGER) = 3 THEN 1 ELSE 0 END, 0) AS face_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 0 THEN 1 ELSE 0 END, 0) AS child_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 1 THEN 1 ELSE 0 END, 0) AS adult_present,\n",
    "    CASE \n",
    "        WHEN \n",
    "            COALESCE(d.FEM, 0) = 1 OR COALESCE(d.CHI, 0) = 1 OR COALESCE(d.MAL, 0) = 1\n",
    "            OR COALESCE(d.proximity, 0) > 0.5\n",
    "            OR COALESCE(CAST(d.object_class AS INTEGER), -1) = 0\n",
    "            OR COALESCE(CAST(d.object_class AS INTEGER), -1) = 1\n",
    "            THEN 'social'\n",
    "        ELSE 'alone'\n",
    "    END AS play_context,\n",
    "    CASE \n",
    "        WHEN COALESCE(CAST(d.object_class AS INTEGER), -1) = 1 THEN 'adult'\n",
    "        WHEN COALESCE(CAST(d.object_class AS INTEGER), -1) = 0 THEN 'child'\n",
    "        ELSE 'none'\n",
    "    END AS person_age_class\n",
    "FROM RandomFrames rf\n",
    "LEFT JOIN Detections_with_speaker d\n",
    "    ON rf.video_id = d.video_id\n",
    "   AND rf.frame_number = d.frame_number\n",
    "ORDER BY rf.child_id, rf.video_id, rf.frame_number;\n",
    "\"\"\"\n",
    "\n",
    "def merge_duplicates_01(df):\n",
    "    # Mapping for object_class\n",
    "    object_class_map = {\n",
    "        '5': 'book',\n",
    "        '6': 'toy',\n",
    "        '7': 'kitchenware',\n",
    "        '8': 'screen',\n",
    "        '9': 'food',\n",
    "        '10': 'other object'\n",
    "    }\n",
    "\n",
    "    grouped = df.groupby(['video_id', 'frame_number', 'child_id', 'age'])\n",
    "    merged_rows = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        merged_row = {\n",
    "            'video_id': name[0],\n",
    "            'frame_number': name[1],\n",
    "            'child_id': name[2],\n",
    "            'age': name[3],\n",
    "            'kchi_present': int(group['kchi_present'].any()),\n",
    "            'cds_present': int(group['cds_present'].any()),\n",
    "            'face_present': int(group['face_present'].any()),\n",
    "            'child_present': int(group['child_present'].any()),\n",
    "            'adult_present': int(group['adult_present'].any()),\n",
    "            'play_context': (\n",
    "                'social' if 'social' in group['play_context'].values\n",
    "                else 'alone' if all(pc == 'alone' for pc in group['play_context'].values)\n",
    "                else 'none'\n",
    "            )\n",
    "        }\n",
    "\n",
    "        # --- object_class: only one column, mapping, 'multiple' if >1 ---\n",
    "        raw_object_classes = [str(v) for v in group['object_class'].unique() if v not in ('none', 'NaN')]\n",
    "        mapped_object_classes = [object_class_map.get(oc, oc) for oc in raw_object_classes]\n",
    "        mapped_object_classes = [oc for oc in mapped_object_classes if oc not in ('none', 'NaN')]\n",
    "        if len(mapped_object_classes) == 1:\n",
    "            merged_row['object_class'] = mapped_object_classes[0]\n",
    "        elif len(mapped_object_classes) > 1:\n",
    "            merged_row['object_class'] = 'multiple'\n",
    "        else:\n",
    "            merged_row['object_class'] = 'none'\n",
    "\n",
    "        # --- person_age_class logic ---\n",
    "        pac_set = set(v for v in group['person_age_class'].unique() if v not in ('none', 'NaN'))\n",
    "        if pac_set == {'child'}:\n",
    "            merged_row['person_age_class'] = 'child'\n",
    "        elif pac_set == {'adult'}:\n",
    "            merged_row['person_age_class'] = 'adult'\n",
    "        elif pac_set == {'child', 'adult'}:\n",
    "            merged_row['person_age_class'] = 'both'\n",
    "        else:\n",
    "            merged_row['person_age_class'] = 'none'\n",
    "\n",
    "        # --- proximity and gaze_direction: take max proximity and corresponding gaze ---\n",
    "        proximities = pd.to_numeric(group['proximity'], errors='coerce').fillna(-1)\n",
    "        if not proximities.empty and proximities.max() >= 0:\n",
    "            max_prox_idx = proximities.idxmax()\n",
    "            max_prox_value = proximities.loc[max_prox_idx]\n",
    "            merged_row['proximity'] = max_prox_value\n",
    "            gaze_value = group.loc[max_prox_idx, 'gaze_direction']\n",
    "            if gaze_value in ('none', 'NaN', None):\n",
    "                gaze_value = 'none'\n",
    "            merged_row['gaze_direction'] = gaze_value\n",
    "        else:\n",
    "            merged_row['proximity'] = None\n",
    "            merged_row['gaze_direction'] = 'none'\n",
    "\n",
    "        merged_rows.append(merged_row)\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>child_id</th>\n",
       "      <th>age</th>\n",
       "      <th>kchi_present</th>\n",
       "      <th>cds_present</th>\n",
       "      <th>face_present</th>\n",
       "      <th>child_present</th>\n",
       "      <th>adult_present</th>\n",
       "      <th>play_context</th>\n",
       "      <th>object_class</th>\n",
       "      <th>person_age_class</th>\n",
       "      <th>proximity</th>\n",
       "      <th>gaze_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alone</td>\n",
       "      <td>multiple</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>490</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alone</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1190</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>social</td>\n",
       "      <td>none</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.290025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1200</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>social</td>\n",
       "      <td>other object</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.301284</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1370</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alone</td>\n",
       "      <td>other object</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>1460</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alone</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>1550</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alone</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>social</td>\n",
       "      <td>none</td>\n",
       "      <td>adult</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>2150</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>social</td>\n",
       "      <td>none</td>\n",
       "      <td>adult</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>2270</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>social</td>\n",
       "      <td>none</td>\n",
       "      <td>adult</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  frame_number  child_id  age  kchi_present  cds_present  \\\n",
       "0        11           100    263284  3.8             0            0   \n",
       "1        11           490    263284  3.8             0            0   \n",
       "2        11          1190    263284  3.8             0            0   \n",
       "3        11          1200    263284  3.8             0            0   \n",
       "4        11          1370    263284  3.8             0            0   \n",
       "5        11          1460    263284  3.8             0            0   \n",
       "6        11          1550    263284  3.8             0            0   \n",
       "7        11          2140    263284  3.8             1            0   \n",
       "8        11          2150    263284  3.8             1            0   \n",
       "9        11          2270    263284  3.8             0            0   \n",
       "\n",
       "   face_present  child_present  adult_present play_context  object_class  \\\n",
       "0             0              0              0        alone      multiple   \n",
       "1             0              0              0        alone          none   \n",
       "2             1              0              1       social          none   \n",
       "3             1              0              1       social  other object   \n",
       "4             0              0              0        alone  other object   \n",
       "5             0              0              0        alone          none   \n",
       "6             0              0              0        alone          none   \n",
       "7             1              0              1       social          none   \n",
       "8             0              0              1       social          none   \n",
       "9             0              0              1       social          none   \n",
       "\n",
       "  person_age_class  proximity gaze_direction  \n",
       "0             none        NaN           none  \n",
       "1             none        NaN           none  \n",
       "2            adult   0.290025            1.0  \n",
       "3            adult   0.301284            1.0  \n",
       "4             none        NaN           none  \n",
       "5             none        NaN           none  \n",
       "6             none        NaN           none  \n",
       "7            adult   1.000000            1.0  \n",
       "8            adult        NaN           none  \n",
       "9            adult        NaN           none  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with sqlite3.connect('/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db') as conn:\n",
    "    utterance_01_df = pd.read_sql_query(query_01, conn)\n",
    "\n",
    "utterance_01_df_merged = merge_duplicates_01(utterance_01_df)\n",
    "utterance_01_df_merged.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/utterance_01_df.csv', index=False)\n",
    "\n",
    "utterance_01_df_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) alone vs. social: kchi_present ~ age * context + (context|child_id) with context being a factor with levels „social“ and „alone“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       "    video_id  frame_number  child_id  kchi_present  age play_context\n",
       " 0        11           100    263284             0  3.8        alone\n",
       " 1        11           490    263284             0  3.8        alone\n",
       " 2        11          1190    263284             0  3.8       social\n",
       " 3        11          1200    263284             0  3.8       social\n",
       " 4        11          1370    263284             0  3.8        alone\n",
       " 5        11          1460    263284             0  3.8        alone\n",
       " 6        11          1550    263284             0  3.8        alone\n",
       " 7        11          2140    263284             1  3.8       social\n",
       " 8        11          2150    263284             1  3.8       social\n",
       " 9        11          2270    263284             0  3.8       social)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_01a_df = utterance_01_df_merged[['video_id', 'frame_number', 'child_id', 'kchi_present', 'age', 'play_context']]\n",
    "utterance_01a_df.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/utterance_01a_df.csv', index=False)\n",
    "len(utterance_01a_df), utterance_01a_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) only alone data: kchi_present ~ age*object + (object | child_id) see if predictor object makes a difference, with object being a factor with levels „toy“, „book“, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2197,\n",
       "     video_id  frame_number  child_id  kchi_present  age  object_class\n",
       " 0         11           100    263284             0  3.8      multiple\n",
       " 1         11           490    263284             0  3.8          none\n",
       " 4         11          1370    263284             0  3.8  other object\n",
       " 5         11          1460    263284             0  3.8          none\n",
       " 6         11          1550    263284             0  3.8          none\n",
       " 11        11          3030    263284             0  3.8      multiple\n",
       " 13        11          3080    263284             0  3.8           toy\n",
       " 14        11          4110    263284             0  3.8          none\n",
       " 16        11          4500    263284             0  3.8          none\n",
       " 17        11          5120    263284             0  3.8           toy)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_01b_df = utterance_01_df_merged[utterance_01_df_merged['play_context'] == 'alone']\n",
    "utterance_01b_df = utterance_01b_df[['video_id', 'frame_number', 'child_id', 'kchi_present', 'age', 'object_class']]\n",
    "utterance_01b_df.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/utterance_01b_df.csv', index=False)\n",
    "len(utterance_01b_df), utterance_01b_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) only social data: kchi_present ~ age * age_class * face * gaze + (age_class * face * gaze|child_id) see if type of social interaction makes a differences, that is the age class of the other person, whether there is a face and whether there is gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2803,\n",
       "     video_id  frame_number  child_id  kchi_present  age  face_present  \\\n",
       " 2         11          1190    263284             0  3.8             1   \n",
       " 3         11          1200    263284             0  3.8             1   \n",
       " 7         11          2140    263284             1  3.8             1   \n",
       " 8         11          2150    263284             1  3.8             0   \n",
       " 9         11          2270    263284             0  3.8             0   \n",
       " 10        11          2640    263284             1  3.8             0   \n",
       " 12        11          3070    263284             0  3.8             1   \n",
       " 15        11          4370    263284             0  3.8             0   \n",
       " 18        11          5450    263284             1  3.8             1   \n",
       " 20        11          7030    263284             1  3.8             0   \n",
       " \n",
       "    person_age_class gaze_direction  \n",
       " 2             adult            1.0  \n",
       " 3             adult            1.0  \n",
       " 7             adult            1.0  \n",
       " 8             adult           none  \n",
       " 9             adult           none  \n",
       " 10            adult           none  \n",
       " 12             none            1.0  \n",
       " 15            adult           none  \n",
       " 18            adult            0.0  \n",
       " 20             none           none  )"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_01c_df = utterance_01_df_merged[utterance_01_df_merged['play_context'] == 'social']\n",
    "utterance_01c_df = utterance_01c_df[['video_id', 'frame_number', 'child_id', 'kchi_present', 'age', 'face_present', 'person_age_class', 'gaze_direction']]\n",
    "utterance_01c_df.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/utterance_01c_df.csv', index=False)\n",
    "len(utterance_01c_df), utterance_01c_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How much speech is directed at the key child?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_02 = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 40\n",
    "),\n",
    "-- Ziehe alle möglichen Frames aus den Videos der RandomSubjects\n",
    "AllFrames AS (\n",
    "    SELECT \n",
    "        rs.child_id, \n",
    "        rs.video_id, \n",
    "        rs.age_at_recording,\n",
    "        f.frame_number\n",
    "    FROM RandomSubjects rs\n",
    "    JOIN (\n",
    "        -- Hier alle möglichen Frames pro Video bestimmen\n",
    "        SELECT video_id, frame_number\n",
    "        FROM Detections_with_speaker\n",
    "        GROUP BY video_id, frame_number\n",
    "    ) f ON rs.video_id = f.video_id\n",
    "),\n",
    "-- Ziehe zufällig 5000 Frames\n",
    "RandomFrames AS (\n",
    "    SELECT *\n",
    "    FROM AllFrames\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5000\n",
    ")\n",
    "SELECT \n",
    "    rf.video_id,\n",
    "    rf.frame_number,\n",
    "    rf.child_id,\n",
    "    rf.age_at_recording AS age,\n",
    "    d.proximity,\n",
    "    COALESCE(d.gaze_direction, 'none') AS gaze_direction,\n",
    "    COALESCE(CASE WHEN d.FEM = 1 OR d.CHI = 1 OR d.MAL = 1 THEN 1 ELSE 0 END, 0) AS cds_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 2 OR CAST(d.object_class AS INTEGER) = 3 THEN 1 ELSE 0 END, 0) AS face_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 0 THEN 1 ELSE 0 END, 0) AS child_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 1 THEN 1 ELSE 0 END, 0) AS adult_present,\n",
    "    CASE \n",
    "        WHEN COALESCE(CAST(d.object_class AS INTEGER), -1) = 1 THEN 'adult'\n",
    "        WHEN COALESCE(CAST(d.object_class AS INTEGER), -1) = 0 THEN 'child'\n",
    "        ELSE 'none'\n",
    "    END AS person_age_class\n",
    "FROM RandomFrames rf\n",
    "LEFT JOIN Detections_with_speaker d\n",
    "    ON rf.video_id = d.video_id\n",
    "   AND rf.frame_number = d.frame_number\n",
    "ORDER BY rf.child_id, rf.video_id, rf.frame_number;\n",
    "\"\"\"\n",
    "\n",
    "def merge_duplicates_02(df):\n",
    "    grouped = df.groupby(['video_id', 'frame_number', 'child_id', 'age'])\n",
    "    merged_rows = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        merged_row = {\n",
    "            'video_id': name[0],\n",
    "            'frame_number': name[1],\n",
    "            'child_id': name[2],\n",
    "            'age': name[3],\n",
    "            'cds_present': int(group['cds_present'].any()),\n",
    "            'face_present': int(group['face_present'].any()),\n",
    "            'child_present': int(group['child_present'].any()),\n",
    "            'adult_present': int(group['adult_present'].any()),\n",
    "        }\n",
    "\n",
    "        # --- person_age_class logic ---\n",
    "        pac_set = set(v for v in group['person_age_class'].unique() if v not in ('none', 'NaN'))\n",
    "        if pac_set == {'child'}:\n",
    "            merged_row['person_age_class'] = 'child'\n",
    "        elif pac_set == {'adult'}:\n",
    "            merged_row['person_age_class'] = 'adult'\n",
    "        elif pac_set == {'child', 'adult'}:\n",
    "            merged_row['person_age_class'] = 'both'\n",
    "        else:\n",
    "            merged_row['person_age_class'] = 'none'\n",
    "\n",
    "        # --- proximity and gaze_direction: take max proximity and corresponding gaze ---\n",
    "        proximities = pd.to_numeric(group['proximity'], errors='coerce').fillna(-1)\n",
    "        if not proximities.empty and proximities.max() >= 0:\n",
    "            max_prox_idx = proximities.idxmax()\n",
    "            max_prox_value = proximities.loc[max_prox_idx]\n",
    "            merged_row['proximity'] = max_prox_value\n",
    "            gaze_value = group.loc[max_prox_idx, 'gaze_direction']\n",
    "            if gaze_value in ('none', 'NaN', None):\n",
    "                gaze_value = 'none'\n",
    "            merged_row['gaze_direction'] = gaze_value\n",
    "        else:\n",
    "            merged_row['proximity'] = None\n",
    "            merged_row['gaze_direction'] = 'none'\n",
    "\n",
    "        merged_rows.append(merged_row)\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cds_present ~ age * age_class * face * gaze * proximity + (age_class * face * gaze|child_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>child_id</th>\n",
       "      <th>age</th>\n",
       "      <th>cds_present</th>\n",
       "      <th>face_present</th>\n",
       "      <th>child_present</th>\n",
       "      <th>adult_present</th>\n",
       "      <th>person_age_class</th>\n",
       "      <th>proximity</th>\n",
       "      <th>gaze_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>490</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>840</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>850</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1060</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1440</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1710</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1930</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2610</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>4110</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  frame_number  child_id   age  cds_present  face_present  \\\n",
       "0         3           490    263190  3.73            1             0   \n",
       "1         3           840    263190  3.73            0             0   \n",
       "2         3           850    263190  3.73            0             0   \n",
       "3         3          1060    263190  3.73            0             0   \n",
       "4         3          1440    263190  3.73            0             0   \n",
       "5         3          1710    263190  3.73            0             0   \n",
       "6         3          1930    263190  3.73            0             0   \n",
       "7         3          2000    263190  3.73            0             0   \n",
       "8         3          2610    263190  3.73            0             0   \n",
       "9         3          4110    263190  3.73            0             0   \n",
       "\n",
       "   child_present  adult_present person_age_class  proximity gaze_direction  \n",
       "0              0              0             none        NaN           none  \n",
       "1              0              0             none        NaN           none  \n",
       "2              0              0             none        NaN           none  \n",
       "3              0              0             none        NaN           none  \n",
       "4              0              0             none        NaN           none  \n",
       "5              0              0             none        NaN           none  \n",
       "6              0              0             none        NaN           none  \n",
       "7              0              0             none        NaN           none  \n",
       "8              0              0             none        NaN           none  \n",
       "9              0              0             none        NaN           none  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with sqlite3.connect('/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db') as conn:\n",
    "    utterance_02_df = pd.read_sql_query(query_02, conn)\n",
    "\n",
    "utterance_02_df_merged = merge_duplicates_02(utterance_02_df)\n",
    "utterance_02_df_merged.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/utterance_02_df.csv', index=False)\n",
    "\n",
    "utterance_02_df_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Are children more frequently in the presence of adults compared to other children?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_03 = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 40\n",
    "),\n",
    "-- Ziehe alle möglichen Frames aus den Videos der RandomSubjects\n",
    "AllFrames AS (\n",
    "    SELECT \n",
    "        rs.child_id, \n",
    "        rs.video_id, \n",
    "        rs.age_at_recording,\n",
    "        f.frame_number\n",
    "    FROM RandomSubjects rs\n",
    "    JOIN (\n",
    "        -- Hier alle möglichen Frames pro Video bestimmen\n",
    "        SELECT video_id, frame_number\n",
    "        FROM Detections_with_speaker\n",
    "        GROUP BY video_id, frame_number\n",
    "    ) f ON rs.video_id = f.video_id\n",
    "),\n",
    "-- Ziehe zufällig 5000 Frames\n",
    "RandomFrames AS (\n",
    "    SELECT *\n",
    "    FROM AllFrames\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5000\n",
    ")\n",
    "SELECT \n",
    "    rf.video_id,\n",
    "    rf.frame_number,\n",
    "    rf.child_id,\n",
    "    rf.age_at_recording AS age,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 0 OR CAST(d.object_class AS INTEGER) = 2 THEN 1 ELSE 0 END, 0) AS child_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 1 OR CAST(d.object_class AS INTEGER) = 3 THEN 1 ELSE 0 END, 0) AS adult_present\n",
    "FROM RandomFrames rf\n",
    "LEFT JOIN Detections_with_speaker d\n",
    "    ON rf.video_id = d.video_id\n",
    "   AND rf.frame_number = d.frame_number\n",
    "WHERE d.object_class IN ('0', '1', '2', '3')  -- Only include child and adult classes\n",
    "ORDER BY rf.child_id, rf.video_id, rf.frame_number;\n",
    "\"\"\"\n",
    "\n",
    "def merge_duplicates_03(df):\n",
    "    grouped = df.groupby(['video_id', 'frame_number', 'child_id', 'age'])\n",
    "    merged_rows = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        child_present = group['child_present'].max()\n",
    "        adult_present = group['adult_present'].max()\n",
    "\n",
    "    for name, group in grouped:\n",
    "        merged_row = {\n",
    "            'video_id': name[0],\n",
    "            'frame_number': name[1],\n",
    "            'child_id': name[2],\n",
    "            'age': name[3],\n",
    "            'child_present': child_present,\n",
    "            'adult_present': adult_present\n",
    "        }\n",
    "\n",
    "        # generate person_age_class from child_present and adult_present\n",
    "        if child_present == 1 and adult_present == 1:\n",
    "            merged_row['person_age_class'] = 'both'\n",
    "        elif child_present == 1:\n",
    "            merged_row['person_age_class'] = 'child'\n",
    "        elif adult_present == 1:\n",
    "            merged_row['person_age_class'] = 'adult'\n",
    "        else:\n",
    "            merged_row['person_age_class'] = 'none'\n",
    "\n",
    "        merged_rows.append(merged_row)\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2882,\n",
       "    video_id  frame_number  child_id   age  child_present  adult_present  \\\n",
       " 0        15           270    264041  3.52              0              1   \n",
       " 1        15           550    264041  3.52              0              1   \n",
       " 2        15           990    264041  3.52              0              1   \n",
       " 3        15          1200    264041  3.52              0              1   \n",
       " 4        15          2070    264041  3.52              0              1   \n",
       " 5        15          2650    264041  3.52              0              1   \n",
       " 6        15          3600    264041  3.52              0              1   \n",
       " 7        15          3900    264041  3.52              0              1   \n",
       " 8        15          3980    264041  3.52              0              1   \n",
       " 9        15          4150    264041  3.52              0              1   \n",
       " \n",
       "   person_age_class  \n",
       " 0            adult  \n",
       " 1            adult  \n",
       " 2            adult  \n",
       " 3            adult  \n",
       " 4            adult  \n",
       " 5            adult  \n",
       " 6            adult  \n",
       " 7            adult  \n",
       " 8            adult  \n",
       " 9            adult  )"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with sqlite3.connect('/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db') as conn:\n",
    "    person_presence_03_df = pd.read_sql_query(query_03, conn)\n",
    "\n",
    "person_presence_03_df_merged = merge_duplicates_03(person_presence_03_df)\n",
    "person_presence_03_df_merged.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/person_presence_03_df.csv', index=False)\n",
    "\n",
    "len(person_presence_03_df_merged), person_presence_03_df_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How does the composition of social interactions change with age?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model <- interaction ~ age + (1|child_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_04 = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 40\n",
    "),\n",
    "-- Ziehe alle möglichen Frames aus den Videos der RandomSubjects\n",
    "AllFrames AS (\n",
    "    SELECT \n",
    "        rs.child_id, \n",
    "        rs.video_id, \n",
    "        rs.age_at_recording,\n",
    "        f.frame_number\n",
    "    FROM RandomSubjects rs\n",
    "    JOIN (\n",
    "        -- Hier alle möglichen Frames pro Video bestimmen\n",
    "        SELECT video_id, frame_number\n",
    "        FROM Detections_with_speaker\n",
    "        GROUP BY video_id, frame_number\n",
    "    ) f ON rs.video_id = f.video_id\n",
    "),\n",
    "-- Ziehe zufällig 5000 Frames\n",
    "RandomFrames AS (\n",
    "    SELECT *\n",
    "    FROM AllFrames\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5000\n",
    ")\n",
    "SELECT \n",
    "    rf.video_id,\n",
    "    rf.frame_number,\n",
    "    rf.child_id,\n",
    "    rf.age_at_recording AS age,\n",
    "    CASE \n",
    "        WHEN \n",
    "            COALESCE(CAST(d.object_class AS INTEGER), -1) IN (0, 1, 2, 3) -- person/face\n",
    "            AND ( -- check for any speech type\n",
    "                COALESCE(CAST(d.KCHI AS INTEGER), -1) = 1\n",
    "                OR COALESCE(CAST(d.FEM AS INTEGER), -1) = 1\n",
    "                OR COALESCE(CAST(d.MAL AS INTEGER), -1) = 1\n",
    "                OR COALESCE(CAST(d.CHI AS INTEGER), -1) = 1\n",
    "            )\n",
    "            THEN 'multimodal'\n",
    "        WHEN\n",
    "            COALESCE(CAST(d.object_class AS INTEGER), -1) NOT IN (0, 1, 2, 3) -- no person/face\n",
    "            AND ( -- check for any speech type\n",
    "                COALESCE(CAST(d.KCHI AS INTEGER), -1) = 1\n",
    "                OR COALESCE(CAST(d.FEM AS INTEGER), -1) = 1\n",
    "                OR COALESCE(CAST(d.MAL AS INTEGER), -1) = 1\n",
    "                OR COALESCE(CAST(d.CHI AS INTEGER), -1) = 1\n",
    "            )\n",
    "            THEN 'speech-only'\n",
    "        WHEN\n",
    "            COALESCE(CAST(d.object_class AS INTEGER), -1) IN (0, 1, 2, 3) -- person/face\n",
    "            AND COALESCE(CAST(d.KCHI AS INTEGER), -1) = 0 -- no KCHI\n",
    "            AND COALESCE(CAST(d.FEM AS INTEGER), -1) = 0 -- no FEM\n",
    "            AND COALESCE(CAST(d.MAL AS INTEGER), -1) = 0 -- no MAL\n",
    "            AND COALESCE(CAST(d.CHI AS INTEGER), -1) = 0 -- no CHI\n",
    "            THEN 'person-only'\n",
    "        ELSE 'none'\n",
    "    END AS interaction_type\n",
    "FROM RandomFrames rf\n",
    "LEFT JOIN Detections_with_speaker d\n",
    "    ON rf.video_id = d.video_id\n",
    "   AND rf.frame_number = d.frame_number -- Removed comma from here\n",
    "WHERE interaction_type IS NOT 'none'\n",
    "ORDER BY rf.child_id, rf.video_id, rf.frame_number;\n",
    "\"\"\"\n",
    "\n",
    "def merge_duplicates_04(df):\n",
    "    grouped = df.groupby(['video_id', 'frame_number', 'child_id', 'age'])\n",
    "    merged_rows = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        merged_row = {\n",
    "            'video_id': name[0],\n",
    "            'frame_number': name[1],\n",
    "            'child_id': name[2],\n",
    "            'age': name[3],\n",
    "        }\n",
    "\n",
    "        interaction_types_set = set(group['interaction_type'].unique())\n",
    "        \n",
    "        is_multimodal_present = 'multimodal' in interaction_types_set\n",
    "        is_speech_only_present = 'speech-only' in interaction_types_set\n",
    "        is_person_only_present = 'person-only' in interaction_types_set\n",
    "\n",
    "        if is_multimodal_present or (is_speech_only_present and is_person_only_present):\n",
    "            merged_row['interaction_type'] = 'multimodal'\n",
    "        elif is_speech_only_present:\n",
    "            merged_row['interaction_type'] = 'speech-only'\n",
    "        elif is_person_only_present:\n",
    "            merged_row['interaction_type'] = 'person-only'\n",
    "        else:\n",
    "            merged_row['interaction_type'] = 'none'\n",
    "\n",
    "        merged_rows.append(merged_row)\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428,\n",
       "    video_id  frame_number  child_id   age interaction_type\n",
       " 0         2            30    264089  3.69      person-only\n",
       " 1         2            40    264089  3.69       multimodal\n",
       " 2         2           290    264089  3.69       multimodal\n",
       " 3         2          1310    264089  3.69      person-only\n",
       " 4         2          1600    264089  3.69      person-only\n",
       " 5         2          1670    264089  3.69      person-only\n",
       " 6         2          1940    264089  3.69      person-only\n",
       " 7         2          2020    264089  3.69      person-only\n",
       " 8         2          2530    264089  3.69      person-only\n",
       " 9         2          2780    264089  3.69      person-only)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with sqlite3.connect('/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db') as conn:\n",
    "    interactions_04_df = pd.read_sql_query(query_04, conn)\n",
    "\n",
    "interactions_04_df_merged = merge_duplicates_04(interactions_04_df)\n",
    "interactions_04_df_merged.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/interactions_04_df.csv', index=False)\n",
    "\n",
    "len(interactions_04_df_merged), interactions_04_df_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. How does the frequency of toy use differ between solo and social play contexts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: toy_present ~ age * toy_class * social_context + (toy_class * social_context | child_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_05 = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    -- Select 10 random subjects\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 10\n",
    "),\n",
    "RandomFrames AS (\n",
    "    -- Select 5000 unique random frames TOTAL from the videos of the selected subjects.\n",
    "    SELECT DISTINCT d.frame_number, d.video_id -- DISTINCT here ensures we get unique frames before LIMIT\n",
    "    FROM Detections d -- This CTE still uses Detections for initial frame selection.\n",
    "    JOIN RandomSubjects rs ON d.video_id = rs.video_id\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5000\n",
    "),\n",
    "CombinedSocialPresence AS (\n",
    "    -- Determine if adult or child are present based on EITHER speech OR object detection\n",
    "    SELECT \n",
    "        rf.frame_number,\n",
    "        rf.video_id,\n",
    "        -- Adult presence: adult speech OR adult object/face\n",
    "        MAX(\n",
    "            CASE \n",
    "                WHEN COALESCE(d_spk.FEM, 0) = 1 THEN 1\n",
    "                WHEN COALESCE(d_spk.MAL, 0) = 1 THEN 1\n",
    "                WHEN d_obj_ctx.object_class = '1' THEN 1 -- Adult person object\n",
    "                WHEN d_obj_ctx.object_class = '3' THEN 1 -- Adult face object\n",
    "                ELSE 0 \n",
    "            END\n",
    "        ) as is_adult_present_any_mode,\n",
    "        -- Child presence: child speech OR child object/face\n",
    "        MAX(\n",
    "            CASE \n",
    "                WHEN COALESCE(d_spk.CHI, 0) = 1 THEN 1\n",
    "                WHEN d_obj_ctx.object_class = '0' THEN 1 -- Child person object\n",
    "                WHEN d_obj_ctx.object_class = '2' THEN 1 -- Child face object\n",
    "                ELSE 0 \n",
    "            END\n",
    "        ) as is_child_present_any_mode\n",
    "    FROM RandomFrames rf\n",
    "    LEFT JOIN Detections_with_speaker d_spk \n",
    "        ON rf.frame_number = d_spk.frame_number AND rf.video_id = d_spk.video_id\n",
    "    LEFT JOIN Detections d_obj_ctx -- For object-based context detection\n",
    "        ON rf.frame_number = d_obj_ctx.frame_number AND rf.video_id = d_obj_ctx.video_id\n",
    "           AND d_obj_ctx.object_class IN ('0', '1', '2', '3') -- Filter for person/face objects for context\n",
    "    GROUP BY rf.frame_number, rf.video_id\n",
    "),\n",
    "FinalSocialContext AS (\n",
    "    -- Assign social_context_val based on combined presence flags\n",
    "    SELECT\n",
    "        csp.frame_number,\n",
    "        csp.video_id,\n",
    "        CASE\n",
    "            WHEN csp.is_adult_present_any_mode = 1 AND csp.is_child_present_any_mode = 1 THEN 'with adult and child'\n",
    "            WHEN csp.is_adult_present_any_mode = 1 THEN 'with adult'\n",
    "            WHEN csp.is_child_present_any_mode = 1 THEN 'with child'\n",
    "            ELSE 'alone'\n",
    "        END as social_context_val\n",
    "    FROM CombinedSocialPresence csp\n",
    "),\n",
    "FrameToyInfo AS (\n",
    "    -- Determine the toy_class and toy_present for each frame\n",
    "    SELECT\n",
    "        rf.frame_number,\n",
    "        rf.video_id,\n",
    "        CASE\n",
    "            WHEN COUNT(DISTINCT d_obj.object_class) = 1 THEN MAX(d_obj.object_class) -- If only one distinct toy type (5-10) is present\n",
    "            WHEN COUNT(DISTINCT d_obj.object_class) > 1 THEN 'multiple'       -- If multiple distinct toy types (5-10) are present\n",
    "            ELSE 'none'                                                  -- If no toy types (5-10) are present\n",
    "        END as determined_toy_class,\n",
    "        CASE\n",
    "            WHEN COUNT(DISTINCT d_obj.object_class) > 0 THEN 1 -- If any toy object ('5'-'10') is present\n",
    "            ELSE 0\n",
    "        END as is_toy_present\n",
    "    FROM RandomFrames rf\n",
    "    LEFT JOIN Detections d_obj -- Using Detections table for object classes (toys)\n",
    "        ON rf.frame_number = d_obj.frame_number\n",
    "        AND rf.video_id = d_obj.video_id\n",
    "        AND d_obj.object_class IN ('5', '6', '7', '8', '9', '10') -- Only consider these specific object classes for toys\n",
    "    GROUP BY rf.frame_number, rf.video_id\n",
    ")\n",
    "-- Final selection of columns for the model\n",
    "SELECT\n",
    "    rf.video_id,\n",
    "    rf.frame_number AS frame_id,\n",
    "    rs.child_id,\n",
    "    rs.age_at_recording AS age,\n",
    "    fti.determined_toy_class AS toy_class, \n",
    "    fsc.social_context_val AS social_context,\n",
    "    fti.is_toy_present AS toy_present -- Added toy_present column\n",
    "FROM \n",
    "    RandomFrames rf\n",
    "    JOIN RandomSubjects rs ON rf.video_id = rs.video_id\n",
    "    LEFT JOIN FinalSocialContext fsc ON rf.frame_number = fsc.frame_number AND rf.video_id = fsc.video_id\n",
    "    LEFT JOIN FrameToyInfo fti ON rf.frame_number = fti.frame_number AND rf.video_id = fti.video_id\n",
    "ORDER BY \n",
    "    rs.child_id, rf.video_id, rf.frame_number;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with sqlite3.connect('/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db') as conn:\n",
    "    toys_05_df = pd.read_sql_query(query_05, conn)\n",
    "\n",
    "toys_05_df.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/toys_05_df.csv', index=False)\n",
    "\n",
    "len(toys_05_df), toys_05_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
