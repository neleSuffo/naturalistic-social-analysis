{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add audio results to output.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pkl file\n",
    "quantex_results = pd.read_pickle(\"/home/nele_pauline_suffo/outputs/vtc/quantex_df.pkl\")\n",
    "# remove _16khz from audio_file_name \n",
    "quantex_results['audio_file_name'] = quantex_results['audio_file_name'].str.replace('_16kHz', '', regex=False)\n",
    "\n",
    "#quantex_results = df[0:10]\n",
    "\n",
    "# Load frame-wise detection results and video info from the database\n",
    "db_path = '/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db'\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    frame_df = pd.read_sql_query(\"SELECT * FROM Detections\", conn)\n",
    "    videos_info_df = pd.read_sql_query(\"SELECT video_id, video_path FROM Videos\", conn)\n",
    "\n",
    "# Merge video_id into quantex_results\n",
    "quantex_results = pd.merge(quantex_results, videos_info_df[['video_id', 'video_path']], left_on='audio_file_name', right_on='video_path', how='left')\n",
    "\n",
    "# Map RTTM annotations to frames\n",
    "fps = 30  # Assuming a frame rate of 30 FPS\n",
    "\n",
    "# Initialize new columns for speaker types in frame_df\n",
    "speaker_types = ['KCHI', 'FEM', 'MAL', 'CHI']  # Define target speaker type columns\n",
    "for speaker_col in speaker_types:\n",
    "    frame_df[speaker_col] = 0\n",
    "\n",
    "# Assign speaker annotations to frames for KCHI, CDS, OHS\n",
    "if not quantex_results.empty:  # Proceed only if quantex_results has data after merge\n",
    "    for _, rttm_row in quantex_results.iterrows():\n",
    "        rttm_video_id = rttm_row['video_id']\n",
    "        speaker_label_from_rttm = rttm_row['Voice_type']  # Label from RTTM 'Speaker' column\n",
    "        utterance_start_time = rttm_row['Utterance_Start']\n",
    "        utterance_end_time = rttm_row['Utterance_End']\n",
    "\n",
    "        # Determine which speaker type column to update\n",
    "        if speaker_label_from_rttm not in speaker_types:\n",
    "            continue  # Skip unknown speaker types\n",
    "\n",
    "        # Convert time to frame numbers (inclusive)\n",
    "        start_frame = int(utterance_start_time * fps)\n",
    "        end_frame = int(utterance_end_time * fps)\n",
    "\n",
    "        #print(f\"Convert {utterance_start_time} - {utterance_end_time} for video {rttm_video_id} with speaker type {speaker_label_from_rttm} to {start_frame} - {end_frame}\")\n",
    "\n",
    "        # Set the speaker label to 1 for all frames in range\n",
    "        frame_mask = (\n",
    "            (frame_df['video_id'] == rttm_video_id) &\n",
    "            (frame_df['frame_number'] >= start_frame) &\n",
    "            (frame_df['frame_number'] <= end_frame)\n",
    "        )\n",
    "        frame_df.loc[frame_mask, speaker_label_from_rttm] = 1\n",
    "\n",
    "# To view the first few rows of the modified frame_df:\n",
    "# print(\"Modified frame_df head:\")\n",
    "# print(frame_df.head())\n",
    "\n",
    "# To view rows where speaker types are active:\n",
    "# print(\"\\nFrames with speaker activity:\")\n",
    "# print(frame_df[(frame_df['KCHI'] == 1) | (frame_df['CDS'] == 1) | (frame_df['OHS'] == 1)].head())\n",
    "\n",
    "#Save the updated frame-wise detection results back to the database (optional)\n",
    "db_path = '/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db'\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Save the new table\n",
    "    frame_df.to_sql('Detections_with_speaker', conn, if_exists='replace', index=False)\n",
    "\n",
    "    # List all tables to confirm it's there\n",
    "    tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "    print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How many utterances does the key child produce?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# show all columns in pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_01 = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 40\n",
    "),\n",
    "-- Ziehe alle möglichen Frames aus den Videos der RandomSubjects\n",
    "AllFrames AS (\n",
    "    SELECT \n",
    "        rs.child_id, \n",
    "        rs.video_id, \n",
    "        rs.age_at_recording,\n",
    "        f.frame_number\n",
    "    FROM RandomSubjects rs\n",
    "    JOIN (\n",
    "        -- Hier alle möglichen Frames pro Video bestimmen\n",
    "        SELECT video_id, frame_number\n",
    "        FROM Detections_with_speaker\n",
    "        GROUP BY video_id, frame_number\n",
    "    ) f ON rs.video_id = f.video_id\n",
    "),\n",
    "-- Ziehe zufällig 5000 Frames\n",
    "RandomFrames AS (\n",
    "    SELECT *\n",
    "    FROM AllFrames\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5000\n",
    ")\n",
    "SELECT \n",
    "    rf.video_id,\n",
    "    rf.frame_number,\n",
    "    rf.child_id,\n",
    "    rf.age_at_recording AS age,\n",
    "    d.proximity,\n",
    "    CASE\n",
    "        WHEN CAST(d.object_class AS INTEGER) >= 5 AND CAST(d.object_class AS INTEGER) <= 10 THEN d.object_class\n",
    "        ELSE 'none'\n",
    "    END AS object_class,\n",
    "    COALESCE(d.gaze_direction, 'none') AS gaze_direction,\n",
    "    COALESCE(d.KCHI, 0) AS kchi_present,\n",
    "    COALESCE(CASE WHEN d.FEM = 1 OR d.CHI = 1 OR d.MAL = 1 THEN 1 ELSE 0 END, 0) AS cds_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 2 OR CAST(d.object_class AS INTEGER) = 3 THEN 1 ELSE 0 END, 0) AS face_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 0 THEN 1 ELSE 0 END, 0) AS child_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 1 THEN 1 ELSE 0 END, 0) AS adult_present,\n",
    "    CASE \n",
    "        WHEN \n",
    "            COALESCE(d.FEM, 0) = 1 OR COALESCE(d.CHI, 0) = 1 OR COALESCE(d.MAL, 0) = 1\n",
    "            OR COALESCE(d.proximity, 0) > 0.5\n",
    "            OR COALESCE(CAST(d.object_class AS INTEGER), -1) = 0\n",
    "            OR COALESCE(CAST(d.object_class AS INTEGER), -1) = 1\n",
    "            THEN 'social'\n",
    "        ELSE 'alone'\n",
    "    END AS play_context,\n",
    "    CASE \n",
    "        WHEN COALESCE(CAST(d.object_class AS INTEGER), -1) = 1 THEN 'adult'\n",
    "        WHEN COALESCE(CAST(d.object_class AS INTEGER), -1) = 0 THEN 'child'\n",
    "        ELSE 'none'\n",
    "    END AS person_age_class\n",
    "FROM RandomFrames rf\n",
    "LEFT JOIN Detections_with_speaker d\n",
    "    ON rf.video_id = d.video_id\n",
    "   AND rf.frame_number = d.frame_number\n",
    "ORDER BY rf.child_id, rf.video_id, rf.frame_number;\n",
    "\"\"\"\n",
    "\n",
    "def merge_duplicates_01(df):\n",
    "    # Mapping for object_class\n",
    "    object_class_map = {\n",
    "        '5': 'book',\n",
    "        '6': 'toy',\n",
    "        '7': 'kitchenware',\n",
    "        '8': 'screen',\n",
    "        '9': 'food',\n",
    "        '10': 'other object'\n",
    "    }\n",
    "\n",
    "    grouped = df.groupby(['video_id', 'frame_number', 'child_id', 'age'])\n",
    "    merged_rows = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        merged_row = {\n",
    "            'video_id': name[0],\n",
    "            'frame_number': name[1],\n",
    "            'child_id': name[2],\n",
    "            'age': name[3],\n",
    "            'kchi_present': int(group['kchi_present'].any()),\n",
    "            'cds_present': int(group['cds_present'].any()),\n",
    "            'face_present': int(group['face_present'].any()),\n",
    "            'child_present': int(group['child_present'].any()),\n",
    "            'adult_present': int(group['adult_present'].any()),\n",
    "            'play_context': (\n",
    "                'social' if 'social' in group['play_context'].values\n",
    "                else 'alone' if all(pc == 'alone' for pc in group['play_context'].values)\n",
    "                else 'none'\n",
    "            )\n",
    "        }\n",
    "\n",
    "        # --- object_class: only one column, mapping, 'multiple' if >1 ---\n",
    "        raw_object_classes = [str(v) for v in group['object_class'].unique() if v not in ('none', 'NaN')]\n",
    "        mapped_object_classes = [object_class_map.get(oc, oc) for oc in raw_object_classes]\n",
    "        mapped_object_classes = [oc for oc in mapped_object_classes if oc not in ('none', 'NaN')]\n",
    "        if len(mapped_object_classes) == 1:\n",
    "            merged_row['object_class'] = mapped_object_classes[0]\n",
    "        elif len(mapped_object_classes) > 1:\n",
    "            merged_row['object_class'] = 'multiple'\n",
    "        else:\n",
    "            merged_row['object_class'] = 'none'\n",
    "\n",
    "        # --- person_age_class logic ---\n",
    "        pac_set = set(v for v in group['person_age_class'].unique() if v not in ('none', 'NaN'))\n",
    "        if pac_set == {'child'}:\n",
    "            merged_row['person_age_class'] = 'child'\n",
    "        elif pac_set == {'adult'}:\n",
    "            merged_row['person_age_class'] = 'adult'\n",
    "        elif pac_set == {'child', 'adult'}:\n",
    "            merged_row['person_age_class'] = 'both'\n",
    "        else:\n",
    "            merged_row['person_age_class'] = 'none'\n",
    "\n",
    "        # --- proximity and gaze_direction: take max proximity and corresponding gaze ---\n",
    "        proximities = pd.to_numeric(group['proximity'], errors='coerce').fillna(-1)\n",
    "        if not proximities.empty and proximities.max() >= 0:\n",
    "            max_prox_idx = proximities.idxmax()\n",
    "            max_prox_value = proximities.loc[max_prox_idx]\n",
    "            merged_row['proximity'] = max_prox_value\n",
    "            gaze_value = group.loc[max_prox_idx, 'gaze_direction']\n",
    "            if gaze_value in ('none', 'NaN', None):\n",
    "                gaze_value = 'none'\n",
    "            merged_row['gaze_direction'] = gaze_value\n",
    "        else:\n",
    "            merged_row['proximity'] = None\n",
    "            merged_row['gaze_direction'] = 'none'\n",
    "\n",
    "        merged_rows.append(merged_row)\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>child_id</th>\n",
       "      <th>age</th>\n",
       "      <th>kchi_present</th>\n",
       "      <th>cds_present</th>\n",
       "      <th>face_present</th>\n",
       "      <th>child_present</th>\n",
       "      <th>adult_present</th>\n",
       "      <th>play_context</th>\n",
       "      <th>object_class</th>\n",
       "      <th>person_age_class</th>\n",
       "      <th>proximity</th>\n",
       "      <th>gaze_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alone</td>\n",
       "      <td>multiple</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>490</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alone</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1190</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>social</td>\n",
       "      <td>none</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.290025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1200</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>social</td>\n",
       "      <td>other object</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.301284</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1370</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alone</td>\n",
       "      <td>other object</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>1460</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alone</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>1550</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alone</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>social</td>\n",
       "      <td>none</td>\n",
       "      <td>adult</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>2150</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>social</td>\n",
       "      <td>none</td>\n",
       "      <td>adult</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>2270</td>\n",
       "      <td>263284</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>social</td>\n",
       "      <td>none</td>\n",
       "      <td>adult</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  frame_number  child_id  age  kchi_present  cds_present  \\\n",
       "0        11           100    263284  3.8             0            0   \n",
       "1        11           490    263284  3.8             0            0   \n",
       "2        11          1190    263284  3.8             0            0   \n",
       "3        11          1200    263284  3.8             0            0   \n",
       "4        11          1370    263284  3.8             0            0   \n",
       "5        11          1460    263284  3.8             0            0   \n",
       "6        11          1550    263284  3.8             0            0   \n",
       "7        11          2140    263284  3.8             1            0   \n",
       "8        11          2150    263284  3.8             1            0   \n",
       "9        11          2270    263284  3.8             0            0   \n",
       "\n",
       "   face_present  child_present  adult_present play_context  object_class  \\\n",
       "0             0              0              0        alone      multiple   \n",
       "1             0              0              0        alone          none   \n",
       "2             1              0              1       social          none   \n",
       "3             1              0              1       social  other object   \n",
       "4             0              0              0        alone  other object   \n",
       "5             0              0              0        alone          none   \n",
       "6             0              0              0        alone          none   \n",
       "7             1              0              1       social          none   \n",
       "8             0              0              1       social          none   \n",
       "9             0              0              1       social          none   \n",
       "\n",
       "  person_age_class  proximity gaze_direction  \n",
       "0             none        NaN           none  \n",
       "1             none        NaN           none  \n",
       "2            adult   0.290025            1.0  \n",
       "3            adult   0.301284            1.0  \n",
       "4             none        NaN           none  \n",
       "5             none        NaN           none  \n",
       "6             none        NaN           none  \n",
       "7            adult   1.000000            1.0  \n",
       "8            adult        NaN           none  \n",
       "9            adult        NaN           none  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with sqlite3.connect('/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db') as conn:\n",
    "    utterance_01_df = pd.read_sql_query(query_01, conn)\n",
    "\n",
    "utterance_01_df_merged = merge_duplicates_01(utterance_01_df)\n",
    "utterance_01_df_merged.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/utterance_01_df.csv', index=False)\n",
    "\n",
    "utterance_01_df_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) alone vs. social: kchi_present ~ age * context + (context|child_id) with context being a factor with levels „social“ and „alone“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       "    video_id  frame_number  child_id  kchi_present  age play_context\n",
       " 0        11           100    263284             0  3.8        alone\n",
       " 1        11           490    263284             0  3.8        alone\n",
       " 2        11          1190    263284             0  3.8       social\n",
       " 3        11          1200    263284             0  3.8       social\n",
       " 4        11          1370    263284             0  3.8        alone\n",
       " 5        11          1460    263284             0  3.8        alone\n",
       " 6        11          1550    263284             0  3.8        alone\n",
       " 7        11          2140    263284             1  3.8       social\n",
       " 8        11          2150    263284             1  3.8       social\n",
       " 9        11          2270    263284             0  3.8       social)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_01a_df = utterance_01_df_merged[['video_id', 'frame_number', 'child_id', 'kchi_present', 'age', 'play_context']]\n",
    "utterance_01a_df.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/utterance_01a_df.csv', index=False)\n",
    "len(utterance_01a_df), utterance_01a_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) only alone data: kchi_present ~ age*object + (object | child_id) see if predictor object makes a difference, with object being a factor with levels „toy“, „book“, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2197,\n",
       "     video_id  frame_number  child_id  kchi_present  age  object_class\n",
       " 0         11           100    263284             0  3.8      multiple\n",
       " 1         11           490    263284             0  3.8          none\n",
       " 4         11          1370    263284             0  3.8  other object\n",
       " 5         11          1460    263284             0  3.8          none\n",
       " 6         11          1550    263284             0  3.8          none\n",
       " 11        11          3030    263284             0  3.8      multiple\n",
       " 13        11          3080    263284             0  3.8           toy\n",
       " 14        11          4110    263284             0  3.8          none\n",
       " 16        11          4500    263284             0  3.8          none\n",
       " 17        11          5120    263284             0  3.8           toy)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_01b_df = utterance_01_df_merged[utterance_01_df_merged['play_context'] == 'alone']\n",
    "utterance_01b_df = utterance_01b_df[['video_id', 'frame_number', 'child_id', 'kchi_present', 'age', 'object_class']]\n",
    "utterance_01b_df.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/utterance_01b_df.csv', index=False)\n",
    "len(utterance_01b_df), utterance_01b_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) only social data: kchi_present ~ age * age_class * face * gaze + (age_class * face * gaze|child_id) see if type of social interaction makes a differences, that is the age class of the other person, whether there is a face and whether there is gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2803,\n",
       "     video_id  frame_number  child_id  kchi_present  age  face_present  \\\n",
       " 2         11          1190    263284             0  3.8             1   \n",
       " 3         11          1200    263284             0  3.8             1   \n",
       " 7         11          2140    263284             1  3.8             1   \n",
       " 8         11          2150    263284             1  3.8             0   \n",
       " 9         11          2270    263284             0  3.8             0   \n",
       " 10        11          2640    263284             1  3.8             0   \n",
       " 12        11          3070    263284             0  3.8             1   \n",
       " 15        11          4370    263284             0  3.8             0   \n",
       " 18        11          5450    263284             1  3.8             1   \n",
       " 20        11          7030    263284             1  3.8             0   \n",
       " \n",
       "    person_age_class gaze_direction  \n",
       " 2             adult            1.0  \n",
       " 3             adult            1.0  \n",
       " 7             adult            1.0  \n",
       " 8             adult           none  \n",
       " 9             adult           none  \n",
       " 10            adult           none  \n",
       " 12             none            1.0  \n",
       " 15            adult           none  \n",
       " 18            adult            0.0  \n",
       " 20             none           none  )"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_01c_df = utterance_01_df_merged[utterance_01_df_merged['play_context'] == 'social']\n",
    "utterance_01c_df = utterance_01c_df[['video_id', 'frame_number', 'child_id', 'kchi_present', 'age', 'face_present', 'person_age_class', 'gaze_direction']]\n",
    "utterance_01c_df.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/utterance_01c_df.csv', index=False)\n",
    "len(utterance_01c_df), utterance_01c_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How much speech is directed at the key child?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_02 = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 40\n",
    "),\n",
    "-- Ziehe alle möglichen Frames aus den Videos der RandomSubjects\n",
    "AllFrames AS (\n",
    "    SELECT \n",
    "        rs.child_id, \n",
    "        rs.video_id, \n",
    "        rs.age_at_recording,\n",
    "        f.frame_number\n",
    "    FROM RandomSubjects rs\n",
    "    JOIN (\n",
    "        -- Hier alle möglichen Frames pro Video bestimmen\n",
    "        SELECT video_id, frame_number\n",
    "        FROM Detections_with_speaker\n",
    "        GROUP BY video_id, frame_number\n",
    "    ) f ON rs.video_id = f.video_id\n",
    "),\n",
    "-- Ziehe zufällig 5000 Frames\n",
    "RandomFrames AS (\n",
    "    SELECT *\n",
    "    FROM AllFrames\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5000\n",
    ")\n",
    "SELECT \n",
    "    rf.video_id,\n",
    "    rf.frame_number,\n",
    "    rf.child_id,\n",
    "    rf.age_at_recording AS age,\n",
    "    d.proximity,\n",
    "    COALESCE(d.gaze_direction, 'none') AS gaze_direction,\n",
    "    COALESCE(CASE WHEN d.FEM = 1 OR d.CHI = 1 OR d.MAL = 1 THEN 1 ELSE 0 END, 0) AS cds_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 2 OR CAST(d.object_class AS INTEGER) = 3 THEN 1 ELSE 0 END, 0) AS face_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 0 THEN 1 ELSE 0 END, 0) AS child_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 1 THEN 1 ELSE 0 END, 0) AS adult_present,\n",
    "    CASE \n",
    "        WHEN COALESCE(CAST(d.object_class AS INTEGER), -1) = 1 THEN 'adult'\n",
    "        WHEN COALESCE(CAST(d.object_class AS INTEGER), -1) = 0 THEN 'child'\n",
    "        ELSE 'none'\n",
    "    END AS person_age_class\n",
    "FROM RandomFrames rf\n",
    "LEFT JOIN Detections_with_speaker d\n",
    "    ON rf.video_id = d.video_id\n",
    "   AND rf.frame_number = d.frame_number\n",
    "ORDER BY rf.child_id, rf.video_id, rf.frame_number;\n",
    "\"\"\"\n",
    "\n",
    "def merge_duplicates_02(df):\n",
    "    grouped = df.groupby(['video_id', 'frame_number', 'child_id', 'age'])\n",
    "    merged_rows = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        merged_row = {\n",
    "            'video_id': name[0],\n",
    "            'frame_number': name[1],\n",
    "            'child_id': name[2],\n",
    "            'age': name[3],\n",
    "            'cds_present': int(group['cds_present'].any()),\n",
    "            'face_present': int(group['face_present'].any()),\n",
    "            'child_present': int(group['child_present'].any()),\n",
    "            'adult_present': int(group['adult_present'].any()),\n",
    "        }\n",
    "\n",
    "        # --- person_age_class logic ---\n",
    "        pac_set = set(v for v in group['person_age_class'].unique() if v not in ('none', 'NaN'))\n",
    "        if pac_set == {'child'}:\n",
    "            merged_row['person_age_class'] = 'child'\n",
    "        elif pac_set == {'adult'}:\n",
    "            merged_row['person_age_class'] = 'adult'\n",
    "        elif pac_set == {'child', 'adult'}:\n",
    "            merged_row['person_age_class'] = 'both'\n",
    "        else:\n",
    "            merged_row['person_age_class'] = 'none'\n",
    "\n",
    "        # --- proximity and gaze_direction: take max proximity and corresponding gaze ---\n",
    "        proximities = pd.to_numeric(group['proximity'], errors='coerce').fillna(-1)\n",
    "        if not proximities.empty and proximities.max() >= 0:\n",
    "            max_prox_idx = proximities.idxmax()\n",
    "            max_prox_value = proximities.loc[max_prox_idx]\n",
    "            merged_row['proximity'] = max_prox_value\n",
    "            gaze_value = group.loc[max_prox_idx, 'gaze_direction']\n",
    "            if gaze_value in ('none', 'NaN', None):\n",
    "                gaze_value = 'none'\n",
    "            merged_row['gaze_direction'] = gaze_value\n",
    "        else:\n",
    "            merged_row['proximity'] = None\n",
    "            merged_row['gaze_direction'] = 'none'\n",
    "\n",
    "        merged_rows.append(merged_row)\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cds_present ~ age * age_class * face * gaze * proximity + (age_class * face * gaze|child_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>child_id</th>\n",
       "      <th>age</th>\n",
       "      <th>cds_present</th>\n",
       "      <th>face_present</th>\n",
       "      <th>child_present</th>\n",
       "      <th>adult_present</th>\n",
       "      <th>person_age_class</th>\n",
       "      <th>proximity</th>\n",
       "      <th>gaze_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>490</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>840</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>850</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1060</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1440</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1710</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1930</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2610</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>4110</td>\n",
       "      <td>263190</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  frame_number  child_id   age  cds_present  face_present  \\\n",
       "0         3           490    263190  3.73            1             0   \n",
       "1         3           840    263190  3.73            0             0   \n",
       "2         3           850    263190  3.73            0             0   \n",
       "3         3          1060    263190  3.73            0             0   \n",
       "4         3          1440    263190  3.73            0             0   \n",
       "5         3          1710    263190  3.73            0             0   \n",
       "6         3          1930    263190  3.73            0             0   \n",
       "7         3          2000    263190  3.73            0             0   \n",
       "8         3          2610    263190  3.73            0             0   \n",
       "9         3          4110    263190  3.73            0             0   \n",
       "\n",
       "   child_present  adult_present person_age_class  proximity gaze_direction  \n",
       "0              0              0             none        NaN           none  \n",
       "1              0              0             none        NaN           none  \n",
       "2              0              0             none        NaN           none  \n",
       "3              0              0             none        NaN           none  \n",
       "4              0              0             none        NaN           none  \n",
       "5              0              0             none        NaN           none  \n",
       "6              0              0             none        NaN           none  \n",
       "7              0              0             none        NaN           none  \n",
       "8              0              0             none        NaN           none  \n",
       "9              0              0             none        NaN           none  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with sqlite3.connect('/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db') as conn:\n",
    "    utterance_02_df = pd.read_sql_query(query_02, conn)\n",
    "\n",
    "utterance_02_df_merged = merge_duplicates_02(utterance_02_df)\n",
    "utterance_02_df_merged.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/utterance_02_df.csv', index=False)\n",
    "\n",
    "utterance_02_df_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Are children more frequently in the presence of adults compared to other children?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_03 = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 40\n",
    "),\n",
    "-- Ziehe alle möglichen Frames aus den Videos der RandomSubjects\n",
    "AllFrames AS (\n",
    "    SELECT \n",
    "        rs.child_id, \n",
    "        rs.video_id, \n",
    "        rs.age_at_recording,\n",
    "        f.frame_number\n",
    "    FROM RandomSubjects rs\n",
    "    JOIN (\n",
    "        -- Hier alle möglichen Frames pro Video bestimmen\n",
    "        SELECT video_id, frame_number\n",
    "        FROM Detections_with_speaker\n",
    "        GROUP BY video_id, frame_number\n",
    "    ) f ON rs.video_id = f.video_id\n",
    "),\n",
    "-- Ziehe zufällig 5000 Frames\n",
    "RandomFrames AS (\n",
    "    SELECT *\n",
    "    FROM AllFrames\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5000\n",
    ")\n",
    "SELECT \n",
    "    rf.video_id,\n",
    "    rf.frame_number,\n",
    "    rf.child_id,\n",
    "    rf.age_at_recording AS age,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 0 OR CAST(d.object_class AS INTEGER) = 2 THEN 1 ELSE 0 END, 0) AS child_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 1 OR CAST(d.object_class AS INTEGER) = 3 THEN 1 ELSE 0 END, 0) AS adult_present\n",
    "FROM RandomFrames rf\n",
    "LEFT JOIN Detections_with_speaker d\n",
    "    ON rf.video_id = d.video_id\n",
    "   AND rf.frame_number = d.frame_number\n",
    "WHERE d.object_class IN ('0', '1', '2', '3')  -- Only include child and adult classes\n",
    "ORDER BY rf.child_id, rf.video_id, rf.frame_number;\n",
    "\"\"\"\n",
    "\n",
    "def merge_duplicates_03(df):\n",
    "    grouped = df.groupby(['video_id', 'frame_number', 'child_id', 'age'])\n",
    "    merged_rows = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        child_present = group['child_present'].max()\n",
    "        adult_present = group['adult_present'].max()\n",
    "\n",
    "        merged_row = {\n",
    "            'video_id': name[0],\n",
    "            'frame_number': name[1],\n",
    "            'child_id': name[2],\n",
    "            'age': name[3],\n",
    "            'child_present': child_present,\n",
    "            'adult_present': adult_present,\n",
    "        }\n",
    "\n",
    "        # generate person_age_class from child_present and adult_present\n",
    "        if child_present == 1 and adult_present == 1:\n",
    "            merged_row['person_age_class'] = 'both'\n",
    "        elif child_present == 1:\n",
    "            merged_row['person_age_class'] = 'child'\n",
    "        elif adult_present == 1:\n",
    "            merged_row['person_age_class'] = 'adult'\n",
    "        else:\n",
    "            merged_row['person_age_class'] = 'none'\n",
    "\n",
    "        merged_rows.append(merged_row)\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2727,\n",
       "    video_id  frame_number  child_id   age  child_present  adult_present  \\\n",
       " 0         4            40    257511  3.84              0              1   \n",
       " 1         4          1400    257511  3.84              0              1   \n",
       " 2         4          5330    257511  3.84              1              0   \n",
       " 3         4          5340    257511  3.84              1              0   \n",
       " 4         4          5930    257511  3.84              1              0   \n",
       " 5         4          6050    257511  3.84              1              0   \n",
       " 6         4          6180    257511  3.84              1              0   \n",
       " 7         4          6290    257511  3.84              1              0   \n",
       " 8         4          6510    257511  3.84              1              0   \n",
       " 9         4          6680    257511  3.84              1              0   \n",
       " \n",
       "   person_age_class  \n",
       " 0            adult  \n",
       " 1            adult  \n",
       " 2            child  \n",
       " 3            child  \n",
       " 4            child  \n",
       " 5            child  \n",
       " 6            child  \n",
       " 7            child  \n",
       " 8            child  \n",
       " 9            child  )"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with sqlite3.connect('/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db') as conn:\n",
    "    person_presence_03_df = pd.read_sql_query(query_03, conn)\n",
    "\n",
    "person_presence_03_df_merged = merge_duplicates_03(person_presence_03_df)\n",
    "person_presence_03_df_merged.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/person_presence_03_df.csv', index=False)\n",
    "\n",
    "len(person_presence_03_df_merged), person_presence_03_df_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How does the composition of social interactions change with age?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model <- interaction ~ age + (1|child_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_04 = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 40\n",
    "),\n",
    "-- Ziehe alle möglichen Frames aus den Videos der RandomSubjects\n",
    "AllFrames AS (\n",
    "    SELECT \n",
    "        rs.child_id, \n",
    "        rs.video_id, \n",
    "        rs.age_at_recording,\n",
    "        f.frame_number\n",
    "    FROM RandomSubjects rs\n",
    "    JOIN (\n",
    "        -- Hier alle möglichen Frames pro Video bestimmen\n",
    "        SELECT video_id, frame_number\n",
    "        FROM Detections_with_speaker\n",
    "        GROUP BY video_id, frame_number\n",
    "    ) f ON rs.video_id = f.video_id\n",
    "),\n",
    "-- Ziehe zufällig 5000 Frames\n",
    "RandomFrames AS (\n",
    "    SELECT *\n",
    "    FROM AllFrames\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 5000\n",
    ")\n",
    "SELECT \n",
    "    rf.video_id,\n",
    "    rf.frame_number,\n",
    "    rf.child_id,\n",
    "    rf.age_at_recording AS age,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 0 OR CAST(d.object_class AS INTEGER) = 2 THEN 1 ELSE 0 END, 0) AS child_present,\n",
    "    COALESCE(CASE WHEN CAST(d.object_class AS INTEGER) = 1 OR CAST(d.object_class AS INTEGER) = 3 THEN 1 ELSE 0 END, 0) AS adult_present\n",
    "FROM RandomFrames rf\n",
    "LEFT JOIN Detections_with_speaker d\n",
    "    ON rf.video_id = d.video_id\n",
    "   AND rf.frame_number = d.frame_number\n",
    "WHERE d.object_class IN ('0', '1', '2', '3')  -- Only include child and adult classes\n",
    "ORDER BY rf.child_id, rf.video_id, rf.frame_number;\n",
    "\"\"\"\n",
    "\n",
    "def merge_duplicates_04(df):\n",
    "    grouped = df.groupby(['video_id', 'frame_number', 'child_id', 'age'])\n",
    "    merged_rows = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        child_present = group['child_present'].max()\n",
    "        adult_present = group['adult_present'].max()\n",
    "\n",
    "        merged_row = {\n",
    "            'video_id': name[0],\n",
    "            'frame_number': name[1],\n",
    "            'child_id': name[2],\n",
    "            'age': name[3],\n",
    "            'child_present': child_present,\n",
    "            'adult_present': adult_present,\n",
    "        }\n",
    "\n",
    "        # generate person_age_class from child_present and adult_present\n",
    "        if child_present == 1 and adult_present == 1:\n",
    "            merged_row['person_age_class'] = 'both'\n",
    "        elif child_present == 1:\n",
    "            merged_row['person_age_class'] = 'child'\n",
    "        elif adult_present == 1:\n",
    "            merged_row['person_age_class'] = 'adult'\n",
    "        else:\n",
    "            merged_row['person_age_class'] = 'none'\n",
    "\n",
    "        merged_rows.append(merged_row)\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. How does the frequency of toy use differ between solo and social play contexts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (3000, 7)\n",
      "\n",
      "Number of unique subjects: 10\n",
      "\n",
      "Variable types:\n",
      "video_id             int64\n",
      "frame_id             int64\n",
      "ID                category\n",
      "object_present       int64\n",
      "object_type       category\n",
      "age                float64\n",
      "social            category\n",
      "dtype: object\n",
      "\n",
      "Sample data (showing first 12 rows to see multiple object types per frame):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>object_present</th>\n",
       "      <th>object_type</th>\n",
       "      <th>age</th>\n",
       "      <th>social</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>330</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>book</td>\n",
       "      <td>4.25</td>\n",
       "      <td>adult present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>330</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>food</td>\n",
       "      <td>4.25</td>\n",
       "      <td>adult present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>330</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>kitchenware</td>\n",
       "      <td>4.25</td>\n",
       "      <td>adult present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151</td>\n",
       "      <td>330</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>other_object</td>\n",
       "      <td>4.25</td>\n",
       "      <td>adult present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>330</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>screen</td>\n",
       "      <td>4.25</td>\n",
       "      <td>adult present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151</td>\n",
       "      <td>330</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>toy</td>\n",
       "      <td>4.25</td>\n",
       "      <td>adult present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>151</td>\n",
       "      <td>1920</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>book</td>\n",
       "      <td>4.25</td>\n",
       "      <td>child present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>151</td>\n",
       "      <td>1920</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>food</td>\n",
       "      <td>4.25</td>\n",
       "      <td>child present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151</td>\n",
       "      <td>1920</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>kitchenware</td>\n",
       "      <td>4.25</td>\n",
       "      <td>child present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151</td>\n",
       "      <td>1920</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>other_object</td>\n",
       "      <td>4.25</td>\n",
       "      <td>child present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>151</td>\n",
       "      <td>1920</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>screen</td>\n",
       "      <td>4.25</td>\n",
       "      <td>child present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>151</td>\n",
       "      <td>1920</td>\n",
       "      <td>257108</td>\n",
       "      <td>0</td>\n",
       "      <td>toy</td>\n",
       "      <td>4.25</td>\n",
       "      <td>child present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    video_id  frame_id      ID  object_present   object_type   age  \\\n",
       "0        151       330  257108               0          book  4.25   \n",
       "1        151       330  257108               0          food  4.25   \n",
       "2        151       330  257108               0   kitchenware  4.25   \n",
       "3        151       330  257108               0  other_object  4.25   \n",
       "4        151       330  257108               0        screen  4.25   \n",
       "5        151       330  257108               0           toy  4.25   \n",
       "6        151      1920  257108               0          book  4.25   \n",
       "7        151      1920  257108               0          food  4.25   \n",
       "8        151      1920  257108               0   kitchenware  4.25   \n",
       "9        151      1920  257108               0  other_object  4.25   \n",
       "10       151      1920  257108               0        screen  4.25   \n",
       "11       151      1920  257108               0           toy  4.25   \n",
       "\n",
       "           social  \n",
       "0   adult present  \n",
       "1   adult present  \n",
       "2   adult present  \n",
       "3   adult present  \n",
       "4   adult present  \n",
       "5   adult present  \n",
       "6   child present  \n",
       "7   child present  \n",
       "8   child present  \n",
       "9   child present  \n",
       "10  child present  \n",
       "11  child present  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    -- Select 5 random subjects\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 10\n",
    "),\n",
    "RandomFrames AS (\n",
    "    -- Select 500 random frames per subject\n",
    "    SELECT DISTINCT d.frame_number, d.video_id\n",
    "    FROM Detections d\n",
    "    JOIN RandomSubjects rs ON d.video_id = rs.video_id\n",
    "    GROUP BY d.frame_number, d.video_id\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 500\n",
    "),\n",
    "SocialContext AS (\n",
    "    SELECT \n",
    "        d.frame_number,\n",
    "        d.video_id,\n",
    "        CASE\n",
    "            WHEN MAX(CASE WHEN d.object_class IN (1,3) THEN 1 ELSE 0 END) = 1 \n",
    "            AND MAX(CASE WHEN d.object_class IN (0,2) THEN 1 ELSE 0 END) = 1 \n",
    "            THEN 'child and adult present'\n",
    "            WHEN MAX(CASE WHEN d.object_class IN (1,3) THEN 1 ELSE 0 END) = 1 \n",
    "            THEN 'adult present'\n",
    "            WHEN MAX(CASE WHEN d.object_class IN (0,2) THEN 1 ELSE 0 END) = 1 \n",
    "            THEN 'child present'\n",
    "            ELSE 'alone'\n",
    "        END as social\n",
    "    FROM Detections d\n",
    "    JOIN RandomFrames rf ON d.frame_number = rf.frame_number AND d.video_id = rf.video_id\n",
    "    GROUP BY d.frame_number, d.video_id\n",
    "),\n",
    "ObjectTypes AS (\n",
    "    -- Create all possible object types\n",
    "    SELECT \n",
    "        'book' as object_type, 5 as object_class UNION ALL\n",
    "        SELECT 'toy', 6 UNION ALL\n",
    "        SELECT 'kitchenware', 7 UNION ALL\n",
    "        SELECT 'screen', 8 UNION ALL\n",
    "        SELECT 'food', 9 UNION ALL\n",
    "        SELECT 'other_object', 10\n",
    "),\n",
    "FrameObjects AS (\n",
    "    -- Get unique object presence per frame and object type\n",
    "    SELECT DISTINCT\n",
    "        rf.frame_number,\n",
    "        rf.video_id,\n",
    "        ot.object_type,\n",
    "        ot.object_class,\n",
    "        MAX(CASE WHEN d.object_class IS NOT NULL THEN 1 ELSE 0 END) as object_present\n",
    "    FROM RandomFrames rf\n",
    "    CROSS JOIN ObjectTypes ot\n",
    "    LEFT JOIN Detections d ON \n",
    "        rf.frame_number = d.frame_number \n",
    "        AND rf.video_id = d.video_id \n",
    "        AND ot.object_class = d.object_class\n",
    "    GROUP BY rf.frame_number, rf.video_id, ot.object_type, ot.object_class\n",
    ")\n",
    "\n",
    "SELECT DISTINCT\n",
    "    fo.video_id,\n",
    "    fo.frame_number as frame_id,\n",
    "    rs.child_id as ID,\n",
    "    fo.object_present,\n",
    "    fo.object_type,\n",
    "    rs.age_at_recording as age,\n",
    "    COALESCE(sc.social, 'alone') as social\n",
    "FROM \n",
    "    FrameObjects fo\n",
    "    JOIN RandomSubjects rs ON fo.video_id = rs.video_id\n",
    "    LEFT JOIN SocialContext sc ON fo.frame_number = sc.frame_number AND fo.video_id = sc.video_id\n",
    "ORDER BY \n",
    "    rs.child_id, fo.video_id, fo.frame_number, fo.object_type;\n",
    "\"\"\"\n",
    "\n",
    "# Load data\n",
    "with sqlite3.connect('/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db') as conn:\n",
    "    object_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Convert categorical variables to factors\n",
    "object_df['social'] = pd.Categorical(object_df['social'])\n",
    "object_df['object_type'] = pd.Categorical(object_df['object_type'])\n",
    "object_df['ID'] = pd.Categorical(object_df['ID'])\n",
    "\n",
    "print(\"Data shape:\", object_df.shape)\n",
    "print(\"\\nNumber of unique subjects:\", object_df['ID'].nunique())\n",
    "print(\"\\nVariable types:\")\n",
    "print(object_df.dtypes)\n",
    "print(\"\\nSample data (showing first 12 rows to see multiple object types per frame):\")\n",
    "display(object_df.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to categorical type\n",
    "object_df['object_type'] = object_df['object_type'].astype('category')\n",
    "object_df['social_context'] = object_df['social'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv\n",
    "object_df.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/object_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Context (Alone Yes or No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (250, 12)\n",
      "\n",
      "Number of unique subjects: 10\n",
      "\n",
      "Variable types:\n",
      "video_id             int64\n",
      "frame_id             int64\n",
      "ID                   int64\n",
      "age                float64\n",
      "child_person         int64\n",
      "adult_person         int64\n",
      "child_face           int64\n",
      "adult_face           int64\n",
      "child_gaze         float64\n",
      "adult_gaze         float64\n",
      "child_proximity    float64\n",
      "adult_proximity    float64\n",
      "dtype: object\n",
      "\n",
      "Sample data (showing first 12 rows to see multiple object types per frame):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>child_person</th>\n",
       "      <th>adult_person</th>\n",
       "      <th>child_face</th>\n",
       "      <th>adult_face</th>\n",
       "      <th>child_gaze</th>\n",
       "      <th>adult_gaze</th>\n",
       "      <th>child_proximity</th>\n",
       "      <th>adult_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173</td>\n",
       "      <td>2150</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173</td>\n",
       "      <td>13170</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.566699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>13540</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.570673</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173</td>\n",
       "      <td>14080</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173</td>\n",
       "      <td>18730</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597570</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>173</td>\n",
       "      <td>19070</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.621938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>173</td>\n",
       "      <td>21910</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>173</td>\n",
       "      <td>22380</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.417363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>173</td>\n",
       "      <td>22950</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>173</td>\n",
       "      <td>28540</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>173</td>\n",
       "      <td>30460</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.629479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>173</td>\n",
       "      <td>31760</td>\n",
       "      <td>257578</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    video_id  frame_id      ID   age  child_person  adult_person  child_face  \\\n",
       "0        173      2150  257578  4.04             0             0           0   \n",
       "1        173     13170  257578  4.04             0             0           1   \n",
       "2        173     13540  257578  4.04             0             0           1   \n",
       "3        173     14080  257578  4.04             0             0           0   \n",
       "4        173     18730  257578  4.04             0             0           1   \n",
       "5        173     19070  257578  4.04             0             0           1   \n",
       "6        173     21910  257578  4.04             0             0           0   \n",
       "7        173     22380  257578  4.04             0             0           0   \n",
       "8        173     22950  257578  4.04             0             0           0   \n",
       "9        173     28540  257578  4.04             0             0           0   \n",
       "10       173     30460  257578  4.04             0             0           1   \n",
       "11       173     31760  257578  4.04             0             0           1   \n",
       "\n",
       "    adult_face  child_gaze  adult_gaze  child_proximity  adult_proximity  \n",
       "0            1         NaN         0.0              NaN         0.658033  \n",
       "1            0         1.0         NaN         0.566699              NaN  \n",
       "2            0         1.0         NaN         0.570673              NaN  \n",
       "3            0         NaN         NaN              NaN              NaN  \n",
       "4            0         1.0         NaN         0.597570              NaN  \n",
       "5            0         1.0         NaN         0.621938              NaN  \n",
       "6            0         NaN         NaN              NaN              NaN  \n",
       "7            1         NaN         1.0              NaN         0.417363  \n",
       "8            0         NaN         NaN              NaN              NaN  \n",
       "9            0         NaN         NaN              NaN              NaN  \n",
       "10           0         1.0         NaN         0.629479              NaN  \n",
       "11           0         1.0         NaN         0.634104              NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH RandomSubjects AS (\n",
    "    SELECT DISTINCT s.child_id, s.video_name, v.video_id, s.age_at_recording\n",
    "    FROM Subjects s\n",
    "    JOIN Videos v ON s.video_name = v.video_path\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 10\n",
    "),\n",
    "AllFrames AS (\n",
    "    SELECT DISTINCT frame_number, video_id\n",
    "    FROM Detections\n",
    "    WHERE video_id IN (SELECT video_id FROM RandomSubjects)\n",
    "),\n",
    "RandomFrames AS (\n",
    "    SELECT frame_number, video_id\n",
    "    FROM AllFrames\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 250\n",
    "),\n",
    "FaceInfo AS (\n",
    "    SELECT \n",
    "        rf.video_id,\n",
    "        rf.frame_number,\n",
    "        rs.child_id,\n",
    "        rs.age_at_recording,\n",
    "        \n",
    "        -- Binary flags\n",
    "        CASE WHEN d.object_class = 0 THEN 1 ELSE 0 END AS child_person,\n",
    "        CASE WHEN d.object_class = 1 THEN 1 ELSE 0 END AS adult_person,\n",
    "        \n",
    "        CASE WHEN d.object_class = 2 THEN 1 ELSE 0 END AS child_face,\n",
    "        CASE WHEN d.object_class = 3 THEN 1 ELSE 0 END AS adult_face,\n",
    "        \n",
    "        -- Gaze\n",
    "        CASE WHEN d.object_class = 2 THEN d.gaze_direction ELSE NULL END AS child_gaze,\n",
    "        CASE WHEN d.object_class = 3 THEN d.gaze_direction ELSE NULL END AS adult_gaze,\n",
    "\n",
    "        -- Proximity\n",
    "        CASE WHEN d.object_class = 2 THEN d.proximity ELSE NULL END AS child_proximity,\n",
    "        CASE WHEN d.object_class = 3 THEN d.proximity ELSE NULL END AS adult_proximity\n",
    "    \n",
    "\n",
    "    FROM RandomFrames rf\n",
    "    JOIN RandomSubjects rs ON rf.video_id = rs.video_id\n",
    "    LEFT JOIN Detections d \n",
    "        ON d.video_id = rf.video_id \n",
    "        AND d.frame_number = rf.frame_number \n",
    "        AND d.object_class IN (2, 3)  -- only faces\n",
    "\n",
    "    GROUP BY rf.video_id, rf.frame_number, rs.child_id, rs.age_at_recording\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    video_id,\n",
    "    frame_number AS frame_id,\n",
    "    child_id AS ID,\n",
    "    age_at_recording AS age,\n",
    "    child_person,\n",
    "    adult_person,\n",
    "    child_face,\n",
    "    adult_face,\n",
    "    child_gaze,\n",
    "    adult_gaze,\n",
    "    child_proximity,\n",
    "    adult_proximity\n",
    "FROM FaceInfo\n",
    "ORDER BY child_id, video_id, frame_number;\n",
    "\"\"\"\n",
    "\n",
    "# Load data\n",
    "with sqlite3.connect('/home/nele_pauline_suffo/outputs/detection_pipeline_results/detection_results.db') as conn:\n",
    "    social_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "print(\"Data shape:\", social_df.shape)\n",
    "print(\"\\nNumber of unique subjects:\", social_df['ID'].nunique())\n",
    "print(\"\\nVariable types:\")\n",
    "print(social_df.dtypes)\n",
    "print(\"\\nSample data (showing first 12 rows to see multiple object types per frame):\")\n",
    "display(social_df.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column person_present if at least one of adult or child is present\n",
    "social_df['person_present'] = social_df['child_person'] | social_df['adult_person'] | social_df['child_face'] | social_df['adult_face']\n",
    "social_df['child_present'] = social_df['child_person'] | social_df['child_face']\n",
    "social_df['adult_present'] = social_df['adult_person'] | social_df['adult_face']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv\n",
    "social_df.to_csv('/home/nele_pauline_suffo/outputs/detection_pipeline_results/social_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found overlapping IDs between validation and test sets!\n",
      "Overlapping IDs: {258704.0}\n",
      "✅ Training set (already annotated):\n",
      "Number of videos: 75\n",
      "\n",
      "✅ Validation candidates:\n",
      "Number of videos: 8\n",
      "       file name  (generated automatically)  duration_minutes\n",
      "533  quantex_at_home_id266050_2024_09_15_01              30.0\n",
      "588  quantex_at_home_id267079_2025_02_11_02              30.0\n",
      "581  quantex_at_home_id266971_2024_09_06_02              30.0\n",
      "159  quantex_at_home_id258704_2022_05_10_01              30.0\n",
      "573  quantex_at_home_id266822_2022_11_14_01              30.0\n",
      "141  quantex_at_home_id258541_2023_03_26_01              30.0\n",
      "547  quantex_at_home_id266063_2024_09_19_01              30.0\n",
      "340  quantex_at_home_id263194_2025_02_15_01               4.9\n",
      "\n",
      "✅ Test candidates:\n",
      "Number of videos: 8\n",
      "       file name  (generated automatically)  duration_minutes\n",
      "550  quantex_at_home_id266151_2024_09_14_01              30.0\n",
      "554  quantex_at_home_id266352_2025_01_28_01              30.0\n",
      "135  quantex_at_home_id258309_2023_03_12_01              30.0\n",
      "564  quantex_at_home_id266606_2024_09_10_01              30.0\n",
      "126  quantex_at_home_id258274_2023_03_21_01              30.0\n",
      "279  quantex_at_home_id262333_2024_12_01_04              30.0\n",
      "106  quantex_at_home_id258192_2021_11_13_01              30.0\n",
      "693  quantex_at_home_id275936_2025_01_16_03               5.0\n",
      "\n",
      "Duration Summary:\n",
      "Training:    1719.12 minutes (80.0%)\n",
      "Validation:  214.90 minutes (10.0%)\n",
      "Test:        215.00 minutes (10.0%)\n",
      "Total:       2149.02 minutes\n",
      "\n",
      "Target duration for val/test: 214.89 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, time\n",
    "\n",
    "# Load Excel file and prepare data\n",
    "df = pd.read_excel(\"/home/nele_pauline_suffo/ProcessedData/quantex_data_sheet.xlsx\") \n",
    "\n",
    "# remove rows with filename starting with \"quantex_at_home_pakistan\"\n",
    "df = df[~df['file name  (generated automatically)'].str.startswith(\"quantex_at_home_pakistan\")]\n",
    "df = df[~df['file name  (generated automatically)'].str.startswith(\"quantex_at_home_id_yyyy\")]\n",
    "\n",
    "# Normalize annotation column\n",
    "df['is_annotated'] = df['Annotated'].isin(['Yes', 'review', 'in progress'])\n",
    "\n",
    "# Convert duration to minutes\n",
    "def time_to_minutes(t):\n",
    "    if isinstance(t, time):\n",
    "        return t.hour * 60 + t.minute + (t.second / 60.0)\n",
    "    elif isinstance(t, str):\n",
    "        # Parse string format if needed\n",
    "        try:\n",
    "            t = datetime.strptime(t, '%H:%M:%S').time()\n",
    "            return t.hour * 60 + t.minute + (t.second / 60.0)\n",
    "        except:\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "# Add duration in minutes column\n",
    "df['duration_minutes'] = df['DURATION'].apply(time_to_minutes)\n",
    "\n",
    "# Get training set (already annotated videos)\n",
    "train_df = df[df['is_annotated']].copy()\n",
    "train_length = train_df['duration_minutes'].sum()\n",
    "\n",
    "# Calculate target duration for val and test (10% each of final dataset)\n",
    "# train_length is 80%, so divide by 0.8 to get total length, then take 10%\n",
    "final_total_length = train_length / 0.8\n",
    "target_length = final_total_length * 0.1\n",
    "\n",
    "# Get candidate videos for val/test (not yet annotated)\n",
    "candidates = df[~df['is_annotated']].copy()\n",
    "candidates = candidates.sort_values('duration_minutes')\n",
    "\n",
    "# Function to select videos closest to target duration\n",
    "def select_videos_for_split(candidates_df: pd.DataFrame, target_duration: float, max_videos: int) -> pd.DataFrame:\n",
    "    \"\"\"Select videos aiming for target duration with unique IDs.\"\"\"\n",
    "    candidates_sorted = candidates_df.copy()  # Create a copy to avoid warnings\n",
    "    selected = []\n",
    "    current_duration = 0\n",
    "    used_ids = set()\n",
    "    \n",
    "    while current_duration < target_duration and len(selected) < max_videos:\n",
    "        # Get remaining candidates using loc\n",
    "        mask = ~candidates_sorted['ID'].isin(used_ids)\n",
    "        remaining = candidates_sorted.loc[mask].copy()\n",
    "        \n",
    "        if remaining.empty:\n",
    "            break\n",
    "            \n",
    "        # Calculate gap to target using loc\n",
    "        remaining.loc[:, 'gap_to_target'] = (\n",
    "            target_duration - (current_duration + remaining['duration_minutes'])\n",
    "        ).abs()\n",
    "        \n",
    "        best_match = remaining.nsmallest(1, 'gap_to_target').iloc[0]\n",
    "        \n",
    "        if current_duration + best_match['duration_minutes'] > target_duration * 1.1:\n",
    "            break\n",
    "            \n",
    "        selected.append(best_match)\n",
    "        used_ids.add(best_match['ID'])\n",
    "        current_duration += best_match['duration_minutes']\n",
    "        \n",
    "        if len(selected) >= 10 and current_duration >= target_duration * 0.9:\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame(selected)\n",
    "\n",
    "# Get validation and test sets\n",
    "candidates_mask = (candidates['duration_minutes'] < target_length * 0.3)  # Reduce max duration threshold\n",
    "remaining_candidates = candidates.loc[candidates_mask].copy()\n",
    "\n",
    "# Select validation set\n",
    "val_df = select_videos_for_split(remaining_candidates, target_length, max_videos=12)\n",
    "\n",
    "# Select test set from remaining videos\n",
    "test_mask = (~candidates['ID'].isin(val_df['ID']) & \n",
    "            (candidates['duration_minutes'] < target_length * 0.3))\n",
    "remaining_candidates = candidates.loc[test_mask].copy()\n",
    "test_df = select_videos_for_split(remaining_candidates, target_length, max_videos=12)\n",
    "\n",
    "\n",
    "# Verify unique IDs\n",
    "train_ids = set(train_df['ID'])\n",
    "val_ids = set(val_df['ID'])\n",
    "test_ids = set(test_df['ID'])\n",
    "# check for overlap in all three sets\n",
    "overlap = train_ids.intersection(val_ids).union(train_ids.intersection(test_ids)).union(val_ids.intersection(test_ids))\n",
    "\n",
    "if overlap:\n",
    "    print(\"Warning: Found overlapping IDs between validation and test sets!\")\n",
    "    print(f\"Overlapping IDs: {overlap}\")\n",
    "    \n",
    "val_length = val_df['duration_minutes'].sum()\n",
    "test_length = test_df['duration_minutes'].sum()\n",
    "total_length = train_length + val_length + test_length\n",
    "\n",
    "print(\"✅ Training set (already annotated):\")\n",
    "print(f\"Number of videos: {len(train_df)}\")\n",
    "\n",
    "print(\"\\n✅ Validation candidates:\")\n",
    "print(f\"Number of videos: {len(val_df)}\")\n",
    "print(val_df[['file name  (generated automatically)', 'duration_minutes']])\n",
    "\n",
    "print(\"\\n✅ Test candidates:\")\n",
    "print(f\"Number of videos: {len(test_df)}\")\n",
    "print(test_df[['file name  (generated automatically)', 'duration_minutes']])\n",
    "\n",
    "print(f\"\\nDuration Summary:\")\n",
    "print(f\"Training:    {train_length:.2f} minutes ({(train_length/total_length)*100:.1f}%)\")\n",
    "print(f\"Validation:  {val_length:.2f} minutes ({(val_length/total_length)*100:.1f}%)\")\n",
    "print(f\"Test:        {test_length:.2f} minutes ({(test_length/total_length)*100:.1f}%)\")\n",
    "print(f\"Total:       {total_length:.2f} minutes\")\n",
    "\n",
    "print(f\"\\nTarget duration for val/test: {target_length:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found overlapping IDs between validation and test sets!\n",
      "Overlapping IDs: {258704.0}\n",
      "✅ Training set (already annotated):\n",
      "Number of videos: 75\n",
      "\n",
      "✅ Validation candidates:\n",
      "Number of videos: 10\n",
      "       file name  (generated automatically)  duration_minutes\n",
      "710  quantex_at_home_id284216_2025_03_14_05         30.000000\n",
      "446  quantex_at_home_id264585_2023_08_16_02         30.000000\n",
      "436  quantex_at_home_id264514_2025_01_13_02         30.000000\n",
      "197  quantex_at_home_id260478_2022_11_05_01         30.000000\n",
      "440  quantex_at_home_id264556_2024_12_18_01         30.000000\n",
      "191  quantex_at_home_id260178_2023_08_12_02         30.000000\n",
      "407  quantex_at_home_id264089_2023_05_14_03         30.000000\n",
      "340  quantex_at_home_id263194_2025_02_15_01          4.900000\n",
      "107  quantex_at_home_id258239_2020_08_23_03          0.750000\n",
      "459  quantex_at_home_id264666_2025_02_28_02          1.066667\n",
      "\n",
      "✅ Test candidates:\n",
      "Number of videos: 10\n",
      "       file name  (generated automatically)  duration_minutes\n",
      "589  quantex_at_home_id267079_2025_02_11_03         30.000000\n",
      "581  quantex_at_home_id266971_2024_09_06_02         30.000000\n",
      "159  quantex_at_home_id258704_2022_05_10_01         30.000000\n",
      "533  quantex_at_home_id266050_2024_09_15_01         30.000000\n",
      "547  quantex_at_home_id266063_2024_09_19_01         30.000000\n",
      "142  quantex_at_home_id258541_2023_03_26_02         30.000000\n",
      "556  quantex_at_home_id266352_2025_02_11_01         30.000000\n",
      "693  quantex_at_home_id275936_2025_01_16_03          5.000000\n",
      "490  quantex_at_home_id265514_2024_09_08_01          1.500000\n",
      "639  quantex_at_home_id267883_2024_12_08_01          1.716667\n",
      "\n",
      "Duration Summary:\n",
      "Training:    1719.12 minutes (79.8%)\n",
      "Validation:  216.72 minutes (10.1%)\n",
      "Test:        218.22 minutes (10.1%)\n",
      "Total:       2154.05 minutes\n",
      "\n",
      "Target duration for val/test: 214.89 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, time\n",
    "\n",
    "# Load Excel file and prepare data\n",
    "df = pd.read_excel(\"/home/nele_pauline_suffo/ProcessedData/quantex_data_sheet.xlsx\") \n",
    "\n",
    "# remove rows with filename starting with \"quantex_at_home_pakistan\"\n",
    "df = df[~df['file name  (generated automatically)'].str.startswith(\"quantex_at_home_pakistan\")]\n",
    "df = df[~df['file name  (generated automatically)'].str.startswith(\"quantex_at_home_id_yyyy\")]\n",
    "\n",
    "# Normalize annotation column\n",
    "df['is_annotated'] = df['Annotated'].isin(['Yes', 'review', 'in progress'])\n",
    "\n",
    "# Convert duration to minutes\n",
    "def time_to_minutes(t):\n",
    "    if isinstance(t, time):\n",
    "        return t.hour * 60 + t.minute + (t.second / 60.0)\n",
    "    elif isinstance(t, str):\n",
    "        # Parse string format if needed\n",
    "        try:\n",
    "            t = datetime.strptime(t, '%H:%M:%S').time()\n",
    "            return t.hour * 60 + t.minute + (t.second / 60.0)\n",
    "        except:\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "# Add duration in minutes column\n",
    "df['duration_minutes'] = df['DURATION'].apply(time_to_minutes)\n",
    "\n",
    "# Get training set (already annotated videos)\n",
    "train_df = df[df['is_annotated']].copy()\n",
    "train_length = train_df['duration_minutes'].sum()\n",
    "\n",
    "# Calculate target duration for val and test (10% each of final dataset)\n",
    "# train_length is 80%, so divide by 0.8 to get total length, then take 10%\n",
    "final_total_length = train_length / 0.8\n",
    "target_length = final_total_length * 0.1\n",
    "\n",
    "# Get candidate videos for val/test (not yet annotated)\n",
    "candidates = df[~df['is_annotated']].copy()\n",
    "candidates = candidates.sort_values('duration_minutes')\n",
    "\n",
    "# Function to select videos closest to target duration\n",
    "def select_videos_for_split(candidates_df: pd.DataFrame, target_duration: float, max_videos: int) -> pd.DataFrame:\n",
    "    \"\"\"Select videos aiming for target duration with unique IDs.\"\"\"\n",
    "    candidates_sorted = candidates_df.copy()  # Create a copy to avoid warnings\n",
    "    selected = []\n",
    "    current_duration = 0\n",
    "    used_ids = set()\n",
    "    \n",
    "    while current_duration < target_duration and len(selected) < max_videos:\n",
    "        # Get remaining candidates using loc\n",
    "        mask = ~candidates_sorted['ID'].isin(used_ids)\n",
    "        remaining = candidates_sorted.loc[mask].copy()\n",
    "        \n",
    "        if remaining.empty:\n",
    "            break\n",
    "            \n",
    "        # Calculate gap to target using loc\n",
    "        remaining.loc[:, 'gap_to_target'] = (\n",
    "            target_duration - (current_duration + remaining['duration_minutes'])\n",
    "        ).abs()\n",
    "        \n",
    "        best_match = remaining.nsmallest(1, 'gap_to_target').iloc[0]\n",
    "        \n",
    "        if current_duration + best_match['duration_minutes'] > target_duration * 1.1:\n",
    "            break\n",
    "            \n",
    "        selected.append(best_match)\n",
    "        used_ids.add(best_match['ID'])\n",
    "        current_duration += best_match['duration_minutes']\n",
    "        \n",
    "        if len(selected) >= 10 and current_duration >= target_duration * 0.9:\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame(selected)\n",
    "\n",
    "# Get validation and test sets\n",
    "candidates_mask = (candidates['duration_minutes'] < target_length * 0.3)  # Reduce max duration threshold\n",
    "remaining_candidates = candidates.loc[candidates_mask].copy()\n",
    "\n",
    "# Select validation set\n",
    "val_df = select_videos_for_split(remaining_candidates, target_length, max_videos=12)\n",
    "\n",
    "# Select test set from remaining videos\n",
    "test_mask = (~candidates['ID'].isin(val_df['ID']) & \n",
    "            (candidates['duration_minutes'] < target_length * 0.3))\n",
    "remaining_candidates = candidates.loc[test_mask].copy()\n",
    "test_df = select_videos_for_split(remaining_candidates, target_length, max_videos=12)\n",
    "\n",
    "\n",
    "# Verify unique IDs\n",
    "train_ids = set(train_df['ID'])\n",
    "val_ids = set(val_df['ID'])\n",
    "test_ids = set(test_df['ID'])\n",
    "# check for overlap in all three sets\n",
    "overlap = train_ids.intersection(val_ids).union(train_ids.intersection(test_ids)).union(val_ids.intersection(test_ids))\n",
    "\n",
    "if overlap:\n",
    "    print(\"Warning: Found overlapping IDs between validation and test sets!\")\n",
    "    print(f\"Overlapping IDs: {overlap}\")\n",
    "    \n",
    "val_length = val_df['duration_minutes'].sum()\n",
    "test_length = test_df['duration_minutes'].sum()\n",
    "total_length = train_length + val_length + test_length\n",
    "\n",
    "print(\"✅ Training set (already annotated):\")\n",
    "print(f\"Number of videos: {len(train_df)}\")\n",
    "\n",
    "print(\"\\n✅ Validation candidates:\")\n",
    "print(f\"Number of videos: {len(val_df)}\")\n",
    "print(val_df[['file name  (generated automatically)', 'duration_minutes']])\n",
    "\n",
    "print(\"\\n✅ Test candidates:\")\n",
    "print(f\"Number of videos: {len(test_df)}\")\n",
    "print(test_df[['file name  (generated automatically)', 'duration_minutes']])\n",
    "\n",
    "print(f\"\\nDuration Summary:\")\n",
    "print(f\"Training:    {train_length:.2f} minutes ({(train_length/total_length)*100:.1f}%)\")\n",
    "print(f\"Validation:  {val_length:.2f} minutes ({(val_length/total_length)*100:.1f}%)\")\n",
    "print(f\"Test:        {test_length:.2f} minutes ({(test_length/total_length)*100:.1f}%)\")\n",
    "print(f\"Total:       {total_length:.2f} minutes\")\n",
    "\n",
    "print(f\"\\nTarget duration for val/test: {target_length:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
