{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26225eeb",
   "metadata": {},
   "source": [
    "## Generate GT RTTM with ID-based Splitting\n",
    "\n",
    "Split videos by participant ID, ensuring all videos from the same child stay in the same split (train/dev/test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90a42c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 192 video-to-ID mappings\n",
      "Sample mappings: {'100898': '266216', '106910': '271693', '108844': '265891', '114534': '264362', '117071': '265674'}\n",
      "\n",
      "Found 58 unique participant IDs\n",
      "Files without ID: 0\n",
      "\n",
      "Top 10 IDs by total duration:\n",
      "  1. ID 280599: 13110.3s (9 videos)\n",
      "  2. ID 262222: 8276.9s (5 videos)\n",
      "  3. ID 262472: 7608.9s (5 videos)\n",
      "  4. ID 260439: 7336.4s (5 videos)\n",
      "  5. ID 266216: 6803.4s (6 videos)\n",
      "  6. ID 266686: 5794.1s (5 videos)\n",
      "  7. ID 265619: 5767.4s (5 videos)\n",
      "  8. ID 279536: 5543.6s (4 videos)\n",
      "  9. ID 266799: 5443.0s (6 videos)\n",
      "  10. ID 262381: 5400.6s (3 videos)\n",
      "\n",
      "📊 ID-based Split Results:\n",
      "Train: 38 IDs, 144 files, 157380.8s (79.9%)\n",
      "Dev:   10 IDs, 23 files, 19953.4s (10.1%)\n",
      "Test:  10 IDs, 25 files, 19716.5s (10.0%)\n",
      "\n",
      "Train IDs: ['280599', '262222', '262472', '260439', '266216', '266686', '265619', '279536', '266799', '262381', '260730', '262564', '262703', '260777', '280429', '265566', '265943', '262020', '260455', '263229', '265674', '271693', '267139', '264362', '265688', '262181', '260040', '262273', '271735', '264521', '280427', '262174', '277887', '265705', '266369', '265891', '280989', '263265']\n",
      "Dev IDs: ['275146', '264395', '264304', '260444', '264614', '264751', '263338', '279886', '264576', '260062']\n",
      "Test IDs: ['262944', '262661', '266935', '265706', '279613', '280817', '263157', '262495', '264436', '265568']\n",
      "\n",
      "Found 58 unique participant IDs\n",
      "Files without ID: 0\n",
      "\n",
      "Top 10 IDs by total duration:\n",
      "  1. ID 280599: 13110.3s (9 videos)\n",
      "  2. ID 262222: 8276.9s (5 videos)\n",
      "  3. ID 262472: 7608.9s (5 videos)\n",
      "  4. ID 260439: 7336.4s (5 videos)\n",
      "  5. ID 266216: 6803.4s (6 videos)\n",
      "  6. ID 266686: 5794.1s (5 videos)\n",
      "  7. ID 265619: 5767.4s (5 videos)\n",
      "  8. ID 279536: 5543.6s (4 videos)\n",
      "  9. ID 266799: 5443.0s (6 videos)\n",
      "  10. ID 262381: 5400.6s (3 videos)\n",
      "\n",
      "📊 ID-based Split Results:\n",
      "Train: 38 IDs, 144 files, 157380.8s (79.9%)\n",
      "Dev:   10 IDs, 23 files, 19953.4s (10.1%)\n",
      "Test:  10 IDs, 25 files, 19716.5s (10.0%)\n",
      "\n",
      "Train IDs: ['280599', '262222', '262472', '260439', '266216', '266686', '265619', '279536', '266799', '262381', '260730', '262564', '262703', '260777', '280429', '265566', '265943', '262020', '260455', '263229', '265674', '271693', '267139', '264362', '265688', '262181', '260040', '262273', '271735', '264521', '280427', '262174', '277887', '265705', '266369', '265891', '280989', '263265']\n",
      "Dev IDs: ['275146', '264395', '264304', '260444', '264614', '264751', '263338', '279886', '264576', '260062']\n",
      "Test IDs: ['262944', '262661', '266935', '265706', '279613', '280817', '263157', '262495', '264436', '265568']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file with ID mappings\n",
    "csv_path = \"/home/nele_pauline_suffo/ProcessedData/childlens_annotations/keeper/v1/childlens_participant_info.csv\"\n",
    "id_mapping_df = pd.read_csv(csv_path, sep=';')\n",
    "# Create mapping from file_name to ID\n",
    "file_name_to_id = dict(zip(id_mapping_df['file_name'].astype(str), id_mapping_df['child_id'].astype(str)))\n",
    "\n",
    "print(f\"Loaded {len(file_name_to_id)} video-to-ID mappings\")\n",
    "print(\"Sample mappings:\", dict(list(file_name_to_id.items())[:5]))\n",
    "\n",
    "# Folder and output paths\n",
    "input_folder = \"/home/nele_pauline_suffo/ProcessedData/childlens_annotations/keeper/v1\"\n",
    "output_dir = Path(\"/home/nele_pauline_suffo/ProcessedData/audio_cls_input\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "valid_event_ids = {\"child_talking\", \"other_person_talking\", \"overheard_speech\", \"singing/humming\"}\n",
    "\n",
    "# Step 1: Load all JSON files and collect metadata with ID grouping\n",
    "id_to_files = defaultdict(list)\n",
    "files_without_id = []\n",
    "\n",
    "json_files = glob(f\"{input_folder}/*.json\")\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        video_name = data.get('video_name', '')\n",
    "        if not video_name:\n",
    "            print(f\"Warning: No video_name found in {json_file}\")\n",
    "            continue\n",
    "            \n",
    "        annotations = data.get('annotations', [])\n",
    "        if not annotations:\n",
    "            print(f\"Warning: No annotations found in {json_file}\")\n",
    "            continue\n",
    "            \n",
    "        duration = max(ann.get('endTime', 0) for ann in annotations)\n",
    "        \n",
    "        # Extract file_name from video_name (remove extension)\n",
    "        file_name = video_name.replace('.MP4', '').replace('.mp4', '')\n",
    "        participant_id = file_name_to_id.get(file_name, None)\n",
    "        \n",
    "        file_info = {\n",
    "            \"path\": json_file,\n",
    "            \"uri\": video_name,\n",
    "            \"file_name\": file_name,\n",
    "            \"duration\": duration,\n",
    "            \"participant_id\": participant_id\n",
    "        }\n",
    "        \n",
    "        if participant_id:\n",
    "            id_to_files[participant_id].append(file_info)\n",
    "        else:\n",
    "            files_without_id.append(file_info)\n",
    "            print(f\"Warning: No ID found for file_name '{file_name}' from video '{video_name}'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {json_file} due to error: {e}\")\n",
    "\n",
    "print(f\"\\nFound {len(id_to_files)} unique participant IDs\")\n",
    "print(f\"Files without ID: {len(files_without_id)}\")\n",
    "\n",
    "# Step 2: Calculate total duration per ID and sort IDs by total duration\n",
    "id_durations = {}\n",
    "for participant_id, files in id_to_files.items():\n",
    "    total_duration = sum(f[\"duration\"] for f in files)\n",
    "    id_durations[participant_id] = total_duration\n",
    "\n",
    "# Sort IDs by total duration (descending) for balanced splitting\n",
    "sorted_ids = sorted(id_durations.keys(), key=lambda x: id_durations[x], reverse=True)\n",
    "\n",
    "print(\"\\nTop 10 IDs by total duration:\")\n",
    "for i, pid in enumerate(sorted_ids[:10]):\n",
    "    print(f\"  {i+1}. ID {pid}: {id_durations[pid]:.1f}s ({len(id_to_files[pid])} videos)\")\n",
    "\n",
    "# Step 3: Split IDs into train/dev/test while maintaining ratios\n",
    "total_duration = sum(id_durations.values())\n",
    "target_train = 0.8 * total_duration\n",
    "target_dev = 0.1 * total_duration\n",
    "target_test = 0.1 * total_duration\n",
    "\n",
    "train_ids, dev_ids, test_ids = [], [], []\n",
    "train_duration, dev_duration, test_duration = 0, 0, 0\n",
    "\n",
    "for participant_id in sorted_ids:\n",
    "    duration = id_durations[participant_id]\n",
    "    \n",
    "    # Assign to the split that needs the most duration relative to its target\n",
    "    train_need = max(0, target_train - train_duration)\n",
    "    dev_need = max(0, target_dev - dev_duration)\n",
    "    test_need = max(0, target_test - test_duration)\n",
    "    \n",
    "    if train_need >= dev_need and train_need >= test_need:\n",
    "        train_ids.append(participant_id)\n",
    "        train_duration += duration\n",
    "    elif dev_need >= test_need:\n",
    "        dev_ids.append(participant_id)\n",
    "        dev_duration += duration\n",
    "    else:\n",
    "        test_ids.append(participant_id)\n",
    "        test_duration += duration\n",
    "\n",
    "# Flatten files by split\n",
    "train_files = [f for pid in train_ids for f in id_to_files[pid]]\n",
    "dev_files = [f for pid in dev_ids for f in id_to_files[pid]]\n",
    "test_files = [f for pid in test_ids for f in id_to_files[pid]]\n",
    "\n",
    "splits = {\n",
    "    \"train\": train_files,\n",
    "    \"dev\": dev_files,\n",
    "    \"test\": test_files\n",
    "}\n",
    "\n",
    "print(f\"\\n📊 ID-based Split Results:\")\n",
    "print(f\"Train: {len(train_ids)} IDs, {len(train_files)} files, {train_duration:.1f}s ({train_duration/total_duration*100:.1f}%)\")\n",
    "print(f\"Dev:   {len(dev_ids)} IDs, {len(dev_files)} files, {dev_duration:.1f}s ({dev_duration/total_duration*100:.1f}%)\")\n",
    "print(f\"Test:  {len(test_ids)} IDs, {len(test_files)} files, {test_duration:.1f}s ({test_duration/total_duration*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTrain IDs: {train_ids}\")\n",
    "print(f\"Dev IDs: {dev_ids}\")\n",
    "print(f\"Test IDs: {test_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ccaad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 RTTM file for train split saved to /home/nele_pauline_suffo/ProcessedData/audio_cls_input/train.rttm\n",
      "📝 RTTM file for dev split saved to /home/nele_pauline_suffo/ProcessedData/audio_cls_input/dev.rttm\n",
      "📝 RTTM file for test split saved to /home/nele_pauline_suffo/ProcessedData/audio_cls_input/test.rttm\n",
      "📝 Complete RTTM file saved to /home/nele_pauline_suffo/ProcessedData/audio_cls_input/complete.rttm\n",
      "✅ Combined DataFrame saved to /home/nele_pauline_suffo/ProcessedData/audio_cls_input/annotations_gt_id_split.pkl (48519 rows)\n",
      "✅ Combined UEM file saved to /home/nele_pauline_suffo/ProcessedData/audio_cls_input/complete.uem\n",
      "✅ .lst and .uem files created for all splits.\n",
      "\n",
      "✅ Total processed files: 192\n",
      "\n",
      "🎙️ Total speaker durations across all splits (minutes):\n",
      "  KCHI: 963.44 minutes\n",
      "  CHI: 53.55 minutes\n",
      "  FEM: 492.96 minutes\n",
      "  MAL: 223.41 minutes\n",
      "  SPEECH: 2158.24 minutes\n",
      "\n",
      "📊 Speaker durations per split (minutes):\n",
      "\n",
      "  TRAIN:\n",
      "    KCHI: 744.64 min (77.3% of total KCHI)\n",
      "    CHI: 41.84 min (78.1% of total CHI)\n",
      "    FEM: 382.23 min (77.5% of total FEM)\n",
      "    MAL: 187.93 min (84.1% of total MAL)\n",
      "    SPEECH: 1696.49 min (78.6% of total SPEECH)\n",
      "\n",
      "  DEV:\n",
      "    KCHI: 109.23 min (11.3% of total KCHI)\n",
      "    CHI: 8.13 min (15.2% of total CHI)\n",
      "    FEM: 65.40 min (13.3% of total FEM)\n",
      "    MAL: 16.85 min (7.5% of total MAL)\n",
      "    SPEECH: 233.93 min (10.8% of total SPEECH)\n",
      "\n",
      "  TEST:\n",
      "    KCHI: 109.56 min (11.4% of total KCHI)\n",
      "    CHI: 3.57 min (6.7% of total CHI)\n",
      "    FEM: 45.33 min (9.2% of total FEM)\n",
      "    MAL: 18.63 min (8.3% of total MAL)\n",
      "    SPEECH: 227.82 min (10.6% of total SPEECH)\n",
      "\n",
      "📊 Final split summary:\n",
      "  Train: 38 IDs, 144 files\n",
      "  Dev:   10 IDs, 23 files\n",
      "  Test:  10 IDs, 25 files\n",
      "  Total: 58 unique IDs, 192 files\n",
      "📝 RTTM file for test split saved to /home/nele_pauline_suffo/ProcessedData/audio_cls_input/test.rttm\n",
      "📝 Complete RTTM file saved to /home/nele_pauline_suffo/ProcessedData/audio_cls_input/complete.rttm\n",
      "✅ Combined DataFrame saved to /home/nele_pauline_suffo/ProcessedData/audio_cls_input/annotations_gt_id_split.pkl (48519 rows)\n",
      "✅ Combined UEM file saved to /home/nele_pauline_suffo/ProcessedData/audio_cls_input/complete.uem\n",
      "✅ .lst and .uem files created for all splits.\n",
      "\n",
      "✅ Total processed files: 192\n",
      "\n",
      "🎙️ Total speaker durations across all splits (minutes):\n",
      "  KCHI: 963.44 minutes\n",
      "  CHI: 53.55 minutes\n",
      "  FEM: 492.96 minutes\n",
      "  MAL: 223.41 minutes\n",
      "  SPEECH: 2158.24 minutes\n",
      "\n",
      "📊 Speaker durations per split (minutes):\n",
      "\n",
      "  TRAIN:\n",
      "    KCHI: 744.64 min (77.3% of total KCHI)\n",
      "    CHI: 41.84 min (78.1% of total CHI)\n",
      "    FEM: 382.23 min (77.5% of total FEM)\n",
      "    MAL: 187.93 min (84.1% of total MAL)\n",
      "    SPEECH: 1696.49 min (78.6% of total SPEECH)\n",
      "\n",
      "  DEV:\n",
      "    KCHI: 109.23 min (11.3% of total KCHI)\n",
      "    CHI: 8.13 min (15.2% of total CHI)\n",
      "    FEM: 65.40 min (13.3% of total FEM)\n",
      "    MAL: 16.85 min (7.5% of total MAL)\n",
      "    SPEECH: 233.93 min (10.8% of total SPEECH)\n",
      "\n",
      "  TEST:\n",
      "    KCHI: 109.56 min (11.4% of total KCHI)\n",
      "    CHI: 3.57 min (6.7% of total CHI)\n",
      "    FEM: 45.33 min (9.2% of total FEM)\n",
      "    MAL: 18.63 min (8.3% of total MAL)\n",
      "    SPEECH: 227.82 min (10.6% of total SPEECH)\n",
      "\n",
      "📊 Final split summary:\n",
      "  Train: 38 IDs, 144 files\n",
      "  Dev:   10 IDs, 23 files\n",
      "  Test:  10 IDs, 25 files\n",
      "  Total: 58 unique IDs, 192 files\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Process each split and write RTTM files with ID-based splitting\n",
    "all_df_rows = []\n",
    "all_rttm_lines_combined = []\n",
    "speaker_durations = Counter()  # Track total durations\n",
    "split_speaker_durations = defaultdict(Counter)  # Track durations per split per class\n",
    "\n",
    "for split_name, files_in_split in splits.items():\n",
    "    rttm_lines_split = []\n",
    "    \n",
    "    for f_info in files_in_split:\n",
    "        try:\n",
    "            with open(f_info[\"path\"], \"r\") as file_handle:\n",
    "                data = json.load(file_handle)\n",
    "            \n",
    "            uri = data.get('video_name', '')\n",
    "            participant_id = f_info.get('participant_id', 'UNKNOWN')\n",
    "            \n",
    "            # Process annotations\n",
    "            for annotation in data.get('annotations', []):\n",
    "                try:\n",
    "                    event_id = annotation.get('eventId', '')\n",
    "                    \n",
    "                    if event_id not in valid_event_ids:\n",
    "                        continue\n",
    "                        \n",
    "                    # Get timing information\n",
    "                    start_sec = annotation.get('startTime', 0)\n",
    "                    end_sec = annotation.get('endTime', 0)\n",
    "                    duration_sec = end_sec - start_sec\n",
    "                    \n",
    "                    if duration_sec <= 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Map event IDs to speaker IDs\n",
    "                    speaker_id = \"NA\"\n",
    "                    fields = annotation.get('fields', {})\n",
    "                    \n",
    "                    if event_id in [\"child_talking\", \"singing/humming\"]:\n",
    "                        speaker_id = \"KCHI\"\n",
    "                    elif event_id == \"other_person_talking\":\n",
    "                        age_group = fields.get(\"1st Person Age Group\", \"\")\n",
    "                        gender = fields.get(\"1st Person Gender\", \"\")\n",
    "                        \n",
    "                        if age_group in [\"Child\", \"Infant\"]:\n",
    "                            speaker_id = \"CHI\"\n",
    "                        elif age_group in [\"Adult\", \"Adolescent\"]:\n",
    "                            if gender == \"Female\":\n",
    "                                speaker_id = \"FEM\"\n",
    "                            elif gender == \"Male\":\n",
    "                                speaker_id = \"MAL\"\n",
    "                    elif event_id == \"overheard_speech\":\n",
    "                        speaker_id = \"SPEECH\"     \n",
    "\n",
    "                    if speaker_id in [\"KCHI\", \"CHI\", \"FEM\", \"MAL\", \"SPEECH\"]:\n",
    "                        # RTTM line with participant ID in the last field\n",
    "                        rttm_line = f\"SPEAKER {uri} 1 {start_sec:.3f} {duration_sec:.3f} <NA> <NA> {speaker_id} <NA> <NA>\"\n",
    "                        rttm_lines_split.append(rttm_line)\n",
    "                        all_rttm_lines_combined.append(rttm_line)\n",
    "                        \n",
    "                        # Add duration tracking (total and per split)\n",
    "                        duration_minutes = duration_sec / 60.0\n",
    "                        speaker_durations[speaker_id] += duration_minutes\n",
    "                        split_speaker_durations[split_name][speaker_id] += duration_minutes\n",
    "                        \n",
    "                        # Add additional SPEECH line only for non-SPEECH speakers\n",
    "                        if speaker_id != \"SPEECH\":\n",
    "                            rttm_line_speech = f\"SPEAKER {uri} 1 {start_sec:.3f} {duration_sec:.3f} <NA> <NA> SPEECH <NA> <NA>\"\n",
    "                            rttm_lines_split.append(rttm_line_speech)\n",
    "                            all_rttm_lines_combined.append(rttm_line_speech)\n",
    "                            speaker_durations[\"SPEECH\"] += duration_minutes\n",
    "                            split_speaker_durations[split_name][\"SPEECH\"] += duration_minutes\n",
    "                        \n",
    "                        # DataFrame row for specific voice type\n",
    "                        row_data_specific = {\n",
    "                            \"audio_file_name\": uri,\n",
    "                            \"Utterance_Start\": round(start_sec, 3),\n",
    "                            \"Utterance_Duration\": round(duration_sec, 3),\n",
    "                            \"Voice_type\": speaker_id,\n",
    "                            \"Utterance_End\": round(end_sec, 3),\n",
    "                            \"Participant_ID\": participant_id,\n",
    "                            \"Split\": split_name\n",
    "                        }\n",
    "                        all_df_rows.append(row_data_specific)\n",
    "\n",
    "                        # DataFrame row for SPEECH (only for non-SPEECH speakers)\n",
    "                        if speaker_id != \"SPEECH\":\n",
    "                            row_data_speech = {\n",
    "                                \"audio_file_name\": uri,\n",
    "                                \"Utterance_Start\": round(start_sec, 3),\n",
    "                                \"Utterance_Duration\": round(duration_sec, 3),\n",
    "                                \"Voice_type\": \"SPEECH\",\n",
    "                                \"Utterance_End\": round(end_sec, 3),\n",
    "                                \"Participant_ID\": participant_id,\n",
    "                                \"Split\": split_name\n",
    "                            }\n",
    "                            all_df_rows.append(row_data_speech)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping annotation in {f_info['path']}: {e}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {f_info['path']}: {e}\")\n",
    "    \n",
    "    # Save RTTM file for current split\n",
    "    rttm_path_split = output_dir / f\"{split_name}.rttm\"\n",
    "    with open(rttm_path_split, \"w\") as out_f:\n",
    "        for line in rttm_lines_split:\n",
    "            out_f.write(line + \"\\n\")\n",
    "    print(f\"📝 RTTM file for {split_name} split saved to {rttm_path_split}\")\n",
    "\n",
    "# Save complete RTTM file\n",
    "complete_rttm_path = output_dir / \"complete.rttm\"\n",
    "with open(complete_rttm_path, \"w\") as out_f:\n",
    "    for line in all_rttm_lines_combined:\n",
    "        out_f.write(line + \"\\n\")\n",
    "print(f\"📝 Complete RTTM file saved to {complete_rttm_path}\")\n",
    "\n",
    "# Create and save DataFrame\n",
    "if all_df_rows:\n",
    "    combined_df = pd.DataFrame(all_df_rows)\n",
    "    combined_df = combined_df[[\"audio_file_name\", \"Utterance_Start\", \"Utterance_Duration\", \n",
    "                              \"Voice_type\", \"Utterance_End\", \"Participant_ID\", \"Split\"]]\n",
    "    \n",
    "    df_pkl_path = output_dir / \"annotations_gt_id_split.pkl\"\n",
    "    combined_df.to_pickle(df_pkl_path)\n",
    "    print(f\"✅ Combined DataFrame saved to {df_pkl_path} ({len(combined_df)} rows)\")\n",
    "else:\n",
    "    print(\"ℹ️ No data to create DataFrame.\")\n",
    "\n",
    "# Save UEM files\n",
    "all_files_flat = train_files + dev_files + test_files\n",
    "uem_lines = []\n",
    "for f in all_files_flat:\n",
    "    uri = f[\"uri\"]\n",
    "    start_time = 0.000\n",
    "    end_time = f[\"duration\"]\n",
    "    uem_lines.append(f\"{uri} 1 {start_time:.3f} {end_time:.3f}\")\n",
    "\n",
    "uem_path = output_dir / \"complete.uem\"\n",
    "with open(uem_path, \"w\") as uem_file:\n",
    "    for line in uem_lines:\n",
    "        uem_file.write(line + \"\\n\")\n",
    "print(f\"✅ Combined UEM file saved to {uem_path}\")\n",
    "\n",
    "# Generate split-specific files (.lst and .uem)\n",
    "for split_name, files in splits.items():\n",
    "    # .lst file\n",
    "    lst_path = output_dir / f\"{split_name}.lst\"\n",
    "    with open(lst_path, \"w\") as lst_file:\n",
    "        for f in files:\n",
    "            lst_file.write(f\"{f['uri']}\\n\")\n",
    "    \n",
    "    # .uem file\n",
    "    uem_path = output_dir / f\"{split_name}.uem\"\n",
    "    with open(uem_path, \"w\") as uem_file:\n",
    "        for f in files:\n",
    "            uri = f[\"uri\"]\n",
    "            start = 0\n",
    "            end = f[\"duration\"]\n",
    "            uem_line = f\"{uri} 1 {start:.3f} {end:.3f}\"\n",
    "            uem_file.write(uem_line + \"\\n\")\n",
    "\n",
    "print(\"✅ .lst and .uem files created for all splits.\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n✅ Total processed files: {len(all_files_flat)}\")\n",
    "\n",
    "print(\"\\n🎙️ Total speaker durations across all splits (minutes):\")\n",
    "for speaker_id in ['KCHI', 'CHI', 'FEM', 'MAL', 'SPEECH']:\n",
    "    duration_minutes = speaker_durations[speaker_id]\n",
    "    print(f\"  {speaker_id}: {duration_minutes:.2f} minutes\")\n",
    "\n",
    "print(\"\\n📊 Speaker durations per split (minutes):\")\n",
    "for split_name in [\"train\", \"dev\", \"test\"]:\n",
    "    print(f\"\\n  {split_name.upper()}:\")\n",
    "    for speaker_id in ['KCHI', 'CHI', 'FEM', 'MAL', 'SPEECH']:\n",
    "        duration_minutes = split_speaker_durations[split_name][speaker_id]\n",
    "        total_duration = speaker_durations[speaker_id]\n",
    "        percentage = (duration_minutes / total_duration * 100) if total_duration > 0 else 0\n",
    "        print(f\"    {speaker_id}: {duration_minutes:.2f} min ({percentage:.1f}% of total {speaker_id})\")\n",
    "\n",
    "print(f\"\\n📊 Final split summary:\")\n",
    "print(f\"  Train: {len(train_ids)} IDs, {len(train_files)} files\")\n",
    "print(f\"  Dev:   {len(dev_ids)} IDs, {len(dev_files)} files\") \n",
    "print(f\"  Test:  {len(test_ids)} IDs, {len(test_files)} files\")\n",
    "print(f\"  Total: {len(id_to_files)} unique IDs, {len(all_files_flat)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a696f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44a6ad67",
   "metadata": {},
   "source": [
    "## Copy Test Files to Destination Folder\n",
    "\n",
    "Copy all audio files listed in test.lst from source directory to destination directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b5511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source directory: /home/nele_pauline_suffo/ProcessedData/childlens_audio\n",
      "Destination directory: /home/nele_pauline_suffo/ProcessedData/childlens_audio_test\n",
      "Test list file: /home/nele_pauline_suffo/ProcessedData/audio_cls_input/test.lst\n",
      "\n",
      "Found 25 video files in test.lst\n",
      "✅ Copied: 252685.MP4.wav\n",
      "✅ Copied: 252685.MP4.wav\n",
      "✅ Copied: 306565.MP4.wav\n",
      "✅ Copied: 306565.MP4.wav\n",
      "✅ Copied: 365908.MP4.wav\n",
      "✅ Copied: 365908.MP4.wav\n",
      "✅ Copied: 282498.MP4.wav\n",
      "✅ Copied: 282498.MP4.wav\n",
      "✅ Copied: 417338.MP4.wav\n",
      "✅ Copied: 417338.MP4.wav\n",
      "✅ Copied: 384179.MP4.wav\n",
      "✅ Copied: 384179.MP4.wav\n",
      "✅ Copied: 326740.MP4.wav\n",
      "✅ Copied: 326740.MP4.wav\n",
      "✅ Copied: 610898.MP4.wav\n",
      "✅ Copied: 610898.MP4.wav\n",
      "✅ Copied: 403769.MP4.wav\n",
      "✅ Copied: 403769.MP4.wav\n",
      "✅ Copied: 519475.MP4.wav\n",
      "✅ Copied: 519475.MP4.wav\n",
      "✅ Copied: 512533.MP4.wav\n",
      "✅ Copied: 512533.MP4.wav\n",
      "✅ Copied: 488644.MP4.wav\n",
      "✅ Copied: 488644.MP4.wav\n",
      "✅ Copied: 261047.MP4.wav\n",
      "✅ Copied: 560558.MP4.wav\n",
      "✅ Copied: 261047.MP4.wav\n",
      "✅ Copied: 560558.MP4.wav\n",
      "✅ Copied: 797582.MP4.wav\n",
      "✅ Copied: 797582.MP4.wav\n",
      "✅ Copied: 139665.MP4.wav\n",
      "✅ Copied: 139665.MP4.wav\n",
      "✅ Copied: 319731.MP4.wav\n",
      "✅ Copied: 319731.MP4.wav\n",
      "✅ Copied: 275212.MP4.wav\n",
      "✅ Copied: 275212.MP4.wav\n",
      "✅ Copied: 779724.MP4.wav\n",
      "✅ Copied: 779724.MP4.wav\n",
      "✅ Copied: 540246.MP4.wav\n",
      "✅ Copied: 540246.MP4.wav\n",
      "✅ Copied: 634172.MP4.wav\n",
      "✅ Copied: 634172.MP4.wav\n",
      "✅ Copied: 160606.MP4.wav\n",
      "✅ Copied: 160606.MP4.wav\n",
      "✅ Copied: 622757.MP4.wav\n",
      "✅ Copied: 622757.MP4.wav\n",
      "✅ Copied: 536025.MP4.wav\n",
      "✅ Copied: 536025.MP4.wav\n",
      "✅ Copied: 409468.MP4.wav\n",
      "\n",
      "📊 Copy Summary:\n",
      "  Successfully copied: 25 files\n",
      "  Missing files: 0 files\n",
      "  Total expected: 25 files\n",
      "\n",
      "✅ Test audio files copied to: /home/nele_pauline_suffo/ProcessedData/childlens_audio_test\n",
      "✅ Copied: 409468.MP4.wav\n",
      "\n",
      "📊 Copy Summary:\n",
      "  Successfully copied: 25 files\n",
      "  Missing files: 0 files\n",
      "  Total expected: 25 files\n",
      "\n",
      "✅ Test audio files copied to: /home/nele_pauline_suffo/ProcessedData/childlens_audio_test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Define source and destination directories\n",
    "source_dir = Path(\"/home/nele_pauline_suffo/ProcessedData/childlens_audio\")  # Folder X - where audio files are stored\n",
    "destination_dir = Path(\"/home/nele_pauline_suffo/ProcessedData/childlens_audio/childlens_audio_test\")  # Folder Y - where to copy test files\n",
    "test_lst_path = output_dir / \"test.lst\"  # Path to test.lst file\n",
    "\n",
    "# Create destination directory if it doesn't exist\n",
    "destination_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Source directory: {source_dir}\")\n",
    "print(f\"Destination directory: {destination_dir}\")\n",
    "print(f\"Test list file: {test_lst_path}\")\n",
    "\n",
    "# Read test.lst file to get list of video files\n",
    "if test_lst_path.exists():\n",
    "    with open(test_lst_path, 'r') as f:\n",
    "        test_video_files = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    \n",
    "    print(f\"\\nFound {len(test_video_files)} video files in test.lst\")\n",
    "    \n",
    "    # Copy each audio file\n",
    "    copied_files = []\n",
    "    missing_files = []\n",
    "    \n",
    "    for video_file in test_video_files:\n",
    "        # Convert video filename to audio filename (MP4 -> wav)\n",
    "        audio_filename = video_file.replace('.MP4', '.MP4.wav').replace('.mp4', '.mp4.wav')\n",
    "        \n",
    "        source_path = source_dir / audio_filename\n",
    "        destination_path = destination_dir / audio_filename\n",
    "        \n",
    "        if source_path.exists():\n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                copied_files.append(audio_filename)\n",
    "                print(f\"✅ Copied: {audio_filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error copying {audio_filename}: {e}\")\n",
    "        else:\n",
    "            missing_files.append(audio_filename)\n",
    "            print(f\"⚠️ Missing: {audio_filename}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n📊 Copy Summary:\")\n",
    "    print(f\"  Successfully copied: {len(copied_files)} files\")\n",
    "    print(f\"  Missing files: {len(missing_files)} files\")\n",
    "    print(f\"  Total expected: {len(test_video_files)} files\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"\\n⚠️ Missing files:\")\n",
    "        for missing in missing_files[:10]:  # Show first 10 missing files\n",
    "            print(f\"    {missing}\")\n",
    "        if len(missing_files) > 10:\n",
    "            print(f\"    ... and {len(missing_files) - 10} more\")\n",
    "    \n",
    "    print(f\"\\n✅ Test audio files copied to: {destination_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ test.lst file not found at: {test_lst_path}\")\n",
    "    print(\"Make sure you've run the previous cells to generate the test.lst file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f87ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyannote",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
