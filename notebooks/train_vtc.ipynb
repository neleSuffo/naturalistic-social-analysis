{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb0f569",
   "metadata": {},
   "source": [
    "## Generate GT RTTM File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f9a2647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'572947': '280989',\n",
       " '319731': '280817',\n",
       " '570513': '280817',\n",
       " '275212': '280817',\n",
       " '139665': '280817',\n",
       " '667048': '280599',\n",
       " '796971': '280599',\n",
       " '387058': '280599',\n",
       " '532883': '280599',\n",
       " '805896': '280599',\n",
       " '331649': '280599',\n",
       " '208080': '280599',\n",
       " '891069': '280599',\n",
       " '418396': '280599',\n",
       " '309992': '280599',\n",
       " '425618': '280599',\n",
       " '682449': '280599',\n",
       " '261409': '280429',\n",
       " '778146': '280429',\n",
       " '424217': '280429',\n",
       " '300654': '280429',\n",
       " '183537': '279536',\n",
       " '918536': '279536',\n",
       " '209812': '279536',\n",
       " '445489': '279536',\n",
       " '225457': '279536',\n",
       " '978369': '279536',\n",
       " '541444': '277887',\n",
       " '720379': '277887',\n",
       " '126181': '275146',\n",
       " '287342': '275146',\n",
       " '405664': '271735',\n",
       " '448237': '271735',\n",
       " '639733': '271735',\n",
       " '924964': '271735',\n",
       " '980187': '271735',\n",
       " '401590': '271735',\n",
       " '586293': '271693',\n",
       " '850351': '271693',\n",
       " '447674': '271693',\n",
       " '720783': '271693',\n",
       " '185049': '271693',\n",
       " '711881': '271693',\n",
       " '904569': '271693',\n",
       " '684742': '271693',\n",
       " '956654': '271693',\n",
       " '106910': '271693',\n",
       " '403769': '266935',\n",
       " '610898': '266935',\n",
       " '326740': '266935',\n",
       " '533034': '266799',\n",
       " '297002': '266799',\n",
       " '987423': '266799',\n",
       " '493644': '266799',\n",
       " '686327': '266799',\n",
       " '954842': '266799',\n",
       " '503253': '266799',\n",
       " '802250': '266799',\n",
       " '994835': '266799',\n",
       " '207949': '266799',\n",
       " '171099': '266686',\n",
       " '463097': '266686',\n",
       " '973541': '266686',\n",
       " '835202': '266686',\n",
       " '410731': '266686',\n",
       " '860780': '266686',\n",
       " '756035': '266686',\n",
       " '998252': '266686',\n",
       " '440485': '266686',\n",
       " '360698': '266216',\n",
       " '100898': '266216',\n",
       " '895811': '266216',\n",
       " '861529': '266216',\n",
       " '212983': '266216',\n",
       " '940018': '266216',\n",
       " '367575': '266216',\n",
       " '339217': '266216',\n",
       " '688731': '265943',\n",
       " '729394': '265943',\n",
       " '227279': '265943',\n",
       " '540737': '265943',\n",
       " '324218': '265891',\n",
       " '108844': '265891',\n",
       " '886998': '265891',\n",
       " '864514': '265891',\n",
       " '519475': '265706',\n",
       " '934552': '265706',\n",
       " '488644': '265706',\n",
       " '512533': '265706',\n",
       " '884926': '265706',\n",
       " '575100': '265705',\n",
       " '504907': '265705',\n",
       " '868008': '265705',\n",
       " '390059': '265705',\n",
       " '646735': '265705',\n",
       " '414831': '265688',\n",
       " '319263': '265688',\n",
       " '772102': '265688',\n",
       " '442279': '265688',\n",
       " '353625': '265688',\n",
       " '370090': '265688',\n",
       " '637210': '265674',\n",
       " '650263': '265674',\n",
       " '863365': '265674',\n",
       " '117071': '265674',\n",
       " '817697': '265674',\n",
       " '750871': '265674',\n",
       " '289287': '265619',\n",
       " '206914': '265619',\n",
       " '850029': '265619',\n",
       " '483937': '265619',\n",
       " '800386': '265619',\n",
       " '923385': '265619',\n",
       " '779126': '265619',\n",
       " '204839': '265566',\n",
       " '284099': '265566',\n",
       " '371111': '265566',\n",
       " '714692': '265566',\n",
       " '916043': '265566',\n",
       " '310699': '264751',\n",
       " '504190': '264751',\n",
       " '528813': '264751',\n",
       " '883783': '264614',\n",
       " '475930': '264614',\n",
       " '305277': '264614',\n",
       " '579786': '264614',\n",
       " '346638': '264614',\n",
       " '975528': '264576',\n",
       " '653666': '264576',\n",
       " '152333': '264576',\n",
       " '821988': '264576',\n",
       " '940000': '264521',\n",
       " '977008': '264521',\n",
       " '727015': '264521',\n",
       " '259814': '264521',\n",
       " '497568': '264521',\n",
       " '905249': '264521',\n",
       " '697461': '264521',\n",
       " '861911': '264521',\n",
       " '536025': '264436',\n",
       " '622757': '264436',\n",
       " '160606': '264436',\n",
       " '818974': '264436',\n",
       " '991315': '264436',\n",
       " '684775': '264433',\n",
       " '629693': '264433',\n",
       " '592427': '264433',\n",
       " '553303': '264395',\n",
       " '283598': '264395',\n",
       " '911040': '264395',\n",
       " '268483': '264395',\n",
       " '386054': '264362',\n",
       " '641905': '264362',\n",
       " '746212': '264362',\n",
       " '214201': '264362',\n",
       " '629434': '264362',\n",
       " '128872': '264362',\n",
       " '553421': '264362',\n",
       " '114534': '264362',\n",
       " '619123': '264362',\n",
       " '666139': '264362',\n",
       " '336244': '264304',\n",
       " '545661': '264304',\n",
       " '467868': '264304',\n",
       " '650943': '264304',\n",
       " '690297': '264304',\n",
       " '533763': '264304',\n",
       " '629077': '263338',\n",
       " '124215': '263338',\n",
       " '897101': '263338',\n",
       " '778685': '263338',\n",
       " '639397': '263338',\n",
       " '153069': '263229',\n",
       " '207115': '263229',\n",
       " '486149': '263229',\n",
       " '915559': '263229',\n",
       " '882144': '263157',\n",
       " '779724': '263157',\n",
       " '989852': '263157',\n",
       " '719283': '262944',\n",
       " '306565': '262944',\n",
       " '654017': '262944',\n",
       " '824948': '262944',\n",
       " '597649': '262944',\n",
       " '812330': '262944',\n",
       " '252685': '262944',\n",
       " '264487': '262703',\n",
       " '414660': '262703',\n",
       " '351105': '262703',\n",
       " '932920': '262703',\n",
       " '581003': '262703',\n",
       " '614682': '262703',\n",
       " '560902': '262703',\n",
       " '365908': '262661',\n",
       " '282498': '262661',\n",
       " '417338': '262661',\n",
       " '384179': '262661',\n",
       " '225742': '262564',\n",
       " '888824': '262564',\n",
       " '310644': '262564',\n",
       " '728100': '262564',\n",
       " '796165': '262564',\n",
       " '607715': '262472',\n",
       " '692696': '262472',\n",
       " '273077': '262472',\n",
       " '543575': '262472',\n",
       " '184452': '262472',\n",
       " '189224': '262472',\n",
       " '852015': '262472',\n",
       " '604034': '262472',\n",
       " '778718': '262381',\n",
       " '378856': '262381',\n",
       " '781206': '262381',\n",
       " '119281': '262381',\n",
       " '730014': '262381',\n",
       " '205296': '262381',\n",
       " '993351': '262381',\n",
       " '364368': '262222',\n",
       " '665704': '262222',\n",
       " '516537': '262222',\n",
       " '757253': '262222',\n",
       " '556915': '262222',\n",
       " '267118': '262222',\n",
       " '457472': '262181',\n",
       " '741611': '262181',\n",
       " '934347': '262181',\n",
       " '830965': '262181',\n",
       " '537865': '262181',\n",
       " '432722': '262020',\n",
       " '984090': '262020',\n",
       " '713084': '262020',\n",
       " '524655': '262020',\n",
       " '252829': '262020',\n",
       " '658937': '262020',\n",
       " '607845': '262020',\n",
       " '662112': '262020',\n",
       " '890139': '260777',\n",
       " '468002': '260777',\n",
       " '445266': '260777',\n",
       " '581130': '260777',\n",
       " '244555': '260777',\n",
       " '572376': '260777',\n",
       " '933580': '260777',\n",
       " '520498': '260777',\n",
       " '418220': '260730',\n",
       " '341934': '260730',\n",
       " '243869': '260730',\n",
       " '797046': '260730',\n",
       " '840607': '260730',\n",
       " '944344': '260730',\n",
       " '987009': '260730',\n",
       " '394148': '260730',\n",
       " '641026': '260730',\n",
       " '390182': '260730',\n",
       " '172864': '260730',\n",
       " '672793': '260455',\n",
       " '385152': '260455',\n",
       " '172296': '260455',\n",
       " '953046': '260444',\n",
       " '472508': '260444',\n",
       " '121497': '260444',\n",
       " '685378': '260439',\n",
       " '476848': '260439',\n",
       " '940710': '260439',\n",
       " '748621': '260439',\n",
       " '190053': '260439',\n",
       " '826118': '260439',\n",
       " '195594': '260439',\n",
       " '520977': '260439',\n",
       " '217622': '260439',\n",
       " '783192': '260040',\n",
       " '138513': '260040',\n",
       " '847675': '260040',\n",
       " '290185': '260040',\n",
       " '210803': '260040',\n",
       " '147984': '267139',\n",
       " '136375': '267139',\n",
       " '487661': '267139',\n",
       " '208409': '267139',\n",
       " '937461': '267139',\n",
       " '847066': '267139',\n",
       " '547935': '267139',\n",
       " '776563': '262174',\n",
       " '186666': '262174',\n",
       " '776910': '262174',\n",
       " '182442': '262273',\n",
       " '996295': '262273',\n",
       " '139229': '262273',\n",
       " '393278': '262273',\n",
       " '542919': '262273',\n",
       " '979114': '262273',\n",
       " '350145': '260062',\n",
       " '803220': '260062',\n",
       " '740360': '260062',\n",
       " '952804': '260062',\n",
       " '879221': '260062',\n",
       " '159353': '266369',\n",
       " '165669': '266369',\n",
       " '606439': '266369',\n",
       " '423978': '266369',\n",
       " '647486': '266369',\n",
       " '287625': '266369',\n",
       " '262568': '266369',\n",
       " '609929': '279886',\n",
       " '541327': '279886',\n",
       " '862825': '279886',\n",
       " '300334': '279886',\n",
       " '146267': '279886',\n",
       " '641755': '262920',\n",
       " '390209': '262920',\n",
       " '792524': '262920',\n",
       " '694155': '262920',\n",
       " '336900': '262920',\n",
       " '259352': '262920',\n",
       " '400771': '262920',\n",
       " '991881': '262920',\n",
       " '554591': '268900',\n",
       " '741214': '268900',\n",
       " '404814': '268900',\n",
       " '548219': '280427',\n",
       " '619306': '280427',\n",
       " '132027': '280427',\n",
       " '860071': '280427',\n",
       " '415671': '280427',\n",
       " '757621': '279613',\n",
       " '375776': '279613',\n",
       " '261047': '279613',\n",
       " '797582': '279613',\n",
       " '231487': '279613',\n",
       " '560558': '279613',\n",
       " '667115': '275146',\n",
       " '961899': '275146',\n",
       " '670066': '275146',\n",
       " '851137': '263265',\n",
       " '883713': '263265',\n",
       " '790249': '263265',\n",
       " '756803': '263265',\n",
       " '475070': '263265',\n",
       " '308207': '273291',\n",
       " '214010': '273291',\n",
       " '634589': '273291',\n",
       " '492251': '273291',\n",
       " '360697': '273291',\n",
       " '499008': '265568',\n",
       " '116170': '265568',\n",
       " '942723': '265568',\n",
       " '409468': '265568'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read xlsx\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "def read_xlsx(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} does not exist.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(file_path, engine='openpyxl')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "childlens_data = read_xlsx(\"/home/nele_pauline_suffo/ProcessedData/childlens_data_sheet.xlsx\")\n",
    "childlens_data[[\"ID\", \"SA_name\"]] \n",
    "# remove rows with NaN in 'ID' or 'SA_name' and convert 'ID' to int\n",
    "childlens_data = childlens_data.dropna(subset=['ID', 'SA_name'])\n",
    "childlens_data['ID'] = childlens_data['ID'].astype(int).astype(str)\n",
    "childlens_data[\"SA_name\"] = childlens_data[\"SA_name\"].astype(str)\n",
    "\n",
    "sa_name_to_id_dict = childlens_data.set_index('SA_name')['ID'].to_dict()\n",
    "sa_name_to_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e72621ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'262381'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_name_to_id_dict['205296']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c42d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù RTTM file for train split saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens/train.rttm\n",
      "üìù RTTM file for dev split saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens/dev.rttm\n",
      "üìù RTTM file for test split saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens/test.rttm\n",
      "üìù Complete RTTM file for all splits saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens/complete.rttm\n",
      "üìù RTTM file for train split saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens/train.rttm\n",
      "üìù RTTM file for dev split saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens/dev.rttm\n",
      "üìù RTTM file for test split saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens/test.rttm\n",
      "üìù Complete RTTM file for all splits saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens/complete.rttm\n",
      "‚úÖ Combined DataFrame for all splits saved to /home/nele_pauline_suffo/ProcessedData/childlens_annotations/processed/childlens_annotations_gt.pkl (48300 rows)\n",
      "‚úÖ Combined UEM file for all videos saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens/complete.uem (161 segments)\n",
      "\n",
      "‚úÖ Total processed files: 322\n",
      "\n",
      "üéôÔ∏è Speaker instance counts in all splits:\n",
      "  KCHI: 11595\n",
      "  CHI: 701\n",
      "  FEM: 6193\n",
      "  MAL: 2447\n",
      "  SPEECH: 75580\n",
      "\n",
      "üìä RTTM split durations and video counts:\n",
      "  train: 146244.93 sec (80.1%), 98 videos\n",
      "  dev: 18337.89 sec (10.0%), 23 videos\n",
      "  test: 17952.87 sec (9.8%), 40 videos\n",
      "‚úÖ .lst files created for train, development, and test splits.\n",
      "‚úÖ .uem files created for train, development, and test splits.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Folder and output paths\n",
    "input_folder = \"/home/nele_pauline_suffo/ProcessedData/childlens_annotations\"\n",
    "output_dir = Path(\"/home/nele_pauline_suffo/ProcessedData/vtc_childlens\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "valid_action_names = {\"Child Talking\", \"Other Person Talking\", \"Overheard Speech\", \"Singing/Humming\"}\n",
    "\n",
    "all_files = []\n",
    "speaker_counts = Counter()\n",
    "files_processed = 0\n",
    "\n",
    "# Step 1: Load all JSON files and collect metadata\n",
    "json_files = glob(f\"{input_folder}/*.json\")\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, \"r\") as f:\n",
    "            annotations = json.load(f)\n",
    "        uri = annotations['metadata']['name']\n",
    "        duration = annotations['metadata']['duration'] / 1_000_000  # microseconds to seconds\n",
    "        all_files.append({\n",
    "            \"path\": json_file,\n",
    "            \"uri\": uri,\n",
    "            \"duration\": duration\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {json_file} due to error: {e}\")\n",
    "\n",
    "# Step 2: Sort and split files by total duration\n",
    "all_files.sort(key=lambda x: x[\"duration\"], reverse=True)\n",
    "total_duration = sum(f[\"duration\"] for f in all_files)\n",
    "\n",
    "train_duration, dev_duration, test_duration = 0, 0, 0\n",
    "train_files, dev_files, test_files = [], [], []\n",
    "\n",
    "for f in all_files:\n",
    "    if train_duration < 0.8 * total_duration:\n",
    "        train_files.append(f)\n",
    "        train_duration += f[\"duration\"]\n",
    "    elif dev_duration < 0.1 * total_duration:\n",
    "        dev_files.append(f)\n",
    "        dev_duration += f[\"duration\"]\n",
    "    else:\n",
    "        test_files.append(f)\n",
    "        test_duration += f[\"duration\"]\n",
    "\n",
    "splits = {\n",
    "    \"train\": train_files,\n",
    "    \"dev\": dev_files,\n",
    "    \"test\": test_files\n",
    "}\n",
    "split_durations = {\n",
    "    \"train\": train_duration,\n",
    "    \"dev\": dev_duration,\n",
    "    \"test\": test_duration\n",
    "}\n",
    "\n",
    "# Step 3: Process each split and write RTTM\n",
    "all_df_rows = [] # Initialize list for DataFrame rows\n",
    "all_rttm_lines_combined = [] # Initialize list for all RTTM lines for the complete.rttm\n",
    "\n",
    "for split_name, files_in_split in splits.items():\n",
    "    rttm_lines_split = [] # RTTM lines for the current split\n",
    "\n",
    "    for f_info in files_in_split:\n",
    "        try:\n",
    "            with open(f_info[\"path\"], \"r\") as file_handle:\n",
    "                annotations = json.load(file_handle)\n",
    "            uri = annotations['metadata']['name']\n",
    "            files_processed += 1\n",
    "            \n",
    "            for instance in annotations.get('instances', []):\n",
    "                if instance[\"meta\"][\"type\"] != \"event\":\n",
    "                    continue\n",
    "                try:\n",
    "                    # Assuming the first parameter block contains the relevant timestamps and attributes\n",
    "                    if not instance[\"parameters\"] or not instance[\"parameters\"][0].get(\"timestamps\"):\n",
    "                        continue\n",
    "                    \n",
    "    \n",
    "                    parameter_block = instance[\"parameters\"][0]\n",
    "                    # Ensure 'timestamps' key exists and is a list\n",
    "                    if not isinstance(parameter_block.get(\"timestamps\"), list):\n",
    "                        continue\n",
    "                    \n",
    "                    # The 'start' and 'end' for the whole instance parameter block\n",
    "                    instance_start_time_us = parameter_block.get(\"start\")\n",
    "                    instance_end_time_us = parameter_block.get(\"end\")\n",
    "                    \n",
    "                    if instance_start_time_us is None or instance_end_time_us is None:\n",
    "                        pass\n",
    "                    \n",
    "                    for detail_idx, detail in enumerate(parameter_block[\"timestamps\"]):\n",
    "                        if \"attributes\" not in detail:\n",
    "                            continue\n",
    "                        \n",
    "                        action_type = next(\n",
    "                            (attr[\"name\"] for attr in detail[\"attributes\"]\n",
    "                             if attr[\"groupName\"] == \"Type of Action\"),\n",
    "                            None\n",
    "                        )  \n",
    "\n",
    "                        if action_type in valid_action_names:\n",
    "                            speaker_id = \"NA\"\n",
    "\n",
    "                            if action_type in [\"Child Talking\", \"Singing/Humming\"]:\n",
    "                                speaker_id = \"KCHI\"\n",
    "                            elif action_type == \"Other Person Talking\":\n",
    "                                age_group = next(\n",
    "                                    (attr[\"name\"] for attr in detail[\"attributes\"]\n",
    "                                     if attr[\"groupName\"] == \"1st Person Age Group\"),\n",
    "                                    None\n",
    "                                )\n",
    "                                gender = next(\n",
    "                                    (attr[\"name\"] for attr in detail[\"attributes\"]\n",
    "                                     if attr[\"groupName\"] == \"1st Person Gender\"),\n",
    "                                    None\n",
    "                                )\n",
    "\n",
    "                                if age_group in [\"Child\", \"Infant\"]:\n",
    "                                    speaker_id = \"CHI\"\n",
    "                                elif age_group in [\"Adult\", \"Adolescent\"]:\n",
    "                                    if gender == \"Female\":\n",
    "                                        speaker_id = \"FEM\"\n",
    "                                    elif gender == \"Male\":\n",
    "                                        speaker_id = \"MAL\"\n",
    "                            elif action_type == \"Overheard Speech\":\n",
    "                                speaker_id = \"SPEECH\"\n",
    "\n",
    "                       \n",
    "                            # Correctly use segment start/end from the parameter_block\n",
    "                            # (which was referred to as 'timestamps' variable in original code)\n",
    "                            segment_start_us = parameter_block.get(\"start\")\n",
    "                            segment_end_us = parameter_block.get(\"end\")\n",
    "                            \n",
    "                            \n",
    "                            if segment_start_us is None or segment_end_us is None:\n",
    "                                print(f\"Warning: Missing start/end in parameter block for instance in {f_info['path']}. Skipping.\")\n",
    "                                continue\n",
    "                            \n",
    "                            \n",
    "                            start_sec = segment_start_us / 1_000_000\n",
    "                            end_sec = segment_end_us / 1_000_000\n",
    "                            duration_sec = end_sec - start_sec\n",
    "\n",
    "                            if duration_sec <= 0: # Ensure duration is positive\n",
    "                                print(f\"Warning: Non-positive duration {duration_sec:.3f}s for segment in {f_info['path']}. Skipping.\")\n",
    "                                continue\n",
    "                            \n",
    "                            rttm_line = f\"SPEAKER {uri} 1 {start_sec:.3f} {duration_sec:.3f} <NA> <NA> {speaker_id} <NA> <NA>\"\n",
    "                            rttm_line_speech = f\"SPEAKER {uri} 1 {start_sec:.3f} {duration_sec:.3f} <NA> <NA> SPEECH <NA> <NA>\"\n",
    "\n",
    "                            if speaker_id != \"NA\":\n",
    "                                rttm_lines_split.append(rttm_line)\n",
    "                                all_rttm_lines_combined.append(rttm_line) # Add to combined list\n",
    "                                rttm_lines_split.append(rttm_line_speech) # RTTM gets both lines\n",
    "                                all_rttm_lines_combined.append(rttm_line_speech) # Add to combined list\n",
    "\n",
    "                                speaker_counts[speaker_id] += 1    # Counts original speaker_id (e.g. OCH)\n",
    "                                speaker_counts[\"SPEECH\"] += 1\n",
    "\n",
    "                                # Prepare data for DataFrame (only specific voice type, OCH mapped to CHI)\n",
    "                                row_data_specific = {\n",
    "                                    \"audio_file_name\": uri,\n",
    "                                    \"Utterance_Start\": round(start_sec, 3),\n",
    "                                    \"Utterance_Duration\": round(duration_sec, 3),\n",
    "                                    \"Voice_type\": speaker_id, # This will be KCHI, CHI, FEM, MAL\n",
    "                                    \"Utterance_End\": round(end_sec, 3)\n",
    "                                }\n",
    "                                all_df_rows.append(row_data_specific)\n",
    "                                \n",
    "                                # Add corresponding SPEECH entry for the DataFrame\n",
    "                                row_data_speech = {\n",
    "                                    \"audio_file_name\": uri,\n",
    "                                    \"Utterance_Start\": round(start_sec, 3),\n",
    "                                    \"Utterance_Duration\": round(duration_sec, 3),\n",
    "                                    \"Voice_type\": \"SPEECH\", # Add the SPEECH category\n",
    "                                    \"Utterance_End\": round(end_sec, 3)\n",
    "                                }\n",
    "                                all_df_rows.append(row_data_speech)\n",
    "                                \n",
    "                                # only use the first instance of each segment\n",
    "                                break\n",
    "                                \n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping instance in {f_info['path']} due to error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {f_info['path']}: {e}\")\n",
    "\n",
    "    # Save to RTTM file for the current split\n",
    "    rttm_path_split = output_dir / f\"{split_name}.rttm\"\n",
    "    with open(rttm_path_split, \"w\") as out_f:\n",
    "        for line in rttm_lines_split:\n",
    "            out_f.write(line + \"\\n\")\n",
    "    print(f\"üìù RTTM file for {split_name} split saved to {rttm_path_split}\")\n",
    "\n",
    "# Save the complete RTTM file after processing all splits\n",
    "complete_rttm_path = output_dir / \"complete.rttm\"\n",
    "with open(complete_rttm_path, \"w\") as out_f:\n",
    "    for line in all_rttm_lines_combined:\n",
    "        out_f.write(line + \"\\n\")\n",
    "print(f\"üìù Complete RTTM file for all splits saved to {complete_rttm_path}\")\n",
    "\n",
    "# Step 3: Process each split and write RTTM\n",
    "all_df_rows = [] # Initialize list for DataFrame rows\n",
    "all_rttm_lines_combined = [] # Initialize list for all RTTM lines for the complete.rttm\n",
    "\n",
    "for split_name, files_in_split in splits.items():\n",
    "    rttm_lines_split = [] # RTTM lines for the current split\n",
    "\n",
    "    for f_info in files_in_split:\n",
    "        try:\n",
    "            with open(f_info[\"path\"], \"r\") as file_handle:\n",
    "                annotations = json.load(file_handle)\n",
    "            uri = annotations['metadata']['name']\n",
    "            # get \n",
    "            child_id = sa_name_to_id_dict.get(uri, \"UNKNOWN_CHILD_ID\")\n",
    "            files_processed += 1\n",
    "            \n",
    "            for instance in annotations.get('instances', []):\n",
    "                if instance[\"meta\"][\"type\"] != \"event\":\n",
    "                    continue\n",
    "                try:\n",
    "                    # Assuming the first parameter block contains the relevant timestamps and attributes\n",
    "                    if not instance[\"parameters\"] or not instance[\"parameters\"][0].get(\"timestamps\"):\n",
    "                        continue\n",
    "                    \n",
    "    \n",
    "                    parameter_block = instance[\"parameters\"][0]\n",
    "                    # Ensure 'timestamps' key exists and is a list\n",
    "                    if not isinstance(parameter_block.get(\"timestamps\"), list):\n",
    "                        continue\n",
    "                    \n",
    "                    # The 'start' and 'end' for the whole instance parameter block\n",
    "                    instance_start_time_us = parameter_block.get(\"start\")\n",
    "                    instance_end_time_us = parameter_block.get(\"end\")\n",
    "                    \n",
    "                    if instance_start_time_us is None or instance_end_time_us is None:\n",
    "                        pass\n",
    "                    \n",
    "                    for detail_idx, detail in enumerate(parameter_block[\"timestamps\"]):\n",
    "                        if \"attributes\" not in detail:\n",
    "                            continue\n",
    "                        \n",
    "                        action_type = next(\n",
    "                            (attr[\"name\"] for attr in detail[\"attributes\"]\n",
    "                             if attr[\"groupName\"] == \"Type of Action\"),\n",
    "                            None\n",
    "                        )  \n",
    "\n",
    "                        if action_type in valid_action_names:\n",
    "                            speaker_id = \"NA\"\n",
    "\n",
    "                            if action_type in [\"Child Talking\", \"Singing/Humming\"]:\n",
    "                                speaker_id = \"KCHI\"\n",
    "                            elif action_type == \"Other Person Talking\":\n",
    "                                age_group = next(\n",
    "                                    (attr[\"name\"] for attr in detail[\"attributes\"]\n",
    "                                     if attr[\"groupName\"] == \"1st Person Age Group\"),\n",
    "                                    None\n",
    "                                )\n",
    "                                gender = next(\n",
    "                                    (attr[\"name\"] for attr in detail[\"attributes\"]\n",
    "                                     if attr[\"groupName\"] == \"1st Person Gender\"),\n",
    "                                    None\n",
    "                                )\n",
    "\n",
    "                                if age_group in [\"Child\", \"Infant\"]:\n",
    "                                    speaker_id = \"CHI\"\n",
    "                                elif age_group in [\"Adult\", \"Adolescent\"]:\n",
    "                                    if gender == \"Female\":\n",
    "                                        speaker_id = \"FEM\"\n",
    "                                    elif gender == \"Male\":\n",
    "                                        speaker_id = \"MAL\"\n",
    "                            elif action_type == \"Overheard Speech\":\n",
    "                                speaker_id = \"SPEECH\"\n",
    "\n",
    "                       \n",
    "                            # Correctly use segment start/end from the parameter_block\n",
    "                            # (which was referred to as 'timestamps' variable in original code)\n",
    "                            segment_start_us = parameter_block.get(\"start\")\n",
    "                            segment_end_us = parameter_block.get(\"end\")\n",
    "                            \n",
    "                            \n",
    "                            if segment_start_us is None or segment_end_us is None:\n",
    "                                print(f\"Warning: Missing start/end in parameter block for instance in {f_info['path']}. Skipping.\")\n",
    "                                continue\n",
    "                            \n",
    "                            \n",
    "                            start_sec = segment_start_us / 1_000_000\n",
    "                            end_sec = segment_end_us / 1_000_000\n",
    "                            duration_sec = end_sec - start_sec\n",
    "\n",
    "                            if duration_sec <= 0: # Ensure duration is positive\n",
    "                                print(f\"Warning: Non-positive duration {duration_sec:.3f}s for segment in {f_info['path']}. Skipping.\")\n",
    "                                continue\n",
    "                            \n",
    "                            rttm_line = f\"SPEAKER {uri} 1 {start_sec:.3f} {duration_sec:.3f} <NA> <NA> {speaker_id} <NA> <NA>\"\n",
    "                            rttm_line_speech = f\"SPEAKER {uri} 1 {start_sec:.3f} {duration_sec:.3f} <NA> <NA> SPEECH <NA> <NA>\"\n",
    "\n",
    "                            if speaker_id != \"NA\":\n",
    "                                rttm_lines_split.append(rttm_line)\n",
    "                                all_rttm_lines_combined.append(rttm_line) # Add to combined list\n",
    "                                rttm_lines_split.append(rttm_line_speech) # RTTM gets both lines\n",
    "                                all_rttm_lines_combined.append(rttm_line_speech) # Add to combined list\n",
    "\n",
    "                                speaker_counts[speaker_id] += 1    # Counts original speaker_id (e.g. OCH)\n",
    "                                speaker_counts[\"SPEECH\"] += 1\n",
    "\n",
    "                                # Prepare data for DataFrame (only specific voice type, OCH mapped to CHI)\n",
    "                                row_data_specific = {\n",
    "                                    \"audio_file_name\": uri,\n",
    "                                    \"Utterance_Start\": round(start_sec, 3),\n",
    "                                    \"Utterance_Duration\": round(duration_sec, 3),\n",
    "                                    \"Voice_type\": speaker_id, # This will be KCHI, CHI, FEM, MAL\n",
    "                                    \"Utterance_End\": round(end_sec, 3)\n",
    "                                }\n",
    "                                all_df_rows.append(row_data_specific)\n",
    "                                \n",
    "                                # Add corresponding SPEECH entry for the DataFrame\n",
    "                                row_data_speech = {\n",
    "                                    \"audio_file_name\": uri,\n",
    "                                    \"Utterance_Start\": round(start_sec, 3),\n",
    "                                    \"Utterance_Duration\": round(duration_sec, 3),\n",
    "                                    \"Voice_type\": \"SPEECH\", # Add the SPEECH category\n",
    "                                    \"Utterance_End\": round(end_sec, 3)\n",
    "                                }\n",
    "                                all_df_rows.append(row_data_speech)\n",
    "                                \n",
    "                                # only use the first instance of each segment\n",
    "                                break\n",
    "                                \n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping instance in {f_info['path']} due to error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {f_info['path']}: {e}\")\n",
    "\n",
    "    # Save to RTTM file for the current split\n",
    "    rttm_path_split = output_dir / f\"{split_name}.rttm\"\n",
    "    with open(rttm_path_split, \"w\") as out_f:\n",
    "        for line in rttm_lines_split:\n",
    "            out_f.write(line + \"\\n\")\n",
    "    print(f\"üìù RTTM file for {split_name} split saved to {rttm_path_split}\")\n",
    "\n",
    "# Save the complete RTTM file after processing all splits\n",
    "complete_rttm_path = output_dir / \"complete.rttm\"\n",
    "with open(complete_rttm_path, \"w\") as out_f:\n",
    "    for line in all_rttm_lines_combined:\n",
    "        out_f.write(line + \"\\n\")\n",
    "print(f\"üìù Complete RTTM file for all splits saved to {complete_rttm_path}\")\n",
    "\n",
    "# Create and save ONE COMBINED DataFrame after processing all splits\n",
    "if all_df_rows:\n",
    "    combined_df = pd.DataFrame(all_df_rows)\n",
    "    # Ensure desired column order\n",
    "    combined_df = combined_df[[\"audio_file_name\", \"Utterance_Start\", \"Utterance_Duration\", \"Voice_type\", \"Utterance_End\"]]\n",
    "    # Define the single output path for the combined pickle file\n",
    "    df_pkl_path = Path(\"/home/nele_pauline_suffo/ProcessedData/childlens_annotations/processed/childlens_annotations_gt.pkl\")\n",
    "    # Ensure the directory exists\n",
    "    df_pkl_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    combined_df.to_pickle(df_pkl_path)\n",
    "    print(f\"‚úÖ Combined DataFrame for all splits saved to {df_pkl_path} ({len(combined_df)} rows)\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è No data to create combined DataFrame.\")\n",
    "\n",
    "# Step 3.5: Save a complete UEM file with all video information\n",
    "uem_lines = []\n",
    "for f in all_files:\n",
    "    uri = f[\"uri\"]\n",
    "    start_time = 0.000\n",
    "    end_time = f[\"duration\"]\n",
    "    uem_lines.append(f\"{uri} 1 {start_time:.3f} {end_time:.3f}\")\n",
    "\n",
    "uem_path = output_dir / \"complete.uem\"\n",
    "with open(uem_path, \"w\") as uem_file:\n",
    "    for line in uem_lines:\n",
    "        uem_file.write(line + \"\\n\")\n",
    "print(f\"‚úÖ Combined UEM file for all videos saved to {uem_path} ({len(uem_lines)} segments)\")\n",
    "\n",
    "# Step 4: Summary logs\n",
    "print(f\"\\n‚úÖ Total processed files: {files_processed}\")\n",
    "print(\"\\nüéôÔ∏è Speaker instance counts in all splits:\")\n",
    "for speaker_id in ['KCHI', 'CHI', 'FEM', 'MAL', 'SPEECH']:\n",
    "    print(f\"  {speaker_id}: {speaker_counts[speaker_id]}\")\n",
    "\n",
    "print(\"\\nüìä RTTM split durations and video counts:\")\n",
    "for split_name in [\"train\", \"dev\", \"test\"]:\n",
    "    dur = split_durations[split_name]\n",
    "    perc = (dur / total_duration) * 100\n",
    "    count = len(splits[split_name])\n",
    "    print(f\"  {split_name}: {dur:.2f} sec ({perc:.1f}%), {count} videos\")\n",
    "\n",
    "# Generate .lst files for train, development, and test splits\n",
    "for split_name, files in splits.items():\n",
    "    lst_path = output_dir / f\"{split_name}.lst\"\n",
    "    with open(lst_path, \"w\") as lst_file:\n",
    "        for f in files:\n",
    "            lst_file.write(f\"{f['uri']}\\n\")\n",
    "\n",
    "print(\"‚úÖ .lst files created for train, development, and test splits.\")\n",
    "\n",
    "# Generate .uem files for train, development, and test splits\n",
    "for split_name, files in splits.items():\n",
    "    uem_path = output_dir / f\"{split_name}.uem\"\n",
    "    with open(uem_path, \"w\") as uem_file:\n",
    "        for f in files:\n",
    "            try:\n",
    "                # Extract the URI and duration for each video\n",
    "                uri = f[\"uri\"]\n",
    "                start = 0  # Start time is always 0\n",
    "                end = f[\"duration\"]  # End time is the video's duration\n",
    "\n",
    "                # Write a single line for each video\n",
    "                uem_line = f\"{uri} 1 {start:.3f} {end:.3f}\"\n",
    "                uem_file.write(uem_line + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {f['path']}: {e}\")\n",
    "\n",
    "print(\"‚úÖ .uem files created for train, development, and test splits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e18f98",
   "metadata": {},
   "source": [
    "## Generate GT RTTM File for ChildLens_v2 VTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e75af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù RTTM file for train split saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens_v2/train.rttm\n",
      "üìù RTTM file for dev split saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens_v2/dev.rttm\n",
      "üìù RTTM file for test split saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens_v2/test.rttm\n",
      "üìù Complete RTTM file for v2 (all splits) saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens_v2/complete.rttm\n",
      "‚úÖ Combined DataFrame for all splits saved to /home/nele_pauline_suffo/ProcessedData/childlens_annotations/processed/childlens_annotations_gt_v2.pkl (24150 rows)\n",
      "‚úÖ Combined UEM file for all videos saved to /home/nele_pauline_suffo/ProcessedData/vtc_childlens_v2/complete.uem (161 segments)\n",
      "\n",
      "‚úÖ Total processed files: 161\n",
      "\n",
      "üéôÔ∏è Speaker instance counts in all splits:\n",
      "  KCHI: 11595\n",
      "  SPEECH: 11595\n",
      "\n",
      "üìä RTTM split durations and video counts:\n",
      "  train: 146244.93 sec (80.1%), 98 videos\n",
      "  dev: 18337.89 sec (10.0%), 23 videos\n",
      "  test: 17952.87 sec (9.8%), 40 videos\n",
      "‚úÖ .lst files created for train, development, and test splits.\n",
      "‚úÖ .uem files created for train, development, and test splits.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Folder and output paths\n",
    "input_folder = \"/home/nele_pauline_suffo/ProcessedData/childlens_annotations\"\n",
    "output_dir = Path(\"/home/nele_pauline_suffo/ProcessedData/vtc_childlens_v2\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "valid_action_names = {\"Child Talking\", \"Other Person Talking\", \"Overheard Speech\", \"Singing/Humming\"}\n",
    "\n",
    "all_files = []\n",
    "speaker_counts = Counter()\n",
    "files_processed = 0\n",
    "\n",
    "# Step 1: Load all JSON files and collect metadata\n",
    "json_files = glob(f\"{input_folder}/*.json\")\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, \"r\") as f:\n",
    "            annotations = json.load(f)\n",
    "        uri = annotations['metadata']['name']\n",
    "        duration = annotations['metadata']['duration'] / 1_000_000  # microseconds to seconds\n",
    "        all_files.append({\n",
    "            \"path\": json_file,\n",
    "            \"uri\": uri,\n",
    "            \"duration\": duration\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {json_file} due to error: {e}\")\n",
    "\n",
    "# Step 2: Sort and split files by total duration\n",
    "all_files.sort(key=lambda x: x[\"duration\"], reverse=True)\n",
    "total_duration = sum(f[\"duration\"] for f in all_files)\n",
    "\n",
    "train_duration, dev_duration, test_duration = 0, 0, 0\n",
    "train_files, dev_files, test_files = [], [], []\n",
    "\n",
    "for f in all_files:\n",
    "    if train_duration < 0.8 * total_duration:\n",
    "        train_files.append(f)\n",
    "        train_duration += f[\"duration\"]\n",
    "    elif dev_duration < 0.1 * total_duration:\n",
    "        dev_files.append(f)\n",
    "        dev_duration += f[\"duration\"]\n",
    "    else:\n",
    "        test_files.append(f)\n",
    "        test_duration += f[\"duration\"]\n",
    "\n",
    "splits = {\n",
    "    \"train\": train_files,\n",
    "    \"dev\": dev_files,\n",
    "    \"test\": test_files\n",
    "}\n",
    "split_durations = {\n",
    "    \"train\": train_duration,\n",
    "    \"dev\": dev_duration,\n",
    "    \"test\": test_duration\n",
    "}\n",
    "\n",
    "# Step 3: Process each split and write RTTM\n",
    "all_df_rows = [] # Initialize list for DataFrame rows\n",
    "all_rttm_lines_combined_v2 = [] # Initialize list for all RTTM lines for the complete_v2.rttm\n",
    "\n",
    "for split_name, files_in_split in splits.items():\n",
    "    rttm_lines = [] # RTTM lines for the current split (v2 logic)\n",
    "\n",
    "    for f_info in files_in_split:\n",
    "        try:\n",
    "            with open(f_info[\"path\"], \"r\") as file_handle:\n",
    "                annotations = json.load(file_handle)\n",
    "            uri = annotations['metadata']['name']\n",
    "            # remove .mp4 from uri\n",
    "            uri_dict = uri.replace(\".MP4\", \"\")\n",
    "            child_id = sa_name_to_id_dict.get(uri_dict, \"UNKNOWN_CHILD_ID\")\n",
    "            files_processed += 1\n",
    "            \n",
    "            for instance in annotations.get('instances', []):\n",
    "                if instance[\"meta\"][\"type\"] != \"event\":\n",
    "                    continue\n",
    "                try:\n",
    "                    # Assuming the first parameter block contains the relevant timestamps and attributes\n",
    "                    if not instance[\"parameters\"] or not instance[\"parameters\"][0].get(\"timestamps\"):\n",
    "                        continue\n",
    "                    \n",
    "    \n",
    "                    parameter_block = instance[\"parameters\"][0]\n",
    "                    # Ensure 'timestamps' key exists and is a list\n",
    "                    if not isinstance(parameter_block.get(\"timestamps\"), list):\n",
    "                        continue\n",
    "                    \n",
    "                    # The 'start' and 'end' for the whole instance parameter block\n",
    "                    instance_start_time_us = parameter_block.get(\"start\")\n",
    "                    instance_end_time_us = parameter_block.get(\"end\")\n",
    "                    \n",
    "                    if instance_start_time_us is None or instance_end_time_us is None:\n",
    "                        pass\n",
    "                    \n",
    "                    for detail_idx, detail in enumerate(parameter_block[\"timestamps\"]):\n",
    "                        if \"attributes\" not in detail:\n",
    "                            continue\n",
    "                        \n",
    "                        action_type = next(\n",
    "                            (attr[\"name\"] for attr in detail[\"attributes\"]\n",
    "                             if attr[\"groupName\"] == \"Type of Action\"),\n",
    "                            None\n",
    "                        )  \n",
    "\n",
    "                        if action_type in valid_action_names:\n",
    "                            speaker_id = \"NA\"\n",
    "\n",
    "                            if action_type in [\"Child Talking\", \"Singing/Humming\"]:\n",
    "                                speaker_id = \"KCHI\"\n",
    "                            elif action_type == \"Other Person Talking\":\n",
    "                                speaker_id = \"CDS\" # Child Directed Speech\n",
    "                            elif action_type == \"Overheard Speech\":\n",
    "                                speaker_id = \"OHS\"\n",
    "\n",
    "                            # Correctly use segment start/end from the parameter_block\n",
    "                            # (which was referred to as 'timestamps' variable in original code)\n",
    "                            segment_start_us = parameter_block.get(\"start\")\n",
    "                            segment_end_us = parameter_block.get(\"end\")\n",
    "                            \n",
    "                            \n",
    "                            if segment_start_us is None or segment_end_us is None:\n",
    "                                print(f\"Warning: Missing start/end in parameter block for instance in {f_info['path']}. Skipping.\")\n",
    "                                continue\n",
    "                            \n",
    "                            \n",
    "                            start_sec = segment_start_us / 1_000_000\n",
    "                            end_sec = segment_end_us / 1_000_000\n",
    "                            duration_sec = end_sec - start_sec\n",
    "\n",
    "                            if duration_sec <= 0: # Ensure duration is positive\n",
    "                                print(f\"Warning: Non-positive duration {duration_sec:.3f}s for segment in {f_info['path']}. Skipping.\")\n",
    "                                continue\n",
    "                            \n",
    "                            rttm_line = f\"SPEAKER {uri} 1 {start_sec:.3f} {duration_sec:.3f} <NA> <NA> {speaker_id} <NA> {child_id}\"\n",
    "                            rttm_line_speech = f\"SPEAKER {uri} 1 {start_sec:.3f} {duration_sec:.3f} <NA> <NA> SPEECH <NA> {child_id}\"\n",
    "\n",
    "                            if speaker_id != \"NA\":\n",
    "                                rttm_lines.append(rttm_line)\n",
    "                                all_rttm_lines_combined_v2.append(rttm_line) # Add to combined list for v2\n",
    "                                if speaker_id == \"KCHI\":\n",
    "                                    rttm_lines.append(rttm_line_speech)\n",
    "                                    all_rttm_lines_combined_v2.append(rttm_line_speech) # Add to combined list for v2\n",
    "                                    speaker_counts[\"SPEECH\"] += 1\n",
    "                                speaker_counts[speaker_id] += 1\n",
    "                                \n",
    "                                # Prepare data for DataFrame (only specific voice type\n",
    "                                row_data_specific = {\n",
    "                                    \"audio_file_name\": uri,\n",
    "                                    \"Utterance_Start\": round(start_sec, 3),\n",
    "                                    \"Utterance_Duration\": round(duration_sec, 3),\n",
    "                                    \"Voice_type\": speaker_id, \n",
    "                                    \"Utterance_End\": round(end_sec, 3),\n",
    "                                    \"Child_ID\": child_id\n",
    "                                }\n",
    "                                all_df_rows.append(row_data_specific)\n",
    "                                \n",
    "                                # only use the first instance of each segment\n",
    "                                break\n",
    "                                \n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping instance in {f_info['path']} due to error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {f_info['path']}: {e}\")\n",
    "\n",
    "    # Save to RTTM file for the current split\n",
    "    rttm_path = output_dir / f\"{split_name}.rttm\" # This is vtc_childlens_v2\n",
    "    with open(rttm_path, \"w\") as out_f:\n",
    "        for line in rttm_lines:\n",
    "            out_f.write(line + \"\\n\")\n",
    "    print(f\"üìù RTTM file for {split_name} split saved to {rttm_path}\")\n",
    "\n",
    "# Save the complete RTTM file for v2 after processing all splits\n",
    "complete_rttm_path_v2 = output_dir / \"complete.rttm\" # This is vtc_childlens_v2\n",
    "with open(complete_rttm_path_v2, \"w\") as out_f:\n",
    "    for line in all_rttm_lines_combined_v2:\n",
    "        out_f.write(line + \"\\n\")\n",
    "print(f\"üìù Complete RTTM file for v2 (all splits) saved to {complete_rttm_path_v2}\")\n",
    "\n",
    "# Create and save ONE COMBINED DataFrame after processing all splits\n",
    "if all_df_rows:\n",
    "    combined_df = pd.DataFrame(all_df_rows)\n",
    "    # Ensure desired column order\n",
    "    combined_df = combined_df[[\"audio_file_name\", \"Utterance_Start\", \"Utterance_Duration\", \"Voice_type\", \"Utterance_End\"]]\n",
    "    # Define the single output path for the combined pickle file\n",
    "    df_pkl_path = Path(\"/home/nele_pauline_suffo/ProcessedData/childlens_annotations/processed/childlens_annotations_gt_v2.pkl\")\n",
    "    # Ensure the directory exists\n",
    "    df_pkl_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    combined_df.to_pickle(df_pkl_path)\n",
    "    print(f\"‚úÖ Combined DataFrame for all splits saved to {df_pkl_path} ({len(combined_df)} rows)\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è No data to create combined DataFrame.\")\n",
    "\n",
    "# Step 3.5: Save a complete UEM file with all video information\n",
    "uem_lines = []\n",
    "for f in all_files:\n",
    "    uri = f[\"uri\"]\n",
    "    start_time = 0.000\n",
    "    end_time = f[\"duration\"]\n",
    "    uem_lines.append(f\"{uri} 1 {start_time:.3f} {end_time:.3f}\")\n",
    "\n",
    "uem_path = output_dir / \"complete.uem\"\n",
    "with open(uem_path, \"w\") as uem_file:\n",
    "    for line in uem_lines:\n",
    "        uem_file.write(line + \"\\n\")\n",
    "print(f\"‚úÖ Combined UEM file for all videos saved to {uem_path} ({len(uem_lines)} segments)\")\n",
    "\n",
    "# Step 4: Summary logs\n",
    "print(f\"\\n‚úÖ Total processed files: {files_processed}\")\n",
    "print(\"\\nüéôÔ∏è Speaker instance counts in all splits:\")\n",
    "for speaker_id in ['KCHI', 'SPEECH']:\n",
    "    print(f\"  {speaker_id}: {speaker_counts[speaker_id]}\")\n",
    "\n",
    "print(\"\\nüìä RTTM split durations and video counts:\")\n",
    "for split_name in [\"train\", \"dev\", \"test\"]:\n",
    "    dur = split_durations[split_name]\n",
    "    perc = (dur / total_duration) * 100\n",
    "    count = len(splits[split_name])\n",
    "    print(f\"  {split_name}: {dur:.2f} sec ({perc:.1f}%), {count} videos\")\n",
    "\n",
    "# Generate .lst files for train, development, and test splits\n",
    "for split_name, files in splits.items():\n",
    "    lst_path = output_dir / f\"{split_name}.lst\"\n",
    "    with open(lst_path, \"w\") as lst_file:\n",
    "        for f in files:\n",
    "            lst_file.write(f\"{f['uri']}\\n\")\n",
    "\n",
    "print(\"‚úÖ .lst files created for train, development, and test splits.\")\n",
    "\n",
    "# Generate .uem files for train, development, and test splits\n",
    "for split_name, files in splits.items():\n",
    "    uem_path = output_dir / f\"{split_name}.uem\"\n",
    "    with open(uem_path, \"w\") as uem_file:\n",
    "        for f in files:\n",
    "            try:\n",
    "                # Extract the URI and duration for each video\n",
    "                uri = f[\"uri\"]\n",
    "                start = 0  # Start time is always 0\n",
    "                end = f[\"duration\"]  # End time is the video's duration\n",
    "\n",
    "                # Write a single line for each video\n",
    "                uem_line = f\"{uri} 1 {start:.3f} {end:.3f}\"\n",
    "                uem_file.write(uem_line + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {f['path']}: {e}\")\n",
    "\n",
    "print(\"‚úÖ .uem files created for train, development, and test splits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b1a56",
   "metadata": {},
   "source": [
    "## Create rttm files per video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3764ff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Individual RTTM files created in /home/nele_pauline_suffo/ProcessedData/vtc_childlens/rttm_per_video.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# Create a new folder to save individual RTTM files\n",
    "individual_rttm_dir = Path(\"/home/nele_pauline_suffo/ProcessedData/vtc_childlens/rttm_per_video\")\n",
    "individual_rttm_dir.mkdir(exist_ok=True)\n",
    "output_dir = Path(\"/home/nele_pauline_suffo/ProcessedData/vtc_childlens\")\n",
    "\n",
    "# Process each split's RTTM file\n",
    "for split_name in [\"train\", \"dev\", \"test\"]:\n",
    "    rttm_path = output_dir / f\"{split_name}.rttm\"\n",
    "    try:\n",
    "        with open(rttm_path, \"r\") as rttm_file:\n",
    "            lines = rttm_file.readlines()\n",
    "\n",
    "        # Group lines by video ID (URI)\n",
    "        video_rttm_data = {}\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            uri = parts[1]  # Video ID\n",
    "            if uri not in video_rttm_data:\n",
    "                video_rttm_data[uri] = []\n",
    "            video_rttm_data[uri].append(line)\n",
    "\n",
    "        # Write each video's RTTM data to a separate file\n",
    "        for uri, rttm_lines in video_rttm_data.items():\n",
    "            video_rttm_path = individual_rttm_dir / f\"{uri}.rttm\"\n",
    "            with open(video_rttm_path, \"w\") as video_rttm_file:\n",
    "                video_rttm_file.writelines(rttm_lines)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing RTTM file {rttm_path}: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Individual RTTM files created in {individual_rttm_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c82e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyannote",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
