{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb0f569",
   "metadata": {},
   "source": [
    "## Generate RTTM File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d85305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Total processed files: 161\n",
      "\n",
      "üéôÔ∏è Speaker instance counts in all splits:\n",
      "  kchi: 11295\n",
      "  och: 701\n",
      "  fem: 6193\n",
      "  mal: 2447\n",
      "  ovh: 3172\n",
      "\n",
      "üìä RTTM split durations and video counts:\n",
      "  train: 146244.93 sec (80.1%), 98 videos\n",
      "  dev: 18337.89 sec (10.0%), 23 videos\n",
      "  test: 17952.87 sec (9.8%), 40 videos\n",
      "‚úÖ .lst files created for train, development, and test splits.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "\n",
    "# Folder and output paths\n",
    "input_folder = \"/home/nele_pauline_suffo/ProcessedData/childlens_annotations\"\n",
    "output_dir = Path(\"/home/nele_pauline_suffo/ProcessedData/vtc_childlens\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "valid_action_names = {\"Child Talking\", \"Other Person Talking\", \"Overheard Speech\"}\n",
    "\n",
    "all_files = []\n",
    "speaker_counts = Counter()\n",
    "files_processed = 0\n",
    "\n",
    "# Step 1: Load all JSON files and collect metadata\n",
    "json_files = glob(f\"{input_folder}/*.json\")\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, \"r\") as f:\n",
    "            annotations = json.load(f)\n",
    "        uri = annotations['metadata']['name']\n",
    "        duration = annotations['metadata']['duration'] / 1_000_000  # microseconds to seconds\n",
    "        all_files.append({\n",
    "            \"path\": json_file,\n",
    "            \"uri\": uri,\n",
    "            \"duration\": duration\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {json_file} due to error: {e}\")\n",
    "\n",
    "# Step 2: Sort and split files by total duration\n",
    "all_files.sort(key=lambda x: x[\"duration\"], reverse=True)\n",
    "total_duration = sum(f[\"duration\"] for f in all_files)\n",
    "\n",
    "train_duration, dev_duration, test_duration = 0, 0, 0\n",
    "train_files, dev_files, test_files = [], [], []\n",
    "\n",
    "for f in all_files:\n",
    "    if train_duration < 0.8 * total_duration:\n",
    "        train_files.append(f)\n",
    "        train_duration += f[\"duration\"]\n",
    "    elif dev_duration < 0.1 * total_duration:\n",
    "        dev_files.append(f)\n",
    "        dev_duration += f[\"duration\"]\n",
    "    else:\n",
    "        test_files.append(f)\n",
    "        test_duration += f[\"duration\"]\n",
    "\n",
    "splits = {\n",
    "    \"train\": train_files,\n",
    "    \"dev\": dev_files,\n",
    "    \"test\": test_files\n",
    "}\n",
    "split_durations = {\n",
    "    \"train\": train_duration,\n",
    "    \"dev\": dev_duration,\n",
    "    \"test\": test_duration\n",
    "}\n",
    "\n",
    "# Step 3: Process each split and write RTTM\n",
    "for split_name, files in splits.items():\n",
    "    rttm_lines = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            with open(f[\"path\"], \"r\") as file:\n",
    "                annotations = json.load(file)\n",
    "            uri = annotations['metadata']['name']\n",
    "            files_processed += 1\n",
    "\n",
    "            for instance in annotations.get('instances', []):\n",
    "                if instance[\"meta\"][\"type\"] != \"event\":\n",
    "                    continue\n",
    "                try:\n",
    "                    details = instance[\"parameters\"][0][\"timestamps\"]\n",
    "                    timestamps = instance[\"parameters\"][0]\n",
    "\n",
    "                    for detail in details:\n",
    "                        if \"attributes\" not in detail:\n",
    "                            continue\n",
    "                        action_type = next(\n",
    "                            (attr[\"name\"] for attr in detail[\"attributes\"]\n",
    "                             if attr[\"groupName\"] == \"Type of Action\"),\n",
    "                            None\n",
    "                        )  \n",
    "\n",
    "                        if action_type in valid_action_names:\n",
    "                            # Determine speaker ID\n",
    "                            speaker_id = \"speech\"\n",
    "\n",
    "                            if action_type == \"Child Talking\":\n",
    "                                speaker_id = \"kchi\"\n",
    "                            elif action_type == \"Other Person Talking\":\n",
    "                                age_group = next(\n",
    "                                    (attr[\"name\"] for attr in detail[\"attributes\"]\n",
    "                                     if attr[\"groupName\"] == \"1st Person Age Group\"),\n",
    "                                    None\n",
    "                                )\n",
    "                                gender = next(\n",
    "                                    (attr[\"name\"] for attr in detail[\"attributes\"]\n",
    "                                     if attr[\"groupName\"] == \"1st Person Gender\"),\n",
    "                                    None\n",
    "                                )\n",
    "\n",
    "                                if age_group in [\"Child\", \"Infant\"]:\n",
    "                                    speaker_id = \"och\"\n",
    "                                elif age_group in [\"Adult\", \"Adolescent\"]:\n",
    "                                    if gender == \"Female\":\n",
    "                                        speaker_id = \"fem\"\n",
    "                                    elif gender == \"Male\":\n",
    "                                        speaker_id = \"mal\"\n",
    "\n",
    "                            elif action_type == \"Overheard Speech\":\n",
    "                                speaker_id = \"ovh\"\n",
    "\n",
    "                            # Timing\n",
    "                            start = timestamps[\"start\"] / 1_000_000\n",
    "                            end = timestamps[\"end\"] / 1_000_000\n",
    "                            duration = end - start\n",
    "\n",
    "                            rttm_line = f\"SPEAKER {uri} 1 {start:.3f} {duration:.3f} <NA> <NA> {speaker_id} <NA> <NA>\"\n",
    "\n",
    "                            if speaker_id != \"speech\":\n",
    "                                rttm_lines.append(rttm_line)\n",
    "                                speaker_counts[speaker_id] += 1\n",
    "                                break  # Only use the first relevant block per instance\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping instance in {f['path']} due to error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {f['path']}: {e}\")\n",
    "\n",
    "    # Save to RTTM file\n",
    "    rttm_path = output_dir / f\"{split_name}.rttm\"\n",
    "    with open(rttm_path, \"w\") as out_f:\n",
    "        for line in rttm_lines:\n",
    "            out_f.write(line + \"\\n\")\n",
    "\n",
    "# Step 4: Summary logs\n",
    "print(f\"\\n‚úÖ Total processed files: {files_processed}\")\n",
    "print(\"\\nüéôÔ∏è Speaker instance counts in all splits:\")\n",
    "for speaker_id in ['kchi', 'och', 'fem', 'mal', 'ovh']:\n",
    "    print(f\"  {speaker_id}: {speaker_counts[speaker_id]}\")\n",
    "\n",
    "print(\"\\nüìä RTTM split durations and video counts:\")\n",
    "for split_name in [\"train\", \"dev\", \"test\"]:\n",
    "    dur = split_durations[split_name]\n",
    "    perc = (dur / total_duration) * 100\n",
    "    count = len(splits[split_name])\n",
    "    print(f\"  {split_name}: {dur:.2f} sec ({perc:.1f}%), {count} videos\")\n",
    "\n",
    "# Generate .lst files for train, development, and test splits\n",
    "for split_name, files in splits.items():\n",
    "    lst_path = output_dir / f\"{split_name}.lst\"\n",
    "    with open(lst_path, \"w\") as lst_file:\n",
    "        for f in files:\n",
    "            lst_file.write(f\"{f['uri']}\\n\")\n",
    "\n",
    "print(\"‚úÖ .lst files created for train, development, and test splits.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyannote",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
