{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "\n",
    "# Load the video_info_new.csv file\n",
    "video_info_new_path = \"/home/nele_pauline_suffo/projects/mmaction2/data/quantex_share/video_info_new.csv\"\n",
    "df_video_info_new = pd.read_csv(video_info_new_path)\n",
    "\n",
    "# Function to get the subset for a given video ID\n",
    "def get_subset(video_id):\n",
    "    row = df_video_info_new[df_video_info_new['video'] == video_id]\n",
    "    if not row.empty:\n",
    "        return row.iloc[0]['subset']\n",
    "    else:\n",
    "        return None  # Video ID not found\n",
    "    \n",
    "# Function to read JSON from a file\n",
    "def read_json(file_path: str) -> Dict:\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Conversion function to ActivityNet format\n",
    "def convert_annotations(data: Dict, fps: float = 30.0) -> Dict:\n",
    "    # Initialize the converted structure\n",
    "    converted_annotations = {}\n",
    "\n",
    "    # Extract video ID, duration in seconds, and duration in frames\n",
    "    video_id = data['metadata']['name']\n",
    "    short_video_id = video_id.replace(\".MP4\", \"\")\n",
    "    duration_microseconds = data['metadata']['duration']\n",
    "    duration_seconds = duration_microseconds / 1_000_000.0\n",
    "    # Extract the subset from the video_info_new.csv file\n",
    "    subset = get_subset(int(short_video_id))\n",
    "\n",
    "    # Initialize the video data structure in ActivityNet format\n",
    "    converted_annotations[short_video_id] = {\n",
    "        \"subset\": subset,\n",
    "        \"duration\": duration_seconds,\n",
    "        \"url\": \"\",  # Optional: Add video URL if available\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "    # Loop through each annotation instance\n",
    "    for item in data['instances']:\n",
    "        meta = item['meta']\n",
    "        if meta.get('className') in (None, 'Location'):\n",
    "            continue\n",
    "\n",
    "        # Extract start and end time\n",
    "        start_time = meta[\"start\"]\n",
    "        end_time = meta[\"end\"]\n",
    "\n",
    "        # Process each parameter and add its first annotation to the list\n",
    "        for parameter in item.get(\"parameters\", []):\n",
    "            timestamps = parameter.get(\"timestamps\", [])\n",
    "\n",
    "            # Check if there is at least one timestamp\n",
    "            if timestamps and \"attributes\" in timestamps[0] and timestamps[0][\"attributes\"]:\n",
    "                # Collect all \"name\" entries in a list\n",
    "                names = [attr[\"name\"] for timestamp in timestamps for attr in timestamp.get(\"attributes\", [])]                \n",
    "                # Choose the first one that is in list_to_include\n",
    "                list_to_include = ['Playing with Object', \n",
    "                                'Playing without Object', \n",
    "                                'Pretend play',\n",
    "                                'Watching Something',\n",
    "                                'Reading a Book',\n",
    "                                'Drawing',\n",
    "                                'Crafting Things',\n",
    "                                'Dancing',\n",
    "                                'Making Music']   \n",
    "                label = next((name for name in names if name in list_to_include), None)\n",
    "                \n",
    "                if label is not None:\n",
    "                    segment = [start_time / 1_000_000.0, end_time / 1_000_000.0]\n",
    "\n",
    "                    # Append the annotation for this timestamp\n",
    "                    converted_annotations[short_video_id][\"annotations\"].append({\n",
    "                        \"segment\": segment,\n",
    "                        \"label\": label\n",
    "                    })\n",
    "\n",
    "    return converted_annotations\n",
    "\n",
    "# Function to process all JSON files in a folder and generate ActivityNet format\n",
    "def process_all_json_files(input_dir: Path, output_file: Path, fps: float = 30.0) -> None:\n",
    "    all_annotations = {\n",
    "        \"version\": \"1.0\",\n",
    "        \"taxonomy\": [\n",
    "            {\"nodeId\": 1, \"nodeName\": \"Playing with object\", \"parentId\": None},\n",
    "            {\"nodeId\": 2, \"nodeName\": \"Playing without object\", \"parentId\": None},\n",
    "            {\"nodeId\": 3, \"nodeName\": \"Pretend play\", \"parentId\": None},\n",
    "            {\"nodeId\": 4, \"nodeName\": \"Watching something\", \"parentId\": None},\n",
    "            {\"nodeId\": 5, \"nodeName\": \"Reading book\", \"parentId\": None},\n",
    "            {\"nodeId\": 6, \"nodeName\": \"Drawing\", \"parentId\": None},\n",
    "            {\"nodeId\": 7, \"nodeName\": \"Crafting things\", \"parentId\": None},\n",
    "            {\"nodeId\": 8, \"nodeName\": \"Dancing\", \"parentId\": None},\n",
    "            {\"nodeId\": 9, \"nodeName\": \"Making music\", \"parentId\": None},\n",
    "        ],\n",
    "        \"database\": {}\n",
    "    }\n",
    "\n",
    "    # Iterate over all files in the specified folder\n",
    "    for filename in input_dir.glob(\"*.json\"):\n",
    "        if filename.name == output_file.name:\n",
    "            continue  # Skip the combined file\n",
    "        # Read the JSON file\n",
    "        data = read_json(filename)\n",
    "\n",
    "        # Convert annotations and merge them into the \"database\" field\n",
    "        video_annotations = convert_annotations(data, fps)\n",
    "        all_annotations[\"database\"].update(video_annotations)\n",
    "\n",
    "    # Save combined_annotations as a JSON file in ActivityNet format\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(all_annotations, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(\"/home/nele_pauline_suffo/ProcessedData/annotations_superannotate\")\n",
    "output_file = Path(\"/home/nele_pauline_suffo/projects/mmaction2/data/quantex_share/quantex_share.json\")\n",
    "process_all_json_files(input_dir, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Playing with Object',\n",
       " 'Playing without Object',\n",
       " 'Pretend play',\n",
       " 'Watching Something',\n",
       " 'Reading a Book',\n",
       " 'Drawing',\n",
       " 'Crafting Things',\n",
       " 'Dancing',\n",
       " 'Making Music']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file = '/home/nele_pauline_suffo/projects/mmaction2/data/quantex_share/quantex_share.json'\n",
    "load_dict = json.load(open(json_file))\n",
    "database = load_dict['database']\n",
    "action_name_list = '/home/nele_pauline_suffo/projects/mmaction2/tools/data/quantex_share/action_name.csv'\n",
    "\n",
    "\n",
    "quantex_labels = open(action_name_list).readlines()\n",
    "quantex_labels = [x.strip() for x in quantex_labels[1:]]\n",
    "quantex_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantex_labels.index('Pretend play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "def simple_label(anno):\n",
    "    label = anno[0]['label']\n",
    "    return quantex_labels.index(label)\n",
    "    \n",
    "data = database['147984']\n",
    "subset = data['subset']\n",
    "\n",
    "if subset in ['training', 'validation']:\n",
    "    annotations = data['annotations']\n",
    "    label = simple_label(annotations)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read JSON from a file\n",
    "def read_json(file_path: str) -> Dict:\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Conversion function\n",
    "def convert_annotations(data: Dict, fps: float = 30.0) -> Dict:\n",
    "    converted_annotations = {}\n",
    "    \n",
    "    # Extract video ID, duration in seconds, and duration in frames\n",
    "    video_id = data['metadata']['name']\n",
    "    short_video_id = video_id.replace(\".MP4\", \"\")\n",
    "    duration_microseconds = data['metadata']['duration']\n",
    "    duration_seconds = duration_microseconds / 1000000.0\n",
    "    duration_frames = int(duration_seconds * fps)\n",
    "    \n",
    "    # Initialize the video data structure\n",
    "    converted_annotations[short_video_id] = {\n",
    "        \"duration_second\": duration_seconds, # duration in seconds\n",
    "        \"duration_frame\": duration_frames,   # duration in frames\n",
    "        \"annotations\": [],                   # initialize empty list for annotations\n",
    "        \"feature_frame\": duration_frames - 1, # feature frame\n",
    "        \"fps\": fps,                          # frames per second\n",
    "        \"rfps\": fps * (duration_frames / duration_seconds) # real frames per second\n",
    "    }\n",
    "\n",
    "    # Loop through each annotation instance\n",
    "    for item in data['instances']:\n",
    "        # Extract start and end time\n",
    "        start_time = item[\"meta\"][\"start\"]\n",
    "        end_time = item[\"meta\"][\"end\"]\n",
    "        \n",
    "        # Process each parameter and add its first annotation to the list\n",
    "        for parameter in item.get(\"parameters\", []):\n",
    "            timestamps = parameter.get(\"timestamps\", [])\n",
    "            \n",
    "            # Check if there is at least one timestamp\n",
    "            if timestamps and \"attributes\" in timestamps[0] and timestamps[0][\"attributes\"]:\n",
    "                # Access the first timestamp directly\n",
    "                label = timestamps[0][\"attributes\"][0][\"name\"]\n",
    "                segment = [start_time / 1000000.0, end_time / 1000000.0]\n",
    "                \n",
    "                # Append the annotation for this timestamp\n",
    "                converted_annotations[short_video_id][\"annotations\"].append({\n",
    "                    \"segment\": segment,\n",
    "                    \"label\": label\n",
    "                })\n",
    "    \n",
    "    return converted_annotations\n",
    "\n",
    "\n",
    "# Function to process all JSON files in a folder\n",
    "def process_all_json_files(folder_path: str, fps: float = 30.0) -> Dict:\n",
    "    all_annotations = {}\n",
    "    \n",
    "    # Iterate over all files in the specified folder\n",
    "    for filename in folder_path.glob(\"*.json\"):\n",
    "        if filename.name == \"combined_annotations.json\":\n",
    "            continue  # Skip the combined file\n",
    "        # Read the JSON file\n",
    "        data = read_json(filename)\n",
    "        \n",
    "        # Convert annotations and merge them into the main dictionary\n",
    "        video_annotations = convert_annotations(data, fps)\n",
    "        all_annotations.update(video_annotations)\n",
    "    \n",
    "    # Save combined_annotations as a JSON file\n",
    "    output_file = folder_path / \"combined_annotations.json\"\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(all_annotations, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames: 8946\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def get_frame_count(video_path):\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Check if the video was opened successfully\n",
    "    if not video.isOpened():\n",
    "        raise ValueError(f\"Could not open the video file: {video_path}\")\n",
    "    \n",
    "    # Get the frame count\n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Release the video file\n",
    "    video.release()\n",
    "    \n",
    "    return frame_count\n",
    "\n",
    "# Example usage\n",
    "video_path = \"/home/nele_pauline_suffo/projects/mmaction2/data/quantex_share/videos/204839.MP4\"\n",
    "print(\"Total number of frames:\", get_frame_count(video_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
