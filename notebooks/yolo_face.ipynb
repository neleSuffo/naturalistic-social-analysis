{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca086425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nele_pauline_suffo/ProcessedData/face_det_input/images/test/quantex_at_home_id261609_2022_04_01_07_019170.jpg: 384x640 1 child face, 46.8ms\n",
      "Speed: 2.9ms preprocess, 46.8ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "image 1/1 /home/nele_pauline_suffo/ProcessedData/face_det_input/images/test/quantex_at_home_id261609_2022_04_01_07_019170.jpg: 384x640 1 child face, 46.8ms\n",
      "Speed: 2.9ms preprocess, 46.8ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from supervision import Detections\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model = YOLO(\"/home/nele_pauline_suffo/outputs/face_detections/20250710_191640_yolo11x_face/weights/best.pt\")\n",
    "\n",
    "image_path = \"/home/nele_pauline_suffo/ProcessedData/face_det_input/images/test/quantex_at_home_id261609_2022_04_01_07_019170.jpg\"\n",
    "output = model(image_path)\n",
    "image = cv2.imread(str(image_path))\n",
    "results = Detections.from_ultralytics(output[0])\n",
    "\n",
    "def draw_detections_and_ground_truth(\n",
    "    image: np.ndarray, \n",
    "    predictions: Detections, \n",
    ") -> np.ndarray:\n",
    "    \"\"\"Draw both predictions and ground truth boxes on image\"\"\"\n",
    "    annotated_image = image.copy()\n",
    "    \n",
    "    # Draw prediction boxes in green\n",
    "    for i, (bbox, conf, class_id) in enumerate(zip(predictions.xyxy, predictions.confidence, predictions.class_id)):\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green\n",
    "        # If class id is 1, display KCHI; otherwise, display default detection label with confidence\n",
    "        if int(class_id) == 1:\n",
    "            label = f\"Adult {conf:.2f}\"\n",
    "        else:\n",
    "            label = f\"Child {conf:.2f}\"\n",
    "        cv2.putText(annotated_image, label, (x1+10, y2-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    return annotated_image\n",
    "\n",
    "# Draw detections and save\n",
    "annotated_image = draw_detections_and_ground_truth(\n",
    "    image, \n",
    "    results, \n",
    ")   \n",
    "\n",
    "output_filename = os.path.basename(image_path)\n",
    "cv2.imwrite(output_filename, annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c424e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
