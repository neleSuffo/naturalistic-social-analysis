{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df from pickle file\n",
    "import pandas as pd\n",
    "vtc_share_output = pd.read_pickle('/home/nele_pauline_suffo/outputs/vtc/quantex_share_vtc_output.pkl')\n",
    "annotations_output = pd.read_pickle('/home/nele_pauline_suffo/ProcessedData/annotations_superannotate/quantex_share_annotations.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file_name</th>\n",
       "      <th>Utterance_Start</th>\n",
       "      <th>Utterance_Duration</th>\n",
       "      <th>Voice_type</th>\n",
       "      <th>Utterance_End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>442279</td>\n",
       "      <td>0.942</td>\n",
       "      <td>1.243</td>\n",
       "      <td>FEM</td>\n",
       "      <td>2.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>442279</td>\n",
       "      <td>2.245</td>\n",
       "      <td>1.129</td>\n",
       "      <td>KCHI</td>\n",
       "      <td>3.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>442279</td>\n",
       "      <td>3.714</td>\n",
       "      <td>1.919</td>\n",
       "      <td>FEM</td>\n",
       "      <td>5.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>442279</td>\n",
       "      <td>5.650</td>\n",
       "      <td>3.044</td>\n",
       "      <td>KCHI</td>\n",
       "      <td>8.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>442279</td>\n",
       "      <td>8.829</td>\n",
       "      <td>1.184</td>\n",
       "      <td>FEM</td>\n",
       "      <td>10.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  audio_file_name  Utterance_Start  Utterance_Duration Voice_type  \\\n",
       "0          442279            0.942               1.243        FEM   \n",
       "1          442279            2.245               1.129       KCHI   \n",
       "2          442279            3.714               1.919        FEM   \n",
       "3          442279            5.650               3.044       KCHI   \n",
       "4          442279            8.829               1.184        FEM   \n",
       "\n",
       "   Utterance_End  \n",
       "0          2.185  \n",
       "1          3.374  \n",
       "2          5.633  \n",
       "3          8.694  \n",
       "4         10.013  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file_name</th>\n",
       "      <th>Utterance_Start</th>\n",
       "      <th>Utterance_Duration</th>\n",
       "      <th>Voice_type</th>\n",
       "      <th>Utterance_End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100898</td>\n",
       "      <td>0.231</td>\n",
       "      <td>4.411</td>\n",
       "      <td>SPEECH</td>\n",
       "      <td>4.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100898</td>\n",
       "      <td>0.251</td>\n",
       "      <td>1.453</td>\n",
       "      <td>KCHI</td>\n",
       "      <td>1.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100898</td>\n",
       "      <td>1.011</td>\n",
       "      <td>0.255</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100898</td>\n",
       "      <td>1.851</td>\n",
       "      <td>1.774</td>\n",
       "      <td>FEM</td>\n",
       "      <td>3.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100898</td>\n",
       "      <td>3.731</td>\n",
       "      <td>0.780</td>\n",
       "      <td>KCHI</td>\n",
       "      <td>4.511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  audio_file_name  Utterance_Start  Utterance_Duration Voice_type  \\\n",
       "0          100898            0.231               4.411     SPEECH   \n",
       "1          100898            0.251               1.453       KCHI   \n",
       "2          100898            1.011               0.255        CHI   \n",
       "3          100898            1.851               1.774        FEM   \n",
       "4          100898            3.731               0.780       KCHI   \n",
       "\n",
       "   Utterance_End  \n",
       "0          4.642  \n",
       "1          1.704  \n",
       "2          1.266  \n",
       "3          3.625  \n",
       "4          4.511  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtc_share_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nele_pauline_suffo/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py:13: DeprecationWarning: Please use `spmatrix` from the `scipy.sparse` namespace, the `scipy.sparse.base` namespace is deprecated.\n",
      "  from scipy.sparse.base import spmatrix\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def time_overlap(start_pred, end_pred, start_annot, end_annot, tolerance=0.0):\n",
    "    \"\"\"\n",
    "    Check if the predicted time interval overlaps with the annotated time interval.\n",
    "    If a tolerance is provided, the overlap is allowed within that collar.\n",
    "    \"\"\"\n",
    "    # Allow tolerance (collar) for the time intervals\n",
    "    start_pred = start_pred - tolerance\n",
    "    end_pred = end_pred + tolerance\n",
    "    \n",
    "    # Check for overlap: [start_pred, end_pred] overlaps with [start_annot, end_annot]\n",
    "    overlap = not (end_pred < start_annot or start_pred > end_annot)\n",
    "    return overlap\n",
    "\n",
    "\n",
    "# Merge predictions and annotations on `audio_file_name`\n",
    "merged = pd.merge(\n",
    "    vtc_share_output,\n",
    "    annotations_output,\n",
    "    on='audio_file_name',\n",
    "    how='left',  # Keeps all predictions, adds NaN for missing annotations\n",
    "    suffixes=('_pred', '_annot')\n",
    ")\n",
    "\n",
    "# Drop rows where there are no annotations available\n",
    "paired_data = merged.dropna(subset=['Utterance_Start_annot'])  # Keeps only matched rows\n",
    "\n",
    "# Ensure all unique voice types are included\n",
    "all_classes = set(paired_data['Voice_type_pred'].unique()) | set(paired_data['Voice_type_annot'].unique())\n",
    "\n",
    "# Initialize placeholders for binary metrics per class\n",
    "results = {}\n",
    "\n",
    "for voice_type in all_classes:\n",
    "    class_data = paired_data[paired_data['Voice_type_pred'] == voice_type]\n",
    "\n",
    "    # Initialize binary metrics\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    \n",
    "    # Compare each prediction and annotation for the current class\n",
    "    for _, row in class_data.iterrows():\n",
    "        start_pred = row['Utterance_Start_pred']\n",
    "        end_pred = row['Utterance_End_pred']\n",
    "        start_annot = row['Utterance_Start_annot']\n",
    "        end_annot = row['Utterance_End_annot']\n",
    "        \n",
    "        # Check if the prediction overlaps with the annotation\n",
    "        if time_overlap(start_pred, end_pred, start_annot, end_annot):\n",
    "            tp += 1  # True Positive: there is an overlap\n",
    "        else:\n",
    "            fp += 1  # False Positive: prediction has no overlap\n",
    "    \n",
    "    # Compute False Negatives: annotations that don't have corresponding predictions\n",
    "    fn = len(class_data) - tp\n",
    "    \n",
    "    # Compute precision, recall, F1 score for the current class\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "\n",
    "    # Store results\n",
    "    results[voice_type] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "    \n",
    "# Calculate macro F1 score\n",
    "f1_scores = [class_metrics['f1'] for class_metrics in results.values()]\n",
    "macro_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# Output results\n",
    "print(\"Class-wise Metrics:\")\n",
    "for voice_type, metrics in results.items():\n",
    "    print(f\"{voice_type}: Precision={metrics['precision']:.3f}, Recall={metrics['recall']:.3f}, F1={metrics['f1']:.3f}\")\n",
    "\n",
    "print(f\"\\nMacro F1 Score: {macro_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyannote",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
